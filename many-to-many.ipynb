{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: -0.7346\n",
      "Epoch: 100, loss: -169.1972\n",
      "Epoch: 200, loss: -334.0926\n",
      "Epoch: 300, loss: -493.5266\n",
      "Epoch: 400, loss: -650.4119\n",
      "Epoch: 500, loss: -805.0861\n",
      "Epoch: 600, loss: -957.2609\n",
      "Epoch: 700, loss: -1110.6610\n",
      "Epoch: 800, loss: -1262.4364\n",
      "Epoch: 900, loss: -1413.7457\n"
     ]
    }
   ],
   "source": [
    "#many to many\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "lr = 0.1\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 2\n",
    "batch_size = 1\n",
    "seq_len = 20\n",
    "num_layers = 1\n",
    "\n",
    "# random data\n",
    "inputs = torch.randn(batch_size, seq_len, input_size)\n",
    "targets = torch.randn(batch_size, seq_len, output_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model\n",
    "# many to many LSTM\n",
    "\n",
    "class LSTMmany(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMmany, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstmencoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.lstmdecoder = nn.LSTM(hidden_size * 2, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        _, h = self.lstmencoder(input, self.hidden)\n",
    "        latent = h[-(1 + int(self.lstmencoder.bidirectional)):]\n",
    "        #decode the latent vector to (batch_size, seq_len, output_size)\n",
    "        #latent is shape of (batch_size, hidden_size * num_directions)\n",
    "        output, _ = self.lstmdecoder(latent.repeat(1, seq_len, 1), self.hidden)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "model = LSTMmany(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    model.zero_grad()\n",
    "    model.hidden = model.init_hidden()\n",
    "    input = torch.Tensor(inputs).to(device)\n",
    "    target = torch.Tensor(targets).to(device)\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch: %d, loss: %.4f' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y, day, input_len=128):\n",
    "        #the input data is a 1d array, indicate the minute of the day\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.day = day\n",
    "        self.input_len = input_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #output previous self.input_len minutes data and target value\n",
    "        #if the there is no enough data in the same day, pad with 0\n",
    "        #y is the target value of future input_len minutes\n",
    "        d = self.day[index]\n",
    "        start = index - self.input_len\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if self.day[start] != d:\n",
    "            while self.day[start] != d:\n",
    "                start += 1\n",
    "            #pad with 0 before start\n",
    "        if index - start < self.input_len:\n",
    "            x = torch.zeros(self.input_len, self.X.shape[1])\n",
    "            x[self.input_len - index + start: self.input_len] = self.X[start: index].clone()\n",
    "        else:\n",
    "            x = self.X[start: index]\n",
    "\n",
    "        #generate y\n",
    "        end = index + self.input_len\n",
    "        if end >= len(self.X):\n",
    "            end = len(self.X) - 1\n",
    "        if self.day[end] != d:\n",
    "            while self.day[end] != d:\n",
    "                end -= 1\n",
    "        #pad with 0 after end\n",
    "        if end - index < self.input_len:\n",
    "            y = torch.zeros(self.input_len)\n",
    "            y[0: end - index] = self.y[index: end].clone()\n",
    "        else:\n",
    "            y = self.y[index: end]\n",
    "            \n",
    "\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n",
      "torch.Size([4, 128, 2]) torch.Size([4, 128])\n"
     ]
    }
   ],
   "source": [
    "#test ManyDataset\n",
    "num_samples = 1000\n",
    "X = torch.randn(num_samples, 2)\n",
    "y = torch.randn(num_samples)\n",
    "days = torch.randint(1, 10, (num_samples,))\n",
    "dataset = ManyDataset(X, y, days)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "for i, data in enumerate(dataloader):\n",
    "    x, y = data\n",
    "    print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'ManyDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'ManyDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 9553) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1164\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 9553) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1326\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1176\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1175\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1178\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 9553) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "for i in dataloader:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([1000, 40])\n",
      "torch.Size([9, 40])\n"
     ]
    }
   ],
   "source": [
    "X= torch.rand(100009, 40)\n",
    "#split into 100 chunks\n",
    "chunks = torch.split(X, len(X) // 100, dim=0)\n",
    "for chunk in chunks:\n",
    "    print(chunk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10, 5)\n",
      "(64, 10, 2)\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [1/100], loss: 1.1006\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [2/100], loss: 1.0983\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [3/100], loss: 1.0952\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [4/100], loss: 1.0938\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [5/100], loss: 1.0909\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [6/100], loss: 1.0888\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [7/100], loss: 1.0857\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [8/100], loss: 1.0839\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [9/100], loss: 1.0815\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [10/100], loss: 1.0800\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [11/100], loss: 1.0774\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [12/100], loss: 1.0753\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [13/100], loss: 1.0731\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [14/100], loss: 1.0722\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [15/100], loss: 1.0698\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [16/100], loss: 1.0680\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [17/100], loss: 1.0663\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [18/100], loss: 1.0644\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [19/100], loss: 1.0626\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [20/100], loss: 1.0603\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [21/100], loss: 1.0586\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [22/100], loss: 1.0580\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [23/100], loss: 1.0560\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [24/100], loss: 1.0539\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [25/100], loss: 1.0524\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [26/100], loss: 1.0509\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [27/100], loss: 1.0498\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [28/100], loss: 1.0485\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [29/100], loss: 1.0460\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [30/100], loss: 1.0442\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [31/100], loss: 1.0452\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [32/100], loss: 1.0414\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [33/100], loss: 1.0416\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [34/100], loss: 1.0404\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [35/100], loss: 1.0378\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [36/100], loss: 1.0358\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [37/100], loss: 1.0352\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [38/100], loss: 1.0338\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [39/100], loss: 1.0325\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [40/100], loss: 1.0301\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [41/100], loss: 1.0291\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [42/100], loss: 1.0278\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [43/100], loss: 1.0285\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [44/100], loss: 1.0260\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [45/100], loss: 1.0228\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [46/100], loss: 1.0244\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [47/100], loss: 1.0227\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [48/100], loss: 1.0217\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [49/100], loss: 1.0194\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [50/100], loss: 1.0171\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [51/100], loss: 1.0167\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [52/100], loss: 1.0170\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [53/100], loss: 1.0139\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [54/100], loss: 1.0150\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [55/100], loss: 1.0128\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [56/100], loss: 1.0128\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [57/100], loss: 1.0094\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [58/100], loss: 1.0100\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [59/100], loss: 1.0095\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [60/100], loss: 1.0111\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [61/100], loss: 1.0055\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [62/100], loss: 1.0039\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [63/100], loss: 1.0059\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [64/100], loss: 1.0000\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [65/100], loss: 1.0026\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [66/100], loss: 1.0028\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [67/100], loss: 1.0015\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [68/100], loss: 1.0021\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [69/100], loss: 0.9999\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [70/100], loss: 1.0030\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [71/100], loss: 1.0006\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [72/100], loss: 1.0020\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [73/100], loss: 0.9993\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [74/100], loss: 1.0005\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [75/100], loss: 0.9988\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [76/100], loss: 0.9999\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [77/100], loss: 1.0004\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [78/100], loss: 0.9998\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [79/100], loss: 1.0021\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [80/100], loss: 0.9981\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [81/100], loss: 0.9972\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [82/100], loss: 0.9999\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [83/100], loss: 1.0005\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [84/100], loss: 0.9980\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [85/100], loss: 0.9974\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [86/100], loss: 0.9947\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [87/100], loss: 0.9975\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [88/100], loss: 0.9991\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [89/100], loss: 0.9967\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [90/100], loss: 0.9968\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [91/100], loss: 1.0029\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [92/100], loss: 0.9970\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [93/100], loss: 0.9956\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [94/100], loss: 0.9943\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [95/100], loss: 0.9960\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [96/100], loss: 0.9955\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [97/100], loss: 0.9937\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [98/100], loss: 0.9971\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [99/100], loss: 0.9972\n",
      "torch.Size([64, 10, 2])\n",
      "Epoch [100/100], loss: 0.9955\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#seq2seq for time series prediction\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, dropout=self.dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input shape: (batch_size, seq_len, input_dim)\n",
    "        # output shape: (batch_size, seq_len, hidden_dim)\n",
    "        # hidden shape: (n_layers, batch_size, hidden_dim)\n",
    "        # cell shape: (n_layers, batch_size, hidden_dim)\n",
    "        output, (hidden, cell) = self.lstm(input)\n",
    "        return output, hidden, cell\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, n_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, n_layers, dropout=self.dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input shape: (batch_size, 1, input_dim)\n",
    "        # hidden shape: (n_layers, batch_size, hidden_dim)\n",
    "        # cell shape: (n_layers, batch_size, hidden_dim)\n",
    "        # output shape: (batch_size, 1, hidden_dim)\n",
    "        output, (hidden, cell) = self.lstm(input, (hidden, cell))\n",
    "        # output shape: (batch_size, output_dim)\n",
    "        output = output.squeeze(1)\n",
    "        return output, hidden, cell\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.fc = nn.Linear(decoder.hidden_dim, decoder.output_dim)\n",
    "        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # input shape: (batch_size, seq_len, input_dim)\n",
    "        batch_size = input.shape[0]\n",
    "        seq_len = input.shape[1]\n",
    "        output_dim = self.decoder.output_dim\n",
    "        outputs = torch.zeros(batch_size, seq_len, output_dim).to(self.device)\n",
    "        encoder_output, hidden, cell = self.encoder(input)\n",
    "        # decoder_input shape: (batch_size, 1, output_dim)\n",
    "        # use encoder_output as the first input to the decoder\n",
    "        decoder_input = encoder_output[:, 0, :].unsqueeze(1)\n",
    "        for t in range(seq_len):\n",
    "            decoder_output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs[:, t, :] = self.fc(decoder_output)\n",
    "            decoder_input = decoder_output.unsqueeze(1)\n",
    "        return outputs\n",
    "    \n",
    "#generate random data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#generate time series data\n",
    "#X is of shape (batch_size, seq_len, input_dim)\n",
    "#y is of shape (batch_size, seq_len, output_dim)\n",
    "def generate_data(batch_size, seq_len, input_dim, output_dim):\n",
    "    X = np.random.randn(batch_size, seq_len, input_dim)\n",
    "    y = np.random.randn(batch_size, seq_len, output_dim)\n",
    "    return X, y\n",
    "\n",
    "#generate data\n",
    "batch_size = 64\n",
    "seq_len = 10\n",
    "input_dim = 5\n",
    "output_dim = 2\n",
    "X, y = generate_data(batch_size, seq_len, input_dim, output_dim)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#train model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = Encoder(input_dim, hidden_dim=10, n_layers=2, dropout=0.5)\n",
    "decoder = Decoder(output_dim, hidden_dim=10, n_layers=2, dropout=0.5)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    input = torch.from_numpy(X).float().to(device)\n",
    "    target = torch.from_numpy(y).float().to(device)\n",
    "    output = model(input)\n",
    "    print(output.shape)\n",
    "    loss = criterion(output, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Epoch [{}/{}], loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
