{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(True))\n",
    "        self.mu = nn.Linear(hidden_size, latent_size)\n",
    "        self.logvar = nn.Linear(hidden_size, latent_size)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps*std\n",
    "        x = self.decoder(z)\n",
    "        return x, mu, logvar\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = torch.randn(100, 784)\n",
    "model = Autoencoder(input_size=784, hidden_size=400, latent_size=20)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in range(100):\n",
    "    X_hat = model(X)\n",
    "    loss = F.mse_loss(X_hat, X)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "X = torch.randn(100, 784)\n",
    "model = VAE(input_size=784, hidden_size=400, latent_size=20)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in range(100):\n",
    "    X_hat, mu, logvar = model(X)\n",
    "    loss = F.mse_loss(X_hat, X) + 0.5 * torch.sum(torch.exp(logvar) + mu**2 - 1. - logvar)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "X = torch.randn(100, 784)\n",
    "Y = torch.randn(100, 784)\n",
    "model = GAN(input_size=784, hidden_size=400, latent_size=20)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in range(100):\n",
    "    X_hat, mu, logvar, D = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN model for 1D time series data, with the goal of predicting the next time step\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GAN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.input_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.output_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.input_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        x = self.forward(x)\n",
    "        return F.mse_loss(x, y)\n",
    "    \n",
    "    def train(self, x, y, epochs=1000, lr=0.01):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss(x, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch: {} Loss: {}'.format(epoch, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
