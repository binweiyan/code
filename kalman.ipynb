{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pykalman2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpylab\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpykalman2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpykalman\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_robot\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpykalman\u001b[39;00m \u001b[39mimport\u001b[39;00m KalmanFilter\n\u001b[1;32m      7\u001b[0m \u001b[39m# Load data and initialize Kalman Filter\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pykalman2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "from pykalman2.pykalman.datasets import load_robot\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Load data and initialize Kalman Filter\n",
    "data = load_robot()\n",
    "kf = KalmanFilter(\n",
    "    data.transition_matrix,\n",
    "    data.observation_matrix,\n",
    "    data.initial_transition_covariance,\n",
    "    data.initial_observation_covariance,\n",
    "    data.transition_offsets,\n",
    "    data.observation_offset,\n",
    "    data.initial_state_mean,\n",
    "    data.initial_state_covariance,\n",
    "    em_vars=[\n",
    "      'transition_matrices', 'observation_matrices',\n",
    "      'transition_covariance', 'observation_covariance',\n",
    "      'observation_offsets', 'initial_state_mean',\n",
    "      'initial_state_covariance'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Learn good values for parameters named in `em_vars` using the EM algorithm\n",
    "loglikelihoods = np.zeros(10)\n",
    "for i in range(len(loglikelihoods)):\n",
    "    kf = kf.em(X=data.observations, n_iter=1)\n",
    "    loglikelihoods[i] = kf.loglikelihood(data.observations)\n",
    "\n",
    "# Estimate the state without using any observations.  This will let us see how\n",
    "# good we could do if we ran blind.\n",
    "n_dim_state = data.transition_matrix.shape[0]\n",
    "n_timesteps = data.observations.shape[0]\n",
    "blind_state_estimates = np.zeros((n_timesteps, n_dim_state))\n",
    "for t in range(n_timesteps - 1):\n",
    "    if t == 0:\n",
    "        blind_state_estimates[t] = kf.initial_state_mean\n",
    "    blind_state_estimates[t + 1] = (\n",
    "      np.dot(kf.transition_matrices, blind_state_estimates[t])\n",
    "      + kf.transition_offsets[t]\n",
    "    )\n",
    "\n",
    "# Estimate the hidden states using observations up to and including\n",
    "# time t for t in [0...n_timesteps-1].  This method outputs the mean and\n",
    "# covariance characterizing the Multivariate Normal distribution for\n",
    "#   P(x_t | z_{1:t})\n",
    "filtered_state_estimates = kf.filter(data.observations)[0]\n",
    "\n",
    "# Estimate the hidden states using all observations.  These estimates\n",
    "# will be 'smoother' (and are to be preferred) to those produced by\n",
    "# simply filtering as they are made with later observations in mind.\n",
    "# Probabilistically, this method produces the mean and covariance\n",
    "# characterizing,\n",
    "#    P(x_t | z_{1:n_timesteps})\n",
    "smoothed_state_estimates = kf.smooth(data.observations)[0]\n",
    "\n",
    "# Draw the true, blind,e filtered, and smoothed state estimates for all 5\n",
    "# dimensions.\n",
    "pl.figure(figsize=(16, 6))\n",
    "lines_true = pl.plot(data.states, linestyle='-', color='b')\n",
    "lines_blind = pl.plot(blind_state_estimates, linestyle=':', color='m')\n",
    "lines_filt = pl.plot(filtered_state_estimates, linestyle='--', color='g')\n",
    "lines_smooth = pl.plot(smoothed_state_estimates, linestyle='-.', color='r')\n",
    "pl.legend(\n",
    "    (lines_true[0], lines_blind[0], lines_filt[0], lines_smooth[0]),\n",
    "    ('true', 'blind', 'filtered', 'smoothed')\n",
    ")\n",
    "pl.xlabel('time')\n",
    "pl.ylabel('state')\n",
    "pl.xlim(xmax=500)\n",
    "\n",
    "# Draw log likelihood of observations as a function of EM iteration number.\n",
    "# Notice how it is increasing (this is guaranteed by the EM algorithm)\n",
    "pl.figure()\n",
    "pl.plot(loglikelihoods)\n",
    "pl.xlabel('em iteration number')\n",
    "pl.ylabel('log likelihood')\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
