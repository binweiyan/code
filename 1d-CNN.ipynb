{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 1d cnn model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1d(nn.Module):\n",
    "    #create a 1d cnn regression model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, kernel_size, layer_num, hidden_size,\n",
    "                  dropout=0.5, batch_norm=True):\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        super(CNN1d, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layer_num = layer_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.batch_norm = batch_norm\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(self.input_dim, self.hidden_size, self.kernel_size)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(self.hidden_size)])\n",
    "        for i in range(self.layer_num - 1):\n",
    "            self.convs.append(nn.Conv1d(self.hidden_size, self.hidden_size, self.kernel_size))\n",
    "            self.bns.append(nn.BatchNorm1d(self.hidden_size))\n",
    "        self.fc1 = nn.Linear(self.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        for conv in self.convs:\n",
    "            torch.nn.init.xavier_uniform_(conv.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        #output shape: (batch_size, 1)\n",
    "        x = x.transpose(1, 2)\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if self.batch_norm:\n",
    "                x = F.relu(self.bns[i](conv(x)))\n",
    "            else:\n",
    "                x = F.relu(conv(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc1(x[:, :, -1])\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        #predict the target value\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        #calculate loss\n",
    "        return F.mse_loss(self.forward(x), y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positional encoding\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #add positional encoding to the input\n",
    "    def __init__(self, input_len, input_dim, dropout=0.5):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pe = torch.zeros(self.input_len, self.input_dim)\n",
    "        position = torch.arange(0, self.input_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.input_dim, 2).float() * (-math.log(10000.0) / self.input_dim))\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0)\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        #output shape: (batch_size, input_len, input_dim)\n",
    "        x = x + self.pe\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    #create MULTIHEADATTENTION model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, num_heads, dropout=0.5):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.q_linear = nn.Linear(self.input_dim, self.hidden_size)\n",
    "        self.v_linear = nn.Linear(self.input_dim, self.hidden_size)\n",
    "        self.k_linear = nn.Linear(self.input_dim, self.hidden_size)\n",
    "        self.multihead_attn = nn.MultiheadAttention(self.hidden_size, self.num_heads)\n",
    "        self.out = nn.Linear(self.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #use positional encoding\n",
    "        x = PositionalEncoding(self.input_len, self.input_dim)(x)\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "        q = self.q_linear(x)\n",
    "        k = self.k_linear(x)\n",
    "        v = self.v_linear(x)\n",
    "        attn_output, _ = self.multihead_attn(q, k, v)\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        output = self.out(attn_output[:, -1, :])\n",
    "        return output\n",
    "\n",
    "    def predict(self, x):\n",
    "        #predict the target value\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        #calculate loss\n",
    "        return F.mse_loss(self.forward(x), y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 1000\n",
    "#test the model\n",
    "X = torch.randn(num_samples, 10)\n",
    "Y = torch.randn(num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "day = torch.randint(0, 30, (num_samples, 1))\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y, day, input_len=128):\n",
    "        #the input data is a 1d array, indicate the minute of the day\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.day = day\n",
    "        self.input_len = input_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #output previous self.input_len minutes data and target value\n",
    "        #if the there is no enough data in the same day, pad with 0\n",
    "        d = self.day[index]\n",
    "        start = index - self.input_len\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if self.day[start] != d:\n",
    "            while self.day[start] != d:\n",
    "                start += 1\n",
    "            #pad with 0 before start\n",
    "        if index - start < self.input_len:\n",
    "            x = torch.zeros(self.input_len, 10)\n",
    "            x[self.input_len - index + start: self.input_len] = self.X[start: index].clone()\n",
    "        else:\n",
    "            x = self.X[start: index]\n",
    "            \n",
    "        y = self.y[index].clone()\n",
    "        if x.shape != (self.input_len, 10):\n",
    "            print(x.shape, index, start)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "mydataset = MyDataset(X, Y, day, input_len=128)\n",
    "train_index = range(0, int(num_samples * 0.8))\n",
    "test_index = range(0, int(num_samples * 0.8))\n",
    "#test_index = range(int(num_samples * 0.8), num_samples)\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(mydataset, train_index)\n",
    "test_dataset = torch.utils.data.Subset(mydataset, test_index)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model with 4 GPUs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "model = Attention(input_len=128, input_dim=10, hidden_size=128, num_heads=8, dropout=0.5)\n",
    "model = DataParallel(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.module.loss(x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, loss.item())\n",
    "\n",
    "#the number of gpu \n",
    "print(torch.cuda.device_count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error initializing torch.distributed using env:// rendezvous: environment variable MASTER_ADDR expected, but not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dist\u001b[39m.\u001b[39;49minit_process_group(\u001b[39m\"\u001b[39;49m\u001b[39mnccl\u001b[39;49m\u001b[39m\"\u001b[39;49m, rank\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, world_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m dist\u001b[39m.\u001b[39mget_rank()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:595\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m store \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m     rendezvous_iterator \u001b[39m=\u001b[39m rendezvous(\n\u001b[1;32m    593\u001b[0m         init_method, rank, world_size, timeout\u001b[39m=\u001b[39mtimeout\n\u001b[1;32m    594\u001b[0m     )\n\u001b[0;32m--> 595\u001b[0m     store, rank, world_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(rendezvous_iterator)\n\u001b[1;32m    596\u001b[0m     store\u001b[39m.\u001b[39mset_timeout(timeout)\n\u001b[1;32m    598\u001b[0m     \u001b[39m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m    599\u001b[0m     \u001b[39m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/distributed/rendezvous.py:254\u001b[0m, in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     world_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(_get_env_or_raise(\u001b[39m\"\u001b[39m\u001b[39mWORLD_SIZE\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 254\u001b[0m master_addr \u001b[39m=\u001b[39m _get_env_or_raise(\u001b[39m\"\u001b[39;49m\u001b[39mMASTER_ADDR\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    255\u001b[0m master_port \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(_get_env_or_raise(\u001b[39m\"\u001b[39m\u001b[39mMASTER_PORT\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    257\u001b[0m store \u001b[39m=\u001b[39m _create_c10d_store(master_addr, master_port, rank, world_size, timeout)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/distributed/rendezvous.py:232\u001b[0m, in \u001b[0;36m_env_rendezvous_handler.<locals>._get_env_or_raise\u001b[0;34m(env_var)\u001b[0m\n\u001b[1;32m    230\u001b[0m env_val \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(env_var, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m env_val:\n\u001b[0;32m--> 232\u001b[0m     \u001b[39mraise\u001b[39;00m _env_error(env_var)\n\u001b[1;32m    233\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[39mreturn\u001b[39;00m env_val\n",
      "\u001b[0;31mValueError\u001b[0m: Error initializing torch.distributed using env:// rendezvous: environment variable MASTER_ADDR expected, but not set"
     ]
    }
   ],
   "source": [
    "dis\n",
    "dist.init_process_group(\"nccl\", rank=0, world_size=4)\n",
    "dist.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scores(pred, target, days):\n",
    "#     pred_group, ground_group, corr = groupbyday(pred, target, days)\n",
    "#     sharpes = sharpeyear(corr, list(pred_group.keys()))\n",
    "#     return corr.mean(), sharpes\n",
    "    \n",
    "# def fitmodel(model, training_data, test_data, training_target, test_target, training_days, test_days):\n",
    "#     for train, test, train_target, test_target, train_day, test_day in zip(training_data, test_data, training_target, test_target, training_days, test_days):\n",
    "#         model.fit(train, train_target)\n",
    "#         pred_train = model.predict(train)\n",
    "#         pred_test = model.predict(test)\n",
    "#         pnl_train, sharpe_train = scores(pred_train, train_target,train_day)\n",
    "#         pnl_test, sharpe_test = scores(pred_test, test_target, test_day)\n",
    "#         return pnl_train, sharpe_train, pnl_test, sharpe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = Attention(input_dim=10, input_len=128, hidden_size=64, num_heads=8)\n",
    "\n",
    "def trainmodel(model, data, target, days, train_index, test_index, epochs=100):\n",
    "    #get dataset\n",
    "    mydataset = MyDataset(data, target, days)\n",
    "    train_index = range(0, int(num_samples * 0.8))\n",
    "    test_index = range(int(num_samples * 0.8), num_samples)\n",
    "\n",
    "    train_dataset = torch.utils.data.Subset(mydataset, train_index)\n",
    "    test_dataset = torch.utils.data.Subset(mydataset, test_index)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "    #train the model\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(x, y)\n",
    "            correlation = torch.sum(torch.mul(model.predict(x), y)) / torch.sqrt(torch.sum(torch.pow(model.predict(x), 2)) * torch.sum(torch.pow(y, 2)))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(\"epoch: {}, loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "        #evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                x, y = data\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                loss = model.loss(x, y)\n",
    "                print(\"test loss: {}\".format(loss.item()))\n",
    "    \n",
    "    pred = torch.zeros(len(test_dataset), 1)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred[i * 128: i * 128 + len(x)] = model.predict(x)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 481 is out of bounds for dimension 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainmodel(model, X, y, day, train_index, test_index, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[118], line 20\u001b[0m, in \u001b[0;36mtrainmodel\u001b[0;34m(model, data, target, days, train_index, test_index, epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m scheduler \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     21\u001b[0m         x, y \u001b[39m=\u001b[39m data\n\u001b[1;32m     22\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "Cell \u001b[0;32mIn[100], line 29\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX[start: index]\n\u001b[0;32m---> 29\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my[index]\u001b[39m.\u001b[39mclone()\n\u001b[1;32m     30\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_len, \u001b[39m10\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape, index, start)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 481 is out of bounds for dimension 0 with size 32"
     ]
    }
   ],
   "source": [
    "trainmodel(model, X, y, day, train_index, test_index, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a zero tensor in gpu\n",
    "x = torch.zeros(10, 10)\n",
    "#to device y is current in cpu\n",
    "y = torch.randn(10, 10)\n",
    "y = y.to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Attention' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Attention' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Attention' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Attention' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Attention' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Attention' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Attention' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m results \u001b[39m=\u001b[39m [pool\u001b[39m.\u001b[39mapply_async(model\u001b[39m.\u001b[39mpredict, args\u001b[39m=\u001b[39m(data[\u001b[39m0\u001b[39m],)) \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m test_loader]\n\u001b[0;32m---> 12\u001b[0m output \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mget() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m results]\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start)\n",
      "Cell \u001b[0;32mIn[130], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m results \u001b[39m=\u001b[39m [pool\u001b[39m.\u001b[39mapply_async(model\u001b[39m.\u001b[39mpredict, args\u001b[39m=\u001b[39m(data[\u001b[39m0\u001b[39m],)) \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m test_loader]\n\u001b[0;32m---> 12\u001b[0m output \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39;49mget() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m results]\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#evaluate the model with multiprocessing on cpu\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "model = Attention(input_dim=10, input_len=128, hidden_size=64, num_heads=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "#multiprocessing\n",
    "pool = mp.Pool(processes=4)\n",
    "start = time.time()\n",
    "results = [pool.apply_async(model.predict, args=(data[0],)) for i, data in test_loader]\n",
    "output = [p.get() for p in results]\n",
    "print(time.time() - start)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
