{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 1d cnn model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1d(nn.Module):\n",
    "    #create a 1d cnn regression model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, kernel_size, layer_num, hidden_size,\n",
    "                  dropout=0.5, batch_norm=True):\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        super(CNN1d, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layer_num = layer_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.batch_norm = batch_norm\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(self.input_dim, self.hidden_size, self.kernel_size, padding=self.kernel_size // 2)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(self.hidden_size)])\n",
    "        for i in range(self.layer_num - 1):\n",
    "            self.convs.append(nn.Conv1d(self.hidden_size, self.hidden_size, self.kernel_size, padding=self.kernel_size // 2))\n",
    "            self.bns.append(nn.BatchNorm1d(self.hidden_size))\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_len * self.hidden_size, 74)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        for conv in self.convs:\n",
    "            torch.nn.init.xavier_uniform_(conv.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        #output shape: (batch_size, 1)\n",
    "        x = x.transpose(1, 2)\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if self.batch_norm:\n",
    "                x = F.relu(self.bns[i](conv(x)))\n",
    "            else:\n",
    "                x = F.relu(conv(x))\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = x.view(-1, (self.input_len * self.hidden_size))\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        #predict the target value\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        #calculate loss\n",
    "        return F.mse_loss(self.forward(x), y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positional encoding\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #add positional encoding to the input\n",
    "    def __init__(self, input_len, input_dim, dropout=0.5):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pe = torch.zeros(self.input_len, self.input_dim)\n",
    "        position = torch.arange(0, self.input_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.input_dim, 2).float() * (-math.log(10000.0) / self.input_dim))\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0)\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        #output shape: (batch_size, input_len, input_dim)\n",
    "        x = x + self.pe\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    #create MULTIHEADATTENTION model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, num_heads, layer_num, dropout=0.5):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        #embedding\n",
    "\n",
    "        self.embedding = nn.Linear(self.input_dim, self.hidden_size)\n",
    "        self.q_linears = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for i in range(self.layer_num)])\n",
    "        self.k_linears = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for i in range(self.layer_num)])\n",
    "        self.v_linears = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for i in range(self.layer_num)])\n",
    "        self.multihead_attns = nn.ModuleList([nn.MultiheadAttention(self.hidden_size, self.num_heads) for i in range(self.layer_num)])\n",
    "        self.norms = nn.ModuleList([nn.BatchNorm1d(self.input_len) for i in range(self.layer_num)])\n",
    "        self.out = nn.Linear(self.hidden_size * self.input_len, 74)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pe = torch.zeros(self.input_len, self.hidden_size)\n",
    "        position = torch.arange(0, self.input_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_size, 2).float() * (-math.log(10000.0) / self.hidden_size))\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0)\n",
    "        self.pe.requires_grad = False\n",
    "        self.init_weights()\n",
    "        self.mean = nn.Parameter(torch.zeros(74))\n",
    "        self.std = nn.Parameter(torch.ones(74))\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.out.weight)\n",
    "        \n",
    "    def positional_encoding(self, x):\n",
    "        #use positional encoding\n",
    "        x = x + self.pe.to(x.device)\n",
    "        return self.dropout(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        #use positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "        for i in range(self.layer_num):\n",
    "            q = self.q_linears[i](x)\n",
    "            k = self.k_linears[i](x)\n",
    "            v = self.v_linears[i](x)\n",
    "            x, _ = self.multihead_attns[i](q, k, v)\n",
    "            x = self.norms[i](x)\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(bs, -1)\n",
    "        x = self.out(x)\n",
    "        x = (x - self.mean) / self.std\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        #calculate loss\n",
    "        return F.mse_loss(self.forward(x), y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 1000\n",
    "#test the model\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "Y = torch.randn(num_samples, 74)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "day = torch.randint(0, 30, (num_samples, 1))\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y, day, input_len=128):\n",
    "        #the input data is a 1d array, indicate the minute of the day\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.day = day\n",
    "        self.input_len = input_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #output previous self.input_len minutes data and target value\n",
    "        #if the there is no enough data in the same day, pad with 0\n",
    "        d = self.day[index]\n",
    "        start = index - self.input_len\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if self.day[start] != d:\n",
    "            while self.day[start] != d:\n",
    "                start += 1\n",
    "            #pad with 0 before start\n",
    "        if index - start < self.input_len:\n",
    "            x = torch.zeros(self.input_len, self.X.shape[1])\n",
    "            x[self.input_len - index + start: self.input_len] = self.X[start: index].clone()\n",
    "        else:\n",
    "            x = self.X[start: index]\n",
    "            \n",
    "        y = self.y[index].clone()\n",
    "        if x.shape != (self.input_len, self.X.shape[1]):\n",
    "            print(x.shape, index, start)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "mydataset = MyDataset(X, Y, day, input_len=120)\n",
    "train_index = range(0, int(num_samples * 0.8))\n",
    "test_index = range(0, int(num_samples * 0.8))\n",
    "#test_index = range(int(num_samples * 0.8), num_samples)\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(mydataset, train_index)\n",
    "test_dataset = torch.utils.data.Subset(mydataset, test_index)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 74, 3], expected input[128, 296, 120] to have 74 channels, but got 296 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m     p \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     20\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(p, y) \u001b[39m+\u001b[39m \u001b[39m0.01\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msum(model\u001b[39m.\u001b[39mfc1\u001b[39m.\u001b[39mweight \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m     21\u001b[0m     prediction\u001b[39m.\u001b[39mappend(p)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m, in \u001b[0;36mCNN1d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m i, conv \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_norm:\n\u001b[0;32m---> 44\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbns[i](conv(x)))\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(conv(x))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    304\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 74, 3], expected input[128, 296, 120] to have 74 channels, but got 296 channels instead"
     ]
    }
   ],
   "source": [
    "#train the model with 4 GPUs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "model = CNN1d(input_len=120, input_dim=74, kernel_size=3, layer_num=3, hidden_size=128, dropout=0.5, batch_norm=True)\n",
    "def correlation_t(x, y):\n",
    "    return torch.sum(x * y) / (torch.sqrt(torch.sum(x * x)) * torch.sqrt(torch.sum(y * y)))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    prediction = []\n",
    "    ground_truth = []\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        p = model(x)\n",
    "        loss = F.mse_loss(p, y) + 0.01 * torch.sum(model.fc1.weight ** 2)\n",
    "        prediction.append(p)\n",
    "        ground_truth.append(y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, loss.item())\n",
    "    prediction = torch.cat(prediction, dim=0)\n",
    "    ground_truth = torch.cat(ground_truth, dim=0)\n",
    "    print(prediction.shape, ground_truth.shape)\n",
    "    print(epoch, correlation_t(prediction, ground_truth).item())\n",
    "\n",
    "#the number of gpu \n",
    "print(torch.cuda.device_count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    #create MLP model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, layer_num, dropout=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        #embedding\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_dim, self.hidden_size)])\n",
    "        self.norms = nn.ModuleList([nn.BatchNorm1d(self.input_len)])\n",
    "\n",
    "        for i in range(self.layer_num - 1):\n",
    "            self.linears.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            self.norms.append(nn.BatchNorm1d(self.input_len))\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size * self.input_len, 74)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "        self.mean = nn.Parameter(torch.zeros(74))\n",
    "        self.std = nn.Parameter(torch.ones(74))\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "\n",
    "        for i in range(self.layer_num):\n",
    "            x = self.linears[i](x)\n",
    "            x = self.norms[i](x)\n",
    "            x = self.dropout(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = x.view(bs, -1)\n",
    "        x = self.out(x)\n",
    "        x = (x - self.mean) / self.std\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    #create RNN model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, layer_num, dropout=0.5, bidirectional=True):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        #embedding\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn = nn.GRU(self.input_dim, self.hidden_size, self.layer_num, batch_first=True, dropout=self.dropout, bidirectional = self.bidirectional)\n",
    "        self.out = nn.Linear(self.hidden_size * (1 + int(self.bidirectional)), 74)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "        x, hn = self.rnn(x)\n",
    "        h = hn[-(1 + int(self.bidirectional)):]\n",
    "        x = torch.cat(h.split(1), dim=-1).squeeze(0)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.0544946193695068\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m prediction\u001b[39m.\u001b[39mappend(p)\n\u001b[1;32m     15\u001b[0m ground_truth\u001b[39m.\u001b[39mappend(y)\n\u001b[0;32m---> 16\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RNN(input_len=120, input_dim=296, hidden_size=128, layer_num=3, dropout=0.5)\n",
    "def correlation_t(x, y):\n",
    "    return torch.sum(x * y) / (torch.sqrt(torch.sum(x * x)) * torch.sqrt(torch.sum(y * y)))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    prediction = []\n",
    "    ground_truth = []\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        p = model(x)\n",
    "        loss = F.mse_loss(p, y)\n",
    "        prediction.append(p)\n",
    "        ground_truth.append(y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, loss.item())\n",
    "    prediction = torch.cat(prediction, dim=0)\n",
    "    ground_truth = torch.cat(ground_truth, dim=0)\n",
    "    print(prediction.shape, ground_truth.shape)\n",
    "    print(epoch, correlation_t(prediction, ground_truth).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    #create LSTM model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, layer_num, dropout=0.5, bidirectional=True):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        #embedding\n",
    "        self.bidirectional = bidirectional\n",
    "        #activation function\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_size, self.layer_num, batch_first=True, dropout=self.dropout, bidirectional = self.bidirectional,\n",
    "                            activation='relu')\n",
    "        self.out = nn.Linear(self.hidden_size * (1 + int(self.bidirectional)), 74)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "        _, (hn, _)= self.lstm(x)\n",
    "        h = hn[-(1 + int(self.bidirectional)):]\n",
    "        x = torch.cat(h.split(1), dim=-1).squeeze(0)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.031086802482605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m     p \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     13\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(p, y)\n\u001b[1;32m     14\u001b[0m     prediction\u001b[39m.\u001b[39mappend(p)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[22], line 26\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     24\u001b[0m     \u001b[39m#forward pass\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     bs \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     x, (hn, cn)\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[1;32m     27\u001b[0m     h \u001b[39m=\u001b[39m hn[\u001b[39m-\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)):]\n\u001b[1;32m     28\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(h\u001b[39m.\u001b[39msplit(\u001b[39m1\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:769\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    770\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    771\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    773\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LSTM(input_len=120, input_dim=296, hidden_size=128, layer_num=3, dropout=0.5)\n",
    "def correlation_t(x, y):\n",
    "    return torch.sum(x * y) / (torch.sqrt(torch.sum(x * x)) * torch.sqrt(torch.sum(y * y)))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    prediction = []\n",
    "    ground_truth = []\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        p = model(x)\n",
    "        loss = F.mse_loss(p, y)\n",
    "        prediction.append(p)\n",
    "        ground_truth.append(y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, loss.item())\n",
    "    prediction = torch.cat(prediction, dim=0)\n",
    "    ground_truth = torch.cat(ground_truth, dim=0)\n",
    "    print(prediction.shape, ground_truth.shape)\n",
    "    print(epoch, correlation_t(prediction, ground_truth).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/rdd16gz922j8hc9s9c737lpw0000gr/T/ipykernel_67180/38055778.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree models random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "Y = torch.randn(num_samples, 1)\n",
    "X = X.numpy()\n",
    "Y = Y.numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "#multiprocessing\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=0, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear classifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "# 4 classes\n",
    "Y = torch.randint(0, 4, (num_samples, 1))\n",
    "X = X.numpy()\n",
    "Y = Y.numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:59:59\n"
     ]
    }
   ],
   "source": [
    "#'04:00:00' to int\n",
    "def time_to_int(time):\n",
    "    #convert time to int\n",
    "    #input time format: '04:00:00'\n",
    "    #output int\n",
    "    h, m, s = time.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "#int to '04:00:00'\n",
    "def int_to_time(i):\n",
    "    #convert int to time\n",
    "    #input int\n",
    "    #output time format: '04:00:00'\n",
    "    h = i // 3600\n",
    "    m = (i - h * 3600) // 60\n",
    "    s = i - h * 3600 - m * 60\n",
    "    return '%02d:%02d:%02d' % (h, m, s)\n",
    "\n",
    "#convert time to int\n",
    "a = time_to_int('04:00:00')\n",
    "a -= 1\n",
    "print(int_to_time(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the std of the previous 60 minutes\n",
    "#nan to 0 in np array\n",
    "#inf to 0 in np array\n",
    "#-inf to 0 in np array\n",
    "x = np.array([1, 2, 3, np.nan])\n",
    "x[np.isnan(x)] = 0\n",
    "x[np.isinf(x)] = 0\n",
    "x[np.isneginf(x)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([1, 1, np.inf, np.nan, -np.inf])\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each row, normalize the mean and std of the previous 100 rows\n",
    "df = pd.DataFrame(np.random.randn(1000, 3))\n",
    "std = df.rolling(100).std().fillna(df.std())\n",
    "mean = df.rolling(100).mean().fillna(df.mean())\n",
    "df = (df - mean) / std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.zeros((1, 2)), np.ones((1, 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(np.random.randn(1000, 3))\n",
    "#assign [1, 5, 6] to each row\n",
    "df.values[:] = [1, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(max_depth=10, max_iter=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(max_depth=10, max_iter=1000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(max_depth=10, max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost Regressor\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "Y = torch.randn(num_samples, 1)\n",
    "X = X.numpy()\n",
    "Y = Y.numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "clf = HistGradientBoostingRegressor(max_iter=1000, learning_rate=0.1, max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "num_samples = 1000\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "Y = torch.randn(num_samples, 1)\n",
    "X = X.numpy()\n",
    "Y = Y.numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "param = {'num_leaves': 31, 'objective': 'regression', 'metric': 'l2'}\n",
    "num_round = 1000\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(5, 3))\n",
    "df.index = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].index = [1, 2, 3, 1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = df[1]\n",
    "u.index = [1, 2, 3, 1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval =  ['04:00:00', '05:00:00', '06:00:00', '07:00:00']\n",
    "X = np.random.randn(4, 74)\n",
    "Y = np.random.randn(4, 1)\n",
    "#insert every minute into interval and fill corresponding position of X and Y with 0\n",
    "def insert_interval(X, Y, interval):\n",
    "    #insert every minute into interval and fill corresponding position of X and Y with 0\n",
    "    #output X and Y\n",
    "    X = pd.DataFrame(X)\n",
    "    Y = pd.DataFrame(Y)\n",
    "\n",
    "    #invert interval to int\n",
    "    interval_t = [time_to_int(i) for i in interval]\n",
    "    X.index = interval_t\n",
    "    Y.index = interval_t\n",
    "\n",
    "    #insert every minute into interval and fill corresponding position of X and Y with 0\n",
    "    X = X.reindex(range(interval_t[0], interval_t[-1] + 1, 60)).fillna(0)\n",
    "    Y = Y.reindex(range(interval_t[0], interval_t[-1] + 1, 60)).fillna(0)\n",
    "    #position of interval_t in X.index\n",
    "    pos = [X.index.get_loc(i) for i in interval_t]\n",
    "\n",
    "    return list(X.index), X.values, Y.values, pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.0.0.tar.gz (1.7 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from lightgbm) (1.10.0)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightgbm: filename=lightgbm-4.0.0-py3-none-macosx_13_0_arm64.whl size=1311735 sha256=0e08c39900e3169ae5ed39eda71385638edcb98c6da26e25b32358c348d3483d\n",
      "  Stored in directory: /Users/binweiyan/Library/Caches/pip/wheels/87/b8/97/383847beeac44a4247d7c7f350f34f0dca66bbd9bc13e02403\n",
      "Successfully built lightgbm\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval, X, Y, pos = insert_interval(X, Y, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interval_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(interval_t)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'interval_t' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(interval_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m5\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "#add 5 to all the elements in l\n",
    "l = [1, 2, 3]\n",
    "l = [i + 5 for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(4, 74)\n",
    "index = [1, 2]\n",
    "X[index][:,range(8)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/rdd16gz922j8hc9s9c737lpw0000gr/T/ipykernel_94237/3180936425.py:5: RuntimeWarning: invalid value encountered in power\n",
      "  X = np.random.normal(0, 1, 100000) ** 1.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsNklEQVR4nO3df3RU9Z3/8dc0IRFocksCmWGOQWObRTBoNbhhol3YAgGWmHrcI9joLB5YwAOCU2D5oXtO0WMTwSPY3awsUA8o4Ilnj8a6FSNx28ayIRDTzhYQ0R5RoWQIdodJoOkEw/3+4ZfbHYLIJKGTz/B8nHPPce59z533BzhnXn7u595x2bZtCwAAwDBfS3QDAAAAPUGIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYKTXRDVwp586d0/Hjx5WRkSGXy5XodgAAwGWwbVvt7e3yer362tcuPdeStCHm+PHjys3NTXQbAACgB44ePaprr732kjVJG2IyMjIkffGHkJmZmeBuAADA5Whra1Nubq7zPX4pSRtizl9CyszMJMQAAGCYy1kKwsJeAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACOlJroBU12/8o2Y1x8/NT1BnQAAcHViJgYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASHGFmOuvv14ul6vbtnDhQkmSbdtavXq1vF6vBg4cqAkTJujgwYMx54hGo1q0aJGGDh2qwYMHq6ysTMeOHYupCYfD8vv9sixLlmXJ7/fr1KlTvRspAABIKnGFmKamJrW0tDhbXV2dJOnee++VJK1du1br1q1TVVWVmpqa5PF4NHnyZLW3tzvnCAQCqqmpUXV1tXbv3q3Tp0+rtLRUXV1dTk15ebmCwaBqa2tVW1urYDAov9/fF+MFAABJwmXbtt3TNwcCAf3sZz/Thx9+KEnyer0KBAJasWKFpC9mXdxut9asWaP58+crEolo2LBh2rZtm2bOnClJOn78uHJzc7Vz505NmTJFhw4d0ujRo9XY2KiioiJJUmNjo3w+n95//32NHDnysnpra2uTZVmKRCLKzMzs6RC/1PUr34h5/fFT0/v8MwAAuNrE8/3d4zUxnZ2d2r59u2bPni2Xy6UjR44oFAqppKTEqUlPT9f48ePV0NAgSWpubtbZs2djarxerwoKCpyaPXv2yLIsJ8BI0rhx42RZllNzMdFoVG1tbTEbAABIXj0OMa+99ppOnTqlBx98UJIUCoUkSW63O6bO7XY7x0KhkNLS0jRkyJBL1uTk5HT7vJycHKfmYiorK501NJZlKTc3t6dDAwAABuhxiHn++ec1bdo0eb3emP0ulyvmtW3b3fZd6MKai9V/1XlWrVqlSCTibEePHr2cYQAAAEP1KMR88sknevvtt/WP//iPzj6PxyNJ3WZLWltbndkZj8ejzs5OhcPhS9acOHGi22eePHmy2yzP/5Wenq7MzMyYDQAAJK8ehZgtW7YoJydH06f/eTFrXl6ePB6Pc8eS9MW6mfr6ehUXF0uSCgsLNWDAgJialpYWHThwwKnx+XyKRCLat2+fU7N3715FIhGnBgAAIDXeN5w7d05btmzRrFmzlJr657e7XC4FAgFVVFQoPz9f+fn5qqio0KBBg1ReXi5JsixLc+bM0dKlS5Wdna2srCwtW7ZMY8aM0aRJkyRJo0aN0tSpUzV37lxt3LhRkjRv3jyVlpZe9p1JAAAg+cUdYt5++219+umnmj17drdjy5cvV0dHhxYsWKBwOKyioiLt2rVLGRkZTs369euVmpqqGTNmqKOjQxMnTtTWrVuVkpLi1OzYsUOLFy927mIqKytTVVVVT8YHAACSVK+eE9Of8ZwYAADM8xd5TgwAAEAiEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMFLcIeb3v/+9HnjgAWVnZ2vQoEH69re/rebmZue4bdtavXq1vF6vBg4cqAkTJujgwYMx54hGo1q0aJGGDh2qwYMHq6ysTMeOHYupCYfD8vv9sixLlmXJ7/fr1KlTPRslAABIOnGFmHA4rDvuuEMDBgzQm2++qffee0/PPPOMvvGNbzg1a9eu1bp161RVVaWmpiZ5PB5NnjxZ7e3tTk0gEFBNTY2qq6u1e/dunT59WqWlperq6nJqysvLFQwGVVtbq9raWgWDQfn9/t6PGAAAJAWXbdv25RavXLlS//3f/61f/epXFz1u27a8Xq8CgYBWrFgh6YtZF7fbrTVr1mj+/PmKRCIaNmyYtm3bppkzZ0qSjh8/rtzcXO3cuVNTpkzRoUOHNHr0aDU2NqqoqEiS1NjYKJ/Pp/fff18jR478yl7b2tpkWZYikYgyMzMvd4iX7fqVb8S8/vip6X3+GQAAXG3i+f6Oaybm9ddf19ixY3XvvfcqJydHt956qzZv3uwcP3LkiEKhkEpKSpx96enpGj9+vBoaGiRJzc3NOnv2bEyN1+tVQUGBU7Nnzx5ZluUEGEkaN26cLMtyai4UjUbV1tYWswEAgOQVV4j56KOPtGHDBuXn5+utt97SQw89pMWLF+vFF1+UJIVCIUmS2+2OeZ/b7XaOhUIhpaWlaciQIZesycnJ6fb5OTk5Ts2FKisrnfUzlmUpNzc3nqEBAADDxBVizp07p9tuu00VFRW69dZbNX/+fM2dO1cbNmyIqXO5XDGvbdvutu9CF9ZcrP5S51m1apUikYizHT169HKHBQAADBRXiBk+fLhGjx4ds2/UqFH69NNPJUkej0eSus2WtLa2OrMzHo9HnZ2dCofDl6w5ceJEt88/efJkt1me89LT05WZmRmzAQCA5BVXiLnjjjt0+PDhmH0ffPCBrrvuOklSXl6ePB6P6urqnOOdnZ2qr69XcXGxJKmwsFADBgyIqWlpadGBAwecGp/Pp0gkon379jk1e/fuVSQScWoAAMDVLTWe4h/84AcqLi5WRUWFZsyYoX379mnTpk3atGmTpC8uAQUCAVVUVCg/P1/5+fmqqKjQoEGDVF5eLkmyLEtz5szR0qVLlZ2draysLC1btkxjxozRpEmTJH0xuzN16lTNnTtXGzdulCTNmzdPpaWll3VnEgAASH5xhZjbb79dNTU1WrVqlZ544gnl5eXp2Wef1f333+/ULF++XB0dHVqwYIHC4bCKioq0a9cuZWRkODXr169XamqqZsyYoY6ODk2cOFFbt25VSkqKU7Njxw4tXrzYuYuprKxMVVVVvR0vAABIEnE9J8YkPCcGAADzXLHnxAAAAPQXhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGCmuELN69Wq5XK6YzePxOMdt29bq1avl9Xo1cOBATZgwQQcPHow5RzQa1aJFizR06FANHjxYZWVlOnbsWExNOByW3++XZVmyLEt+v1+nTp3q+SgBAEDSiXsm5qabblJLS4uz7d+/3zm2du1arVu3TlVVVWpqapLH49HkyZPV3t7u1AQCAdXU1Ki6ulq7d+/W6dOnVVpaqq6uLqemvLxcwWBQtbW1qq2tVTAYlN/v7+VQAQBAMkmN+w2pqTGzL+fZtq1nn31Wjz32mO655x5J0gsvvCC3262XXnpJ8+fPVyQS0fPPP69t27Zp0qRJkqTt27crNzdXb7/9tqZMmaJDhw6ptrZWjY2NKioqkiRt3rxZPp9Phw8f1siRI3szXgAAkCTinon58MMP5fV6lZeXp/vuu08fffSRJOnIkSMKhUIqKSlxatPT0zV+/Hg1NDRIkpqbm3X27NmYGq/Xq4KCAqdmz549sizLCTCSNG7cOFmW5dRcTDQaVVtbW8wGAACSV1whpqioSC+++KLeeustbd68WaFQSMXFxfrDH/6gUCgkSXK73THvcbvdzrFQKKS0tDQNGTLkkjU5OTndPjsnJ8epuZjKykpnDY1lWcrNzY1naAAAwDBxhZhp06bp7//+7zVmzBhNmjRJb7zxhqQvLhud53K5Yt5j23a3fRe6sOZi9V91nlWrVikSiTjb0aNHL2tMAADATL26xXrw4MEaM2aMPvzwQ2edzIWzJa2trc7sjMfjUWdnp8Lh8CVrTpw40e2zTp482W2W5/9KT09XZmZmzAYAAJJXr0JMNBrVoUOHNHz4cOXl5cnj8aiurs453tnZqfr6ehUXF0uSCgsLNWDAgJialpYWHThwwKnx+XyKRCLat2+fU7N3715FIhGnBgAAIK67k5YtW6a77rpLI0aMUGtrq5588km1tbVp1qxZcrlcCgQCqqioUH5+vvLz81VRUaFBgwapvLxckmRZlubMmaOlS5cqOztbWVlZWrZsmXN5SpJGjRqlqVOnau7cudq4caMkad68eSotLeXOJAAA4IgrxBw7dkzf//739dlnn2nYsGEaN26cGhsbdd1110mSli9fro6ODi1YsEDhcFhFRUXatWuXMjIynHOsX79eqampmjFjhjo6OjRx4kRt3bpVKSkpTs2OHTu0ePFi5y6msrIyVVVV9cV4AQBAknDZtm0nuokroa2tTZZlKRKJXJH1MdevfCPm9cdPTe/zzwAA4GoTz/c3v50EAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADBSaqIbSBbXr3yj276Pn5qegE4AALg6MBMDAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIvQoxlZWVcrlcCgQCzj7btrV69Wp5vV4NHDhQEyZM0MGDB2PeF41GtWjRIg0dOlSDBw9WWVmZjh07FlMTDofl9/tlWZYsy5Lf79epU6d60y4AAEgiPQ4xTU1N2rRpk26++eaY/WvXrtW6detUVVWlpqYmeTweTZ48We3t7U5NIBBQTU2NqqurtXv3bp0+fVqlpaXq6upyasrLyxUMBlVbW6va2loFg0H5/f6etgsAAJJMj0LM6dOndf/992vz5s0aMmSIs9+2bT377LN67LHHdM8996igoEAvvPCC/vjHP+qll16SJEUiET3//PN65plnNGnSJN16663avn279u/fr7fffluSdOjQIdXW1uonP/mJfD6ffD6fNm/erJ/97Gc6fPhwHwwbAACYrkchZuHChZo+fbomTZoUs//IkSMKhUIqKSlx9qWnp2v8+PFqaGiQJDU3N+vs2bMxNV6vVwUFBU7Nnj17ZFmWioqKnJpx48bJsiyn5kLRaFRtbW0xGwAASF5xP7G3urpav/71r9XU1NTtWCgUkiS53e6Y/W63W5988olTk5aWFjODc77m/PtDoZBycnK6nT8nJ8epuVBlZaUef/zxeIcDAAAMFddMzNGjR/XII49o+/btuuaaa760zuVyxby2bbvbvgtdWHOx+kudZ9WqVYpEIs529OjRS34eAAAwW1whprm5Wa2trSosLFRqaqpSU1NVX1+vf/mXf1FqaqozA3PhbElra6tzzOPxqLOzU+Fw+JI1J06c6Pb5J0+e7DbLc156eroyMzNjNgAAkLziCjETJ07U/v37FQwGnW3s2LG6//77FQwGdcMNN8jj8aiurs55T2dnp+rr61VcXCxJKiws1IABA2JqWlpadODAAafG5/MpEolo3759Ts3evXsViUScGgAAcHWLa01MRkaGCgoKYvYNHjxY2dnZzv5AIKCKigrl5+crPz9fFRUVGjRokMrLyyVJlmVpzpw5Wrp0qbKzs5WVlaVly5ZpzJgxzkLhUaNGaerUqZo7d642btwoSZo3b55KS0s1cuTIXg8aAACYL+6FvV9l+fLl6ujo0IIFCxQOh1VUVKRdu3YpIyPDqVm/fr1SU1M1Y8YMdXR0aOLEidq6datSUlKcmh07dmjx4sXOXUxlZWWqqqrq63YBAIChXLZt24lu4kpoa2uTZVmKRCJXZH3M9Svf+Mqaj5+a3uefCwBAMovn+5vfTgIAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRUhPdQDK7fuUbMa8/fmp6gjoBACD5MBMDAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGCmuELNhwwbdfPPNyszMVGZmpnw+n958803nuG3bWr16tbxerwYOHKgJEybo4MGDMeeIRqNatGiRhg4dqsGDB6usrEzHjh2LqQmHw/L7/bIsS5Zlye/369SpUz0fJQAASDpxhZhrr71WTz31lN599129++67+u53v6vvfe97TlBZu3at1q1bp6qqKjU1Ncnj8Wjy5Mlqb293zhEIBFRTU6Pq6mrt3r1bp0+fVmlpqbq6upya8vJyBYNB1dbWqra2VsFgUH6/v4+GDAAAkoHLtm27NyfIysrS008/rdmzZ8vr9SoQCGjFihWSvph1cbvdWrNmjebPn69IJKJhw4Zp27ZtmjlzpiTp+PHjys3N1c6dOzVlyhQdOnRIo0ePVmNjo4qKiiRJjY2N8vl8ev/99zVy5MjL6qutrU2WZSkSiSgzM7M3Q7yo61e+Efd7Pn5qep/3AQBAMonn+7vHa2K6urpUXV2tM2fOyOfz6ciRIwqFQiopKXFq0tPTNX78eDU0NEiSmpubdfbs2Zgar9ergoICp2bPnj2yLMsJMJI0btw4WZbl1AAAAKTG+4b9+/fL5/PpT3/6k77+9a+rpqZGo0ePdgKG2+2OqXe73frkk08kSaFQSGlpaRoyZEi3mlAo5NTk5OR0+9ycnByn5mKi0aii0ajzuq2tLd6hAQAAg8QdYkaOHKlgMKhTp07plVde0axZs1RfX+8cd7lcMfW2bXfbd6ELay5W/1Xnqays1OOPP365w0iIi12C4hITAAA9E/flpLS0NH3rW9/S2LFjVVlZqVtuuUU//vGP5fF4JKnbbElra6szO+PxeNTZ2alwOHzJmhMnTnT73JMnT3ab5fm/Vq1apUgk4mxHjx6Nd2gAAMAgvX5OjG3bikajysvLk8fjUV1dnXOss7NT9fX1Ki4uliQVFhZqwIABMTUtLS06cOCAU+Pz+RSJRLRv3z6nZu/evYpEIk7NxaSnpzu3fp/fAABA8orrctKjjz6qadOmKTc3V+3t7aqurtYvf/lL1dbWyuVyKRAIqKKiQvn5+crPz1dFRYUGDRqk8vJySZJlWZozZ46WLl2q7OxsZWVladmyZRozZowmTZokSRo1apSmTp2quXPnauPGjZKkefPmqbS09LLvTAIAAMkvrhBz4sQJ+f1+tbS0yLIs3XzzzaqtrdXkyZMlScuXL1dHR4cWLFigcDisoqIi7dq1SxkZGc451q9fr9TUVM2YMUMdHR2aOHGitm7dqpSUFKdmx44dWrx4sXMXU1lZmaqqqvpivAAAIEn0+jkx/VV/fE7MxbCwFwCAP/uLPCcGAAAgkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGCkuH4AEn3vwt9g4reUAAC4PMzEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASv2Ldz1z4q9YSv2wNAMDFMBMDAACMRIgBAABGIsQAAAAjEWIAAICRWNhrgAsX+7LQFwAAZmIAAIChCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIwUV4iprKzU7bffroyMDOXk5Ojuu+/W4cOHY2ps29bq1avl9Xo1cOBATZgwQQcPHoypiUajWrRokYYOHarBgwerrKxMx44di6kJh8Py+/2yLEuWZcnv9+vUqVM9GyUAAEg6cYWY+vp6LVy4UI2Njaqrq9Pnn3+ukpISnTlzxqlZu3at1q1bp6qqKjU1Ncnj8Wjy5Mlqb293agKBgGpqalRdXa3du3fr9OnTKi0tVVdXl1NTXl6uYDCo2tpa1dbWKhgMyu/398GQAQBAMnDZtm339M0nT55UTk6O6uvr9Td/8zeybVter1eBQEArVqyQ9MWsi9vt1po1azR//nxFIhENGzZM27Zt08yZMyVJx48fV25urnbu3KkpU6bo0KFDGj16tBobG1VUVCRJamxslM/n0/vvv6+RI0d+ZW9tbW2yLEuRSESZmZk9HeKXutivTf+l8LA7AECyiuf7u1drYiKRiCQpKytLknTkyBGFQiGVlJQ4Nenp6Ro/frwaGhokSc3NzTp79mxMjdfrVUFBgVOzZ88eWZblBBhJGjdunCzLcmouFI1G1dbWFrMBAIDk1eMQY9u2lixZojvvvFMFBQWSpFAoJElyu90xtW632zkWCoWUlpamIUOGXLImJyen22fm5OQ4NReqrKx01s9YlqXc3NyeDg0AABigx7+d9PDDD+u3v/2tdu/e3e2Yy+WKeW3bdrd9F7qw5mL1lzrPqlWrtGTJEud1W1tb0gaZi13K4hITAOBq06OZmEWLFun111/XL37xC1177bXOfo/HI0ndZktaW1ud2RmPx6POzk6Fw+FL1pw4caLb5548ebLbLM956enpyszMjNkAAEDyiivE2Lathx9+WK+++qp+/vOfKy8vL+Z4Xl6ePB6P6urqnH2dnZ2qr69XcXGxJKmwsFADBgyIqWlpadGBAwecGp/Pp0gkon379jk1e/fuVSQScWoAAMDVLa7LSQsXLtRLL72kn/70p8rIyHBmXCzL0sCBA+VyuRQIBFRRUaH8/Hzl5+eroqJCgwYNUnl5uVM7Z84cLV26VNnZ2crKytKyZcs0ZswYTZo0SZI0atQoTZ06VXPnztXGjRslSfPmzVNpaell3ZkEAACSX1whZsOGDZKkCRMmxOzfsmWLHnzwQUnS8uXL1dHRoQULFigcDquoqEi7du1SRkaGU79+/XqlpqZqxowZ6ujo0MSJE7V161alpKQ4NTt27NDixYudu5jKyspUVVXVkzECAIAk1KvnxPRnyfycmIthYS8AIBn8xZ4TAwAAkCiEGAAAYCRCDAAAMBIhBgAAGKnHT+xF/3LhQmMW+gIAkh0zMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARuIW6yR1sd924rZrAEAyYSYGAAAYiRADAACMxOWkqwhP9QUAJBNmYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIm7k65iPBAPAGAyZmIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJu5MQg99XAgCYgpkYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjcYs14sZt2ACA/oAQg0u62C9dAwDQH3A5CQAAGIkQAwAAjBR3iHnnnXd01113yev1yuVy6bXXXos5btu2Vq9eLa/Xq4EDB2rChAk6ePBgTE00GtWiRYs0dOhQDR48WGVlZTp27FhMTTgclt/vl2VZsixLfr9fp06dinuAAAAgOcUdYs6cOaNbbrlFVVVVFz2+du1arVu3TlVVVWpqapLH49HkyZPV3t7u1AQCAdXU1Ki6ulq7d+/W6dOnVVpaqq6uLqemvLxcwWBQtbW1qq2tVTAYlN/v78EQAQBAMnLZtm33+M0ul2pqanT33XdL+mIWxuv1KhAIaMWKFZK+mHVxu91as2aN5s+fr0gkomHDhmnbtm2aOXOmJOn48ePKzc3Vzp07NWXKFB06dEijR49WY2OjioqKJEmNjY3y+Xx6//33NXLkyK/sra2tTZZlKRKJKDMzs6dD/FIseP0z7k4CAPSVeL6/+/TupCNHjigUCqmkpMTZl56ervHjx6uhoUHz589Xc3Ozzp49G1Pj9XpVUFCghoYGTZkyRXv27JFlWU6AkaRx48bJsiw1NDRcNMREo1FFo1HndVtbW18ODZdwsUBHsAEAXGl9urA3FApJktxud8x+t9vtHAuFQkpLS9OQIUMuWZOTk9Pt/Dk5OU7NhSorK531M5ZlKTc3t9fjAQAA/dcVuTvJ5XLFvLZtu9u+C11Yc7H6S51n1apVikQiznb06NEedA4AAEzRp5eTPB6PpC9mUoYPH+7sb21tdWZnPB6POjs7FQ6HY2ZjWltbVVxc7NScOHGi2/lPnjzZbZbnvPT0dKWnp/fZWNA7PNUXAHCl9elMTF5enjwej+rq6px9nZ2dqq+vdwJKYWGhBgwYEFPT0tKiAwcOODU+n0+RSET79u1zavbu3atIJOLUAACAq1vcMzGnT5/W7373O+f1kSNHFAwGlZWVpREjRigQCKiiokL5+fnKz89XRUWFBg0apPLyckmSZVmaM2eOli5dquzsbGVlZWnZsmUaM2aMJk2aJEkaNWqUpk6dqrlz52rjxo2SpHnz5qm0tPSy7kwCAADJL+4Q8+677+pv//ZvnddLliyRJM2aNUtbt27V8uXL1dHRoQULFigcDquoqEi7du1SRkaG857169crNTVVM2bMUEdHhyZOnKitW7cqJSXFqdmxY4cWL17s3MVUVlb2pc+mAQAAV59ePSemP+M5Mf0La2IAAJcjYc+JAb4Mz5IBAPQ1fgASAAAYiRADAACMxOUkJAzPkgEA9AYzMQAAwEjMxKDfYPEvACAezMQAAAAjEWIAAICRuJyEfo3FvwCAL8NMDAAAMBIhBgAAGIkQAwAAjESIAQAARmJhL4zCs2QAAOcxEwMAAIzETAyMx23YAHB1YiYGAAAYiZkYJJ2LrZu5HMzgAIBZmIkBAABGIsQAAAAjEWIAAICRWBMDXAJ3PgFA/0WIAf6/ni4IBgAkBpeTAACAkQgxAADASFxOAuLAM2gAoP9gJgYAABiJEAMAAIzE5STgL6Anl6G4BAUAl8ZMDAAAMBIzMYBBePgeAPwZIQbopy7nEtTFagg2AK4WhBggyTBbA+BqQYgBkhyzNQCSFSEGuAoxWwMgGRBiAPAkYgBG6vch5rnnntPTTz+tlpYW3XTTTXr22Wf1ne98J9FtAdDlhR+CDoArpV+HmJdfflmBQEDPPfec7rjjDm3cuFHTpk3Te++9pxEjRiS6PQCX4XIuXRGGAPSEy7ZtO9FNfJmioiLddttt2rBhg7Nv1KhRuvvuu1VZWXnJ97a1tcmyLEUiEWVmZvZ5bz2dfgeQWIQhoH+L5/u7387EdHZ2qrm5WStXrozZX1JSooaGhm710WhU0WjUeR2JRCR98YdxJZyL/vGKnBfAlTXiB/+R6BZiHHh8SqJbAPqV89/blzPH0m9DzGeffaauri653e6Y/W63W6FQqFt9ZWWlHn/88W77c3Nzr1iPANBb1rOJ7gDon9rb22VZ1iVr+m2IOc/lcsW8tm272z5JWrVqlZYsWeK8PnfunP73f/9X2dnZF63vjba2NuXm5uro0aNX5FJVIjE2cyXz+BibmZJ5bFJyjy+RY7NtW+3t7fJ6vV9Z229DzNChQ5WSktJt1qW1tbXb7IwkpaenKz09PWbfN77xjSvZojIzM5PuH+55jM1cyTw+xmamZB6blNzjS9TYvmoG5rx++yvWaWlpKiwsVF1dXcz+uro6FRcXJ6grAADQX/TbmRhJWrJkifx+v8aOHSufz6dNmzbp008/1UMPPZTo1gAAQIL16xAzc+ZM/eEPf9ATTzyhlpYWFRQUaOfOnbruuusS2ld6erp++MMfdrt8lQwYm7mSeXyMzUzJPDYpucdnytj69XNiAAAAvky/XRMDAABwKYQYAABgJEIMAAAwEiEGAAAYiRATp+eee055eXm65pprVFhYqF/96leJbqlPvPPOO7rrrrvk9Xrlcrn02muvJbqlPlNZWanbb79dGRkZysnJ0d13363Dhw8nuq0+sWHDBt18883OA6l8Pp/efPPNRLd1RVRWVsrlcikQCCS6lT6xevVquVyumM3j8SS6rT7z+9//Xg888ICys7M1aNAgffvb31Zzc3Oi2+q166+/vtvfm8vl0sKFCxPdWq99/vnn+ud//mfl5eVp4MCBuuGGG/TEE0/o3LlziW7tSxFi4vDyyy8rEAjoscce029+8xt95zvf0bRp0/Tpp58murVeO3PmjG655RZVVVUlupU+V19fr4ULF6qxsVF1dXX6/PPPVVJSojNnziS6tV679tpr9dRTT+ndd9/Vu+++q+9+97v63ve+p4MHDya6tT7V1NSkTZs26eabb050K33qpptuUktLi7Pt378/0S31iXA4rDvuuEMDBgzQm2++qffee0/PPPPMFX+K+l9CU1NTzN/Z+Qey3nvvvQnurPfWrFmjf//3f1dVVZUOHTqktWvX6umnn9a//uu/Jrq1L2fjsv31X/+1/dBDD8Xsu/HGG+2VK1cmqKMrQ5JdU1OT6DaumNbWVluSXV9fn+hWroghQ4bYP/nJTxLdRp9pb2+38/Pz7bq6Onv8+PH2I488kuiW+sQPf/hD+5Zbbkl0G1fEihUr7DvvvDPRbfxFPPLII/Y3v/lN+9y5c4lupdemT59uz549O2bfPffcYz/wwAMJ6uirMRNzmTo7O9Xc3KySkpKY/SUlJWpoaEhQV+iJSCQiScrKykpwJ32rq6tL1dXVOnPmjHw+X6Lb6TMLFy7U9OnTNWnSpES30uc+/PBDeb1e5eXl6b777tNHH32U6Jb6xOuvv66xY8fq3nvvVU5Ojm699VZt3rw50W31uc7OTm3fvl2zZ8/u8x8aToQ777xT//Vf/6UPPvhAkvQ///M/2r17t/7u7/4uwZ19uX79xN7+5LPPPlNXV1e3H590u93dfqQS/Zdt21qyZInuvPNOFRQUJLqdPrF//375fD796U9/0te//nXV1NRo9OjRiW6rT1RXV+vXv/61mpqaEt1KnysqKtKLL76ov/qrv9KJEyf05JNPqri4WAcPHlR2dnai2+uVjz76SBs2bNCSJUv06KOPat++fVq8eLHS09P1D//wD4lur8+89tprOnXqlB588MFEt9InVqxYoUgkohtvvFEpKSnq6urSj370I33/+99PdGtfihATpwvTtm3bSZHArxYPP/ywfvvb32r37t2JbqXPjBw5UsFgUKdOndIrr7yiWbNmqb6+3vggc/ToUT3yyCPatWuXrrnmmkS30+emTZvm/PeYMWPk8/n0zW9+Uy+88IKWLFmSwM5679y5cxo7dqwqKiokSbfeeqsOHjyoDRs2JFWIef755zVt2jR5vd5Et9InXn75ZW3fvl0vvfSSbrrpJgWDQQUCAXm9Xs2aNSvR7V0UIeYyDR06VCkpKd1mXVpbW7vNzqB/WrRokV5//XW98847uvbaaxPdTp9JS0vTt771LUnS2LFj1dTUpB//+MfauHFjgjvrnebmZrW2tqqwsNDZ19XVpXfeeUdVVVWKRqNKSUlJYId9a/DgwRozZow+/PDDRLfSa8OHD+8WokeNGqVXXnklQR31vU8++URvv/22Xn311US30mf+6Z/+SStXrtR9990n6Ytw/cknn6iysrLfhhjWxFymtLQ0FRYWOivRz6urq1NxcXGCusLlsG1bDz/8sF599VX9/Oc/V15eXqJbuqJs21Y0Gk10G702ceJE7d+/X8Fg0NnGjh2r+++/X8FgMKkCjCRFo1EdOnRIw4cPT3QrvXbHHXd0e4zBBx98kPAf7+1LW7ZsUU5OjqZPn57oVvrMH//4R33ta7GxICUlpV/fYs1MTByWLFkiv9+vsWPHyufzadOmTfr000/10EMPJbq1Xjt9+rR+97vfOa+PHDmiYDCorKwsjRgxIoGd9d7ChQv10ksv6ac//akyMjKc2TTLsjRw4MAEd9c7jz76qKZNm6bc3Fy1t7erurpav/zlL1VbW5vo1notIyOj27qlwYMHKzs7OynWMy1btkx33XWXRowYodbWVj355JNqa2vrt//HG48f/OAHKi4uVkVFhWbMmKF9+/Zp06ZN2rRpU6Jb6xPnzp3Tli1bNGvWLKWmJs/X6F133aUf/ehHGjFihG666Sb95je/0bp16zR79uxEt/blEntzlHn+7d/+zb7uuuvstLQ0+7bbbkua23R/8Ytf2JK6bbNmzUp0a712sXFJsrds2ZLo1npt9uzZzr/HYcOG2RMnTrR37dqV6LaumGS6xXrmzJn28OHD7QEDBther9e+55577IMHDya6rT7zn//5n3ZBQYGdnp5u33jjjfamTZsS3VKfeeutt2xJ9uHDhxPdSp9qa2uzH3nkEXvEiBH2NddcY99www32Y489Zkej0US39qVctm3biYlPAAAAPceaGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACM9P8AGI5sZECr0H4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#normal distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.random.normal(0, 1, 100000) ** 1.5\n",
    "plt.hist(X, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas fill -inf with min value\n",
    "import pandas as pd\n",
    "X = pd.DataFrame(np.random.randn(100, 3))\n",
    "X.iloc[0:10, 0] = -np.inf\n",
    "X = X.replace(-np.inf, np.nan)\n",
    "X = X.fillna(min(X.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>0.785854</td>\n",
       "      <td>0.139290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>0.348877</td>\n",
       "      <td>1.290593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>0.940154</td>\n",
       "      <td>-0.762405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>-1.022373</td>\n",
       "      <td>0.075832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>-0.230745</td>\n",
       "      <td>0.880037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.850661</td>\n",
       "      <td>0.511920</td>\n",
       "      <td>-0.356195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.506087</td>\n",
       "      <td>-0.490782</td>\n",
       "      <td>0.750037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.268783</td>\n",
       "      <td>-1.446341</td>\n",
       "      <td>-0.239300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.918332</td>\n",
       "      <td>-0.730611</td>\n",
       "      <td>-0.046762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.660034</td>\n",
       "      <td>0.349468</td>\n",
       "      <td>-1.451226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0  -3.038437  0.785854  0.139290\n",
       "1  -3.038437  0.348877  1.290593\n",
       "2  -3.038437  0.940154 -0.762405\n",
       "3  -3.038437 -1.022373  0.075832\n",
       "4  -3.038437 -0.230745  0.880037\n",
       "..       ...       ...       ...\n",
       "95  1.850661  0.511920 -0.356195\n",
       "96 -1.506087 -0.490782  0.750037\n",
       "97  2.268783 -1.446341 -0.239300\n",
       "98  0.918332 -0.730611 -0.046762\n",
       "99 -1.660034  0.349468 -1.451226\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, np.nan])\n",
    "#count the number of nan\n",
    "np.sum(np.isnan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select column not nan\n",
    "X = pd.DataFrame(np.random.randn(100, 3))\n",
    "X.iloc[0:10, 0] = np.nan\n",
    "X = X[np.isnan(X.iloc[:, 0]) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate average minute quote data\n",
    "import pandas as pd\n",
    "\n",
    "#df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize']\n",
    "num_samples = 1000\n",
    "df = pd.DataFrame(columns = ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize'], \n",
    "                  index = range(num_samples))\n",
    "df['date'] = '2020-01-01'\n",
    "#generate random interval for each second\n",
    "df['interval'] = pd.date_range('2020-01-01 04:00:00', periods=num_samples, freq='S')\n",
    "df['interval'] = df['interval'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "df['msymbol_ukey'] = 1\n",
    "df['DD.askSize'] = np.random.randn(num_samples)\n",
    "df['DD.ask'] = np.random.randn(num_samples)\n",
    "df['DD.bid'] = np.random.randn(num_samples)\n",
    "df['DD.bidSize'] = np.random.randn(num_samples)\n",
    "df['DD.isActive'] = np.random.randint(0, 2, num_samples)\n",
    "df['DD.volBuy'] = np.random.randn(num_samples)\n",
    "df['DD.volSell'] = np.random.randn(num_samples)\n",
    "df['DD.ret'] = np.random.randn(num_samples)\n",
    "df['DD.vol'] = np.random.randn(num_samples)\n",
    "#get the average minute quote data\n",
    "\n",
    "def get_average_minute_quote(df):\n",
    "    #get the average minute quota data\n",
    "    #input df\n",
    "    #output df\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5])\n",
    "    ask = df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.askSize'].transform(lambda x: np.mean(x))\n",
    "    bid = df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.bidSize'].transform(lambda x: np.mean(x))\n",
    "    return pd.concat([ask, bid], axis=1)\n",
    "#how many seconds is active in each minute\n",
    "def get_active_seconds(df):\n",
    "    #how many seconds is active in each minute\n",
    "    #input df\n",
    "    #output df\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize', 'DD.isActive']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    #count the number of DD.active == 1 in each minute\n",
    "    df['active_seconds'] = df.groupby( ['date', 'minute', 'msymbol_ukey'])['DD.isActive'].transform('sum')\n",
    "    return df['active_seconds']\n",
    "\n",
    "#how any times the ret goes from positive to negative in each minute\n",
    "def get_ret_change_times(df):\n",
    "    #how any times the ret goes from positive to negative in each minute\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    #how many times the ret goes from positive to negative in each minute\n",
    "    #ignore 0\n",
    "\n",
    "    df['non_zero_ret'] = df.groupby( ['date', 'minute', 'msymbol_ukey'] )['DD.ret'].transform(lambda x: x[x != 0])\n",
    "    df['ret_change_times'] = df.groupby(['date', 'minute', 'msymbol_ukey'])['non_zero_ret'].transform( lambda x: np.sum(np.diff(np.sign(x)) != 0))\n",
    "\n",
    "    return df['ret_change_times']\n",
    "\n",
    "#quantile for each minute\n",
    "def get_quantile(df, quantile = 3):\n",
    "    #quantile for each minute\n",
    "    #input df\n",
    "    #output df\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    #return the mean of each quantile\n",
    "    for i in range(quantile):\n",
    "        df['quantile_' + str(i)] = df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.ret'].transform( lambda x: np.mean(x[(x > np.quantile(x, i / quantile)) * ((x < np.quantile(x, (i + 1) / quantile)))]))\n",
    "    return df[[col for col in df.columns if 'quantile' in col]]\n",
    "\n",
    "#Entropy of a time horizon\n",
    "def get_entropy(df, m, t):\n",
    "    #Entropy of a time horizon\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    #t is the time horizon\n",
    "    #apply smoothing to each horizon m\n",
    "    df['smooth'] = df['DD.ret'].rolling(m).mean()\n",
    "    #get the entropy of each time horizon t\n",
    "    df['entropy'] = df['smooth'].rolling(t).apply(lambda x: -np.sum(x * np.log(x)))\n",
    "    return df['entropy']\n",
    "\n",
    "#the acculmulated Buy - Sell imbalance\n",
    "def get_imbalance(df):\n",
    "    #the acculmulated Buy - Sell imbalance\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize', 'DD.isActive', 'DD.volBuy', 'DD.volSell']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    df['imbalance'] = df.groupby(['date', 'msymbol_ukey'])['DD.volBuy'].transform(lambda x: np.cumsum(x)) - df.groupby(['date', 'msymbol_ukey'])['DD.volSell'].transform(lambda x: np.cumsum(x))\n",
    "    return df['imbalance']\n",
    "\n",
    "#get the quantile of ret based on DD.vol quantile\n",
    "def get_vol_quantile(df):\n",
    "    #get the quantile of ret based on the mean of DD.vol quantile of the last minute\n",
    "    #return vol quantile\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    df['vol_quantile'] = df.groupby(['date', 'minute'])['DD.vol'].transform(lambda x: np.mean(x[x != 0])).shift(60).fillna(0)   \n",
    "    \n",
    "\n",
    "    #positive quantile is the mean of ret when vol is bigger than mean of vol of the last minute\n",
    "    def pos_func(x):\n",
    "        #x is of ret and vol\n",
    "        x, y = x['DD.ret'], x['DD.vol']\n",
    "        if len(x[x != 0]) == 0:\n",
    "            return 0\n",
    "        print((y > df.loc[y.index, 'vol_quantile']) * (x != 0))\n",
    "        return np.mean(x[(y > df.loc[y.index, 'vol_quantile']) & (x != 0)])\n",
    "    df['pos_quantile'] = df.groupby(['date', 'minute'])[['DD.ret', 'DD.vol']].apply(pos_func)\n",
    "    # df['neg_quantile'] = df.groupby(['date', 'minute'])['DD.ret'].transform(neg_func)\n",
    "    # df['pos_imbalance'] = df.groupby(['date', 'minute'])['DD.volBuy'].transform(pos_func) - df.groupby(['date', 'minute'])['DD.volSell'].transform(pos_func)\n",
    "    # df['neg_imbalance'] = df.groupby(['date', 'minute'])['DD.volBuy'].transform(neg_func) - df.groupby(['date', 'minute'])['DD.volSell'].transform(neg_func)\n",
    "    return df[[col for col in df.columns if '_quantile_' in col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3      True\n",
      "4     False\n",
      "5      True\n",
      "6      True\n",
      "7      True\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14     True\n",
      "15    False\n",
      "16     True\n",
      "17     True\n",
      "18    False\n",
      "19    False\n",
      "20    False\n",
      "21     True\n",
      "22     True\n",
      "23    False\n",
      "24     True\n",
      "25    False\n",
      "26    False\n",
      "27     True\n",
      "28    False\n",
      "29     True\n",
      "30     True\n",
      "31    False\n",
      "32     True\n",
      "33    False\n",
      "34    False\n",
      "35     True\n",
      "36     True\n",
      "37     True\n",
      "38     True\n",
      "39     True\n",
      "40     True\n",
      "41     True\n",
      "42    False\n",
      "43     True\n",
      "44     True\n",
      "45    False\n",
      "46    False\n",
      "47    False\n",
      "48    False\n",
      "49    False\n",
      "50    False\n",
      "51     True\n",
      "52     True\n",
      "53     True\n",
      "54     True\n",
      "55    False\n",
      "56     True\n",
      "57     True\n",
      "58    False\n",
      "59    False\n",
      "dtype: bool\n",
      "60      True\n",
      "61     False\n",
      "62     False\n",
      "63     False\n",
      "64     False\n",
      "65     False\n",
      "66     False\n",
      "67     False\n",
      "68      True\n",
      "69     False\n",
      "70     False\n",
      "71      True\n",
      "72     False\n",
      "73      True\n",
      "74      True\n",
      "75      True\n",
      "76      True\n",
      "77      True\n",
      "78     False\n",
      "79      True\n",
      "80     False\n",
      "81      True\n",
      "82     False\n",
      "83     False\n",
      "84     False\n",
      "85     False\n",
      "86      True\n",
      "87      True\n",
      "88      True\n",
      "89      True\n",
      "90      True\n",
      "91     False\n",
      "92     False\n",
      "93      True\n",
      "94      True\n",
      "95     False\n",
      "96     False\n",
      "97     False\n",
      "98     False\n",
      "99      True\n",
      "100     True\n",
      "101     True\n",
      "102    False\n",
      "103     True\n",
      "104    False\n",
      "105     True\n",
      "106    False\n",
      "107    False\n",
      "108    False\n",
      "109     True\n",
      "110     True\n",
      "111     True\n",
      "112    False\n",
      "113    False\n",
      "114     True\n",
      "115     True\n",
      "116     True\n",
      "117    False\n",
      "118     True\n",
      "119     True\n",
      "dtype: bool\n",
      "120    False\n",
      "121     True\n",
      "122     True\n",
      "123    False\n",
      "124     True\n",
      "125    False\n",
      "126    False\n",
      "127    False\n",
      "128    False\n",
      "129     True\n",
      "130     True\n",
      "131     True\n",
      "132     True\n",
      "133     True\n",
      "134     True\n",
      "135     True\n",
      "136     True\n",
      "137    False\n",
      "138     True\n",
      "139     True\n",
      "140    False\n",
      "141    False\n",
      "142    False\n",
      "143     True\n",
      "144    False\n",
      "145     True\n",
      "146    False\n",
      "147    False\n",
      "148    False\n",
      "149     True\n",
      "150     True\n",
      "151     True\n",
      "152     True\n",
      "153    False\n",
      "154     True\n",
      "155     True\n",
      "156    False\n",
      "157     True\n",
      "158    False\n",
      "159     True\n",
      "160    False\n",
      "161     True\n",
      "162     True\n",
      "163     True\n",
      "164     True\n",
      "165     True\n",
      "166     True\n",
      "167     True\n",
      "168     True\n",
      "169    False\n",
      "170     True\n",
      "171     True\n",
      "172     True\n",
      "173     True\n",
      "174    False\n",
      "175     True\n",
      "176     True\n",
      "177     True\n",
      "178    False\n",
      "179     True\n",
      "dtype: bool\n",
      "180    False\n",
      "181     True\n",
      "182     True\n",
      "183     True\n",
      "184     True\n",
      "185    False\n",
      "186     True\n",
      "187    False\n",
      "188    False\n",
      "189    False\n",
      "190    False\n",
      "191    False\n",
      "192     True\n",
      "193    False\n",
      "194    False\n",
      "195    False\n",
      "196    False\n",
      "197     True\n",
      "198    False\n",
      "199    False\n",
      "200    False\n",
      "201     True\n",
      "202     True\n",
      "203    False\n",
      "204    False\n",
      "205    False\n",
      "206     True\n",
      "207    False\n",
      "208    False\n",
      "209     True\n",
      "210    False\n",
      "211     True\n",
      "212    False\n",
      "213     True\n",
      "214     True\n",
      "215    False\n",
      "216    False\n",
      "217     True\n",
      "218    False\n",
      "219    False\n",
      "220    False\n",
      "221    False\n",
      "222     True\n",
      "223     True\n",
      "224    False\n",
      "225     True\n",
      "226    False\n",
      "227     True\n",
      "228     True\n",
      "229    False\n",
      "230     True\n",
      "231     True\n",
      "232    False\n",
      "233    False\n",
      "234    False\n",
      "235     True\n",
      "236     True\n",
      "237     True\n",
      "238     True\n",
      "239    False\n",
      "dtype: bool\n",
      "240    False\n",
      "241     True\n",
      "242     True\n",
      "243    False\n",
      "244    False\n",
      "245    False\n",
      "246     True\n",
      "247     True\n",
      "248    False\n",
      "249    False\n",
      "250     True\n",
      "251     True\n",
      "252    False\n",
      "253    False\n",
      "254    False\n",
      "255    False\n",
      "256     True\n",
      "257    False\n",
      "258     True\n",
      "259     True\n",
      "260     True\n",
      "261    False\n",
      "262     True\n",
      "263     True\n",
      "264    False\n",
      "265    False\n",
      "266     True\n",
      "267     True\n",
      "268     True\n",
      "269     True\n",
      "270     True\n",
      "271    False\n",
      "272    False\n",
      "273    False\n",
      "274     True\n",
      "275    False\n",
      "276    False\n",
      "277    False\n",
      "278    False\n",
      "279     True\n",
      "280     True\n",
      "281     True\n",
      "282     True\n",
      "283     True\n",
      "284     True\n",
      "285    False\n",
      "286    False\n",
      "287     True\n",
      "288     True\n",
      "289     True\n",
      "290     True\n",
      "291     True\n",
      "292     True\n",
      "293    False\n",
      "294    False\n",
      "295     True\n",
      "296     True\n",
      "297    False\n",
      "298     True\n",
      "299    False\n",
      "dtype: bool\n",
      "300    False\n",
      "301    False\n",
      "302    False\n",
      "303    False\n",
      "304     True\n",
      "305     True\n",
      "306    False\n",
      "307     True\n",
      "308    False\n",
      "309    False\n",
      "310     True\n",
      "311    False\n",
      "312     True\n",
      "313     True\n",
      "314     True\n",
      "315    False\n",
      "316    False\n",
      "317     True\n",
      "318    False\n",
      "319     True\n",
      "320     True\n",
      "321     True\n",
      "322    False\n",
      "323    False\n",
      "324    False\n",
      "325    False\n",
      "326    False\n",
      "327    False\n",
      "328    False\n",
      "329     True\n",
      "330    False\n",
      "331    False\n",
      "332     True\n",
      "333    False\n",
      "334     True\n",
      "335    False\n",
      "336    False\n",
      "337    False\n",
      "338    False\n",
      "339    False\n",
      "340    False\n",
      "341     True\n",
      "342    False\n",
      "343    False\n",
      "344    False\n",
      "345    False\n",
      "346     True\n",
      "347    False\n",
      "348     True\n",
      "349    False\n",
      "350    False\n",
      "351    False\n",
      "352    False\n",
      "353     True\n",
      "354    False\n",
      "355    False\n",
      "356    False\n",
      "357    False\n",
      "358    False\n",
      "359    False\n",
      "dtype: bool\n",
      "360    False\n",
      "361     True\n",
      "362    False\n",
      "363    False\n",
      "364     True\n",
      "365     True\n",
      "366    False\n",
      "367    False\n",
      "368    False\n",
      "369    False\n",
      "370     True\n",
      "371     True\n",
      "372    False\n",
      "373     True\n",
      "374     True\n",
      "375     True\n",
      "376     True\n",
      "377    False\n",
      "378     True\n",
      "379     True\n",
      "380    False\n",
      "381     True\n",
      "382     True\n",
      "383     True\n",
      "384    False\n",
      "385     True\n",
      "386     True\n",
      "387    False\n",
      "388    False\n",
      "389    False\n",
      "390     True\n",
      "391    False\n",
      "392     True\n",
      "393     True\n",
      "394     True\n",
      "395     True\n",
      "396    False\n",
      "397    False\n",
      "398     True\n",
      "399    False\n",
      "400    False\n",
      "401    False\n",
      "402    False\n",
      "403     True\n",
      "404     True\n",
      "405     True\n",
      "406     True\n",
      "407     True\n",
      "408     True\n",
      "409     True\n",
      "410     True\n",
      "411     True\n",
      "412     True\n",
      "413    False\n",
      "414    False\n",
      "415     True\n",
      "416     True\n",
      "417    False\n",
      "418     True\n",
      "419     True\n",
      "dtype: bool\n",
      "420    False\n",
      "421    False\n",
      "422    False\n",
      "423     True\n",
      "424    False\n",
      "425    False\n",
      "426     True\n",
      "427     True\n",
      "428     True\n",
      "429     True\n",
      "430     True\n",
      "431     True\n",
      "432     True\n",
      "433    False\n",
      "434     True\n",
      "435     True\n",
      "436    False\n",
      "437    False\n",
      "438    False\n",
      "439    False\n",
      "440    False\n",
      "441     True\n",
      "442     True\n",
      "443    False\n",
      "444    False\n",
      "445    False\n",
      "446    False\n",
      "447     True\n",
      "448    False\n",
      "449     True\n",
      "450     True\n",
      "451    False\n",
      "452     True\n",
      "453    False\n",
      "454    False\n",
      "455     True\n",
      "456    False\n",
      "457    False\n",
      "458    False\n",
      "459     True\n",
      "460    False\n",
      "461     True\n",
      "462    False\n",
      "463    False\n",
      "464     True\n",
      "465     True\n",
      "466     True\n",
      "467     True\n",
      "468     True\n",
      "469     True\n",
      "470    False\n",
      "471     True\n",
      "472     True\n",
      "473     True\n",
      "474     True\n",
      "475     True\n",
      "476    False\n",
      "477    False\n",
      "478    False\n",
      "479    False\n",
      "dtype: bool\n",
      "480    False\n",
      "481    False\n",
      "482    False\n",
      "483    False\n",
      "484     True\n",
      "485     True\n",
      "486    False\n",
      "487     True\n",
      "488    False\n",
      "489     True\n",
      "490    False\n",
      "491     True\n",
      "492     True\n",
      "493     True\n",
      "494     True\n",
      "495     True\n",
      "496    False\n",
      "497    False\n",
      "498     True\n",
      "499     True\n",
      "500    False\n",
      "501    False\n",
      "502    False\n",
      "503     True\n",
      "504     True\n",
      "505     True\n",
      "506     True\n",
      "507    False\n",
      "508    False\n",
      "509    False\n",
      "510    False\n",
      "511    False\n",
      "512    False\n",
      "513    False\n",
      "514    False\n",
      "515     True\n",
      "516    False\n",
      "517    False\n",
      "518    False\n",
      "519     True\n",
      "520    False\n",
      "521     True\n",
      "522    False\n",
      "523     True\n",
      "524    False\n",
      "525    False\n",
      "526    False\n",
      "527    False\n",
      "528     True\n",
      "529    False\n",
      "530    False\n",
      "531    False\n",
      "532     True\n",
      "533     True\n",
      "534    False\n",
      "535    False\n",
      "536    False\n",
      "537    False\n",
      "538     True\n",
      "539    False\n",
      "dtype: bool\n",
      "540     True\n",
      "541     True\n",
      "542     True\n",
      "543     True\n",
      "544    False\n",
      "545    False\n",
      "546     True\n",
      "547    False\n",
      "548     True\n",
      "549     True\n",
      "550    False\n",
      "551    False\n",
      "552     True\n",
      "553     True\n",
      "554     True\n",
      "555    False\n",
      "556     True\n",
      "557     True\n",
      "558    False\n",
      "559     True\n",
      "560    False\n",
      "561    False\n",
      "562     True\n",
      "563     True\n",
      "564     True\n",
      "565    False\n",
      "566    False\n",
      "567    False\n",
      "568     True\n",
      "569    False\n",
      "570     True\n",
      "571     True\n",
      "572    False\n",
      "573     True\n",
      "574     True\n",
      "575    False\n",
      "576     True\n",
      "577    False\n",
      "578     True\n",
      "579    False\n",
      "580     True\n",
      "581     True\n",
      "582    False\n",
      "583     True\n",
      "584    False\n",
      "585     True\n",
      "586     True\n",
      "587    False\n",
      "588     True\n",
      "589    False\n",
      "590     True\n",
      "591     True\n",
      "592     True\n",
      "593     True\n",
      "594    False\n",
      "595     True\n",
      "596    False\n",
      "597     True\n",
      "598    False\n",
      "599    False\n",
      "dtype: bool\n",
      "600     True\n",
      "601    False\n",
      "602    False\n",
      "603    False\n",
      "604    False\n",
      "605    False\n",
      "606    False\n",
      "607    False\n",
      "608    False\n",
      "609    False\n",
      "610     True\n",
      "611    False\n",
      "612    False\n",
      "613     True\n",
      "614     True\n",
      "615    False\n",
      "616     True\n",
      "617     True\n",
      "618     True\n",
      "619    False\n",
      "620     True\n",
      "621     True\n",
      "622     True\n",
      "623    False\n",
      "624     True\n",
      "625     True\n",
      "626     True\n",
      "627     True\n",
      "628    False\n",
      "629    False\n",
      "630     True\n",
      "631     True\n",
      "632     True\n",
      "633     True\n",
      "634    False\n",
      "635     True\n",
      "636    False\n",
      "637    False\n",
      "638    False\n",
      "639    False\n",
      "640    False\n",
      "641     True\n",
      "642     True\n",
      "643     True\n",
      "644     True\n",
      "645     True\n",
      "646     True\n",
      "647    False\n",
      "648    False\n",
      "649    False\n",
      "650     True\n",
      "651    False\n",
      "652     True\n",
      "653     True\n",
      "654     True\n",
      "655    False\n",
      "656    False\n",
      "657    False\n",
      "658     True\n",
      "659    False\n",
      "dtype: bool\n",
      "660     True\n",
      "661     True\n",
      "662    False\n",
      "663    False\n",
      "664     True\n",
      "665     True\n",
      "666     True\n",
      "667    False\n",
      "668    False\n",
      "669    False\n",
      "670    False\n",
      "671     True\n",
      "672    False\n",
      "673    False\n",
      "674     True\n",
      "675     True\n",
      "676     True\n",
      "677    False\n",
      "678     True\n",
      "679     True\n",
      "680     True\n",
      "681    False\n",
      "682    False\n",
      "683     True\n",
      "684    False\n",
      "685     True\n",
      "686     True\n",
      "687     True\n",
      "688     True\n",
      "689     True\n",
      "690     True\n",
      "691     True\n",
      "692    False\n",
      "693    False\n",
      "694     True\n",
      "695    False\n",
      "696     True\n",
      "697    False\n",
      "698     True\n",
      "699    False\n",
      "700    False\n",
      "701     True\n",
      "702    False\n",
      "703     True\n",
      "704     True\n",
      "705     True\n",
      "706     True\n",
      "707    False\n",
      "708     True\n",
      "709    False\n",
      "710     True\n",
      "711     True\n",
      "712    False\n",
      "713     True\n",
      "714     True\n",
      "715    False\n",
      "716     True\n",
      "717     True\n",
      "718    False\n",
      "719     True\n",
      "dtype: bool\n",
      "720     True\n",
      "721    False\n",
      "722    False\n",
      "723     True\n",
      "724     True\n",
      "725    False\n",
      "726    False\n",
      "727    False\n",
      "728     True\n",
      "729     True\n",
      "730    False\n",
      "731     True\n",
      "732     True\n",
      "733    False\n",
      "734     True\n",
      "735     True\n",
      "736     True\n",
      "737    False\n",
      "738    False\n",
      "739    False\n",
      "740    False\n",
      "741    False\n",
      "742     True\n",
      "743     True\n",
      "744     True\n",
      "745     True\n",
      "746     True\n",
      "747     True\n",
      "748     True\n",
      "749     True\n",
      "750     True\n",
      "751    False\n",
      "752    False\n",
      "753     True\n",
      "754     True\n",
      "755    False\n",
      "756     True\n",
      "757     True\n",
      "758    False\n",
      "759    False\n",
      "760     True\n",
      "761     True\n",
      "762     True\n",
      "763     True\n",
      "764     True\n",
      "765    False\n",
      "766     True\n",
      "767    False\n",
      "768    False\n",
      "769    False\n",
      "770     True\n",
      "771     True\n",
      "772     True\n",
      "773    False\n",
      "774     True\n",
      "775     True\n",
      "776     True\n",
      "777     True\n",
      "778    False\n",
      "779    False\n",
      "dtype: bool\n",
      "780    False\n",
      "781    False\n",
      "782    False\n",
      "783     True\n",
      "784     True\n",
      "785    False\n",
      "786    False\n",
      "787    False\n",
      "788     True\n",
      "789    False\n",
      "790    False\n",
      "791    False\n",
      "792     True\n",
      "793    False\n",
      "794     True\n",
      "795     True\n",
      "796     True\n",
      "797     True\n",
      "798     True\n",
      "799    False\n",
      "800    False\n",
      "801    False\n",
      "802     True\n",
      "803     True\n",
      "804    False\n",
      "805    False\n",
      "806    False\n",
      "807     True\n",
      "808    False\n",
      "809    False\n",
      "810    False\n",
      "811    False\n",
      "812    False\n",
      "813    False\n",
      "814    False\n",
      "815    False\n",
      "816     True\n",
      "817    False\n",
      "818     True\n",
      "819    False\n",
      "820    False\n",
      "821     True\n",
      "822    False\n",
      "823     True\n",
      "824     True\n",
      "825     True\n",
      "826    False\n",
      "827     True\n",
      "828     True\n",
      "829    False\n",
      "830     True\n",
      "831     True\n",
      "832    False\n",
      "833    False\n",
      "834    False\n",
      "835    False\n",
      "836    False\n",
      "837    False\n",
      "838    False\n",
      "839    False\n",
      "dtype: bool\n",
      "840    False\n",
      "841     True\n",
      "842     True\n",
      "843     True\n",
      "844     True\n",
      "845     True\n",
      "846    False\n",
      "847    False\n",
      "848     True\n",
      "849     True\n",
      "850     True\n",
      "851     True\n",
      "852     True\n",
      "853     True\n",
      "854    False\n",
      "855    False\n",
      "856     True\n",
      "857     True\n",
      "858    False\n",
      "859    False\n",
      "860     True\n",
      "861    False\n",
      "862     True\n",
      "863     True\n",
      "864     True\n",
      "865     True\n",
      "866     True\n",
      "867    False\n",
      "868     True\n",
      "869     True\n",
      "870    False\n",
      "871    False\n",
      "872     True\n",
      "873    False\n",
      "874     True\n",
      "875    False\n",
      "876     True\n",
      "877     True\n",
      "878    False\n",
      "879     True\n",
      "880    False\n",
      "881     True\n",
      "882    False\n",
      "883     True\n",
      "884     True\n",
      "885    False\n",
      "886     True\n",
      "887    False\n",
      "888    False\n",
      "889    False\n",
      "890     True\n",
      "891     True\n",
      "892     True\n",
      "893     True\n",
      "894     True\n",
      "895    False\n",
      "896     True\n",
      "897     True\n",
      "898    False\n",
      "899    False\n",
      "dtype: bool\n",
      "900    False\n",
      "901    False\n",
      "902    False\n",
      "903    False\n",
      "904     True\n",
      "905    False\n",
      "906    False\n",
      "907    False\n",
      "908    False\n",
      "909    False\n",
      "910    False\n",
      "911    False\n",
      "912    False\n",
      "913     True\n",
      "914    False\n",
      "915    False\n",
      "916    False\n",
      "917    False\n",
      "918    False\n",
      "919    False\n",
      "920     True\n",
      "921     True\n",
      "922     True\n",
      "923    False\n",
      "924    False\n",
      "925    False\n",
      "926    False\n",
      "927     True\n",
      "928    False\n",
      "929    False\n",
      "930    False\n",
      "931    False\n",
      "932    False\n",
      "933     True\n",
      "934     True\n",
      "935     True\n",
      "936    False\n",
      "937    False\n",
      "938    False\n",
      "939    False\n",
      "940     True\n",
      "941    False\n",
      "942     True\n",
      "943     True\n",
      "944     True\n",
      "945     True\n",
      "946    False\n",
      "947    False\n",
      "948    False\n",
      "949    False\n",
      "950    False\n",
      "951    False\n",
      "952    False\n",
      "953     True\n",
      "954     True\n",
      "955     True\n",
      "956    False\n",
      "957     True\n",
      "958    False\n",
      "959     True\n",
      "dtype: bool\n",
      "960    False\n",
      "961     True\n",
      "962     True\n",
      "963     True\n",
      "964     True\n",
      "965     True\n",
      "966     True\n",
      "967     True\n",
      "968    False\n",
      "969     True\n",
      "970     True\n",
      "971    False\n",
      "972     True\n",
      "973     True\n",
      "974    False\n",
      "975    False\n",
      "976    False\n",
      "977    False\n",
      "978    False\n",
      "979    False\n",
      "980     True\n",
      "981     True\n",
      "982     True\n",
      "983    False\n",
      "984     True\n",
      "985    False\n",
      "986     True\n",
      "987    False\n",
      "988    False\n",
      "989    False\n",
      "990    False\n",
      "991    False\n",
      "992    False\n",
      "993    False\n",
      "994    False\n",
      "995    False\n",
      "996    False\n",
      "997     True\n",
      "998     True\n",
      "999     True\n",
      "dtype: bool\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "incompatible index of inserted column with frame index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:12020\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  12019\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m> 12020\u001b[0m     reindexed_value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mreindex(index)\u001b[39m.\u001b[39m_values\n\u001b[1;32m  12021\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  12022\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/series.py:5094\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5093\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index})\n\u001b[0;32m-> 5094\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreindex(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/generic.py:5289\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5288\u001b[0m \u001b[39m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_axes(\n\u001b[1;32m   5290\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[1;32m   5291\u001b[0m )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreindex\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/generic.py:5304\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5303\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(a)\n\u001b[0;32m-> 5304\u001b[0m new_index, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49mreindex(\n\u001b[1;32m   5305\u001b[0m     labels, level\u001b[39m=\u001b[39;49mlevel, limit\u001b[39m=\u001b[39;49mlimit, tolerance\u001b[39m=\u001b[39;49mtolerance, method\u001b[39m=\u001b[39;49mmethod\n\u001b[1;32m   5306\u001b[0m )\n\u001b[1;32m   5308\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(a)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:4434\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4427\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   4428\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mreindexing with a non-unique Index is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4429\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mwill raise in a future version.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4430\u001b[0m                 \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m   4431\u001b[0m                 stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   4432\u001b[0m             )\n\u001b[0;32m-> 4434\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrap_reindex_result(target, indexer, preserve_names)\n\u001b[1;32m   4435\u001b[0m \u001b[39mreturn\u001b[39;00m target, indexer\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/multi.py:2556\u001b[0m, in \u001b[0;36mMultiIndex._wrap_reindex_result\u001b[0;34m(self, target, indexer, preserve_names)\u001b[0m\n\u001b[1;32m   2555\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2556\u001b[0m     target \u001b[39m=\u001b[39m MultiIndex\u001b[39m.\u001b[39;49mfrom_tuples(target)\n\u001b[1;32m   2557\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   2558\u001b[0m     \u001b[39m# not all tuples, see test_constructor_dict_multiindex_reindex_flat\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/multi.py:205\u001b[0m, in \u001b[0;36mnames_compat.<locals>.new_meth\u001b[0;34m(self_or_cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m meth(self_or_cls, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/multi.py:573\u001b[0m, in \u001b[0;36mMultiIndex.from_tuples\u001b[0;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[1;32m    571\u001b[0m         tuples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(tuples\u001b[39m.\u001b[39m_values)\n\u001b[0;32m--> 573\u001b[0m     arrays \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(lib\u001b[39m.\u001b[39;49mtuples_to_object_array(tuples)\u001b[39m.\u001b[39mT)\n\u001b[1;32m    574\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(tuples, \u001b[39mlist\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2984\u001b[0m, in \u001b[0;36mpandas._libs.lib.tuples_to_object_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[261], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_vol_quantile(df)\n",
      "Cell \u001b[0;32mIn[260], line 107\u001b[0m, in \u001b[0;36mget_vol_quantile\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[39mprint\u001b[39m((y \u001b[39m>\u001b[39m df\u001b[39m.\u001b[39mloc[y\u001b[39m.\u001b[39mindex, \u001b[39m'\u001b[39m\u001b[39mvol_quantile\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m*\u001b[39m (x \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m))\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(x[(y \u001b[39m>\u001b[39m df\u001b[39m.\u001b[39mloc[y\u001b[39m.\u001b[39mindex, \u001b[39m'\u001b[39m\u001b[39mvol_quantile\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m&\u001b[39m (x \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m)])\n\u001b[0;32m--> 107\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpos_quantile\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminute\u001b[39m\u001b[39m'\u001b[39m])[[\u001b[39m'\u001b[39m\u001b[39mDD.ret\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDD.vol\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mapply(pos_func)\n\u001b[1;32m    108\u001b[0m \u001b[39m# df['neg_quantile'] = df.groupby(['date', 'minute'])['DD.ret'].transform(neg_func)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m# df['pos_imbalance'] = df.groupby(['date', 'minute'])['DD.volBuy'].transform(pos_func) - df.groupby(['date', 'minute'])['DD.volSell'].transform(pos_func)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m# df['neg_imbalance'] = df.groupby(['date', 'minute'])['DD.volBuy'].transform(neg_func) - df.groupby(['date', 'minute'])['DD.volSell'].transform(neg_func)\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39mreturn\u001b[39;00m df[[col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_quantile_\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m col]]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4176\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:4912\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4910\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4911\u001b[0m \u001b[39melif\u001b[39;00m is_dict_like(value):\n\u001b[0;32m-> 4912\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   4915\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:12027\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  12023\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  12024\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n\u001b[1;32m  12025\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m> 12027\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m  12028\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mincompatible index of inserted column with frame index\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  12029\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m  12030\u001b[0m \u001b[39mreturn\u001b[39;00m reindexed_value\n",
      "\u001b[0;31mTypeError\u001b[0m: incompatible index of inserted column with frame index"
     ]
    }
   ],
   "source": [
    "get_vol_quantile(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "995    False\n",
       "996     True\n",
       "997    False\n",
       "998    False\n",
       "999     True\n",
       "Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DD.askSize'] > df['DD.bidSize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile = 3\n",
    "i = 0\n",
    "f =  lambda x: np.mean(x[(x > np.quantile(x, i / quantile)) * ((x < np.quantile(x, (i + 1) / quantile)))])\n",
    "f(np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrate all the features\n",
    "def get_features(df):\n",
    "    #integrate all the features\n",
    "    new = pd.DataFrame()\n",
    "    new = pd.concat([new, get_average_minute_quote(df)], axis=1)\n",
    "    new['active_seconds'] = get_active_seconds(df)\n",
    "    new['ret_change_times'] = get_ret_change_times(df)\n",
    "    new = pd.concat([new, get_quantile(df, quantile = 3)], axis=1)\n",
    "    for m in [10, 30, 60]:\n",
    "        for t in [10, 30, 60]:\n",
    "            new['entropy_' + str(m) + '_' + str(t)] = get_entropy(df, m, t)\n",
    "    new['imbalance'] = get_imbalance(df)\n",
    "    new = pd.concat([new, get_vol_quantile(df, quantile = 3)], axis=1)\n",
    "    new['date'] = df['date']\n",
    "    new['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    new['msymbol_ukey'] = df['msymbol_ukey']\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1,   1,   1,   1,   1, -17,  19])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(np.array([1, 2, 3, 4, 5, 6, 7, 8, -9, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = get_features(df)\n",
    "#squeeze the dataframe by squeezing the minute\n",
    "new = new.groupby(['date', 'minute', 'msymbol_ukey']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>minute</th>\n",
       "      <th>msymbol_ukey</th>\n",
       "      <th>DD.askSize</th>\n",
       "      <th>DD.bidSize</th>\n",
       "      <th>active_seconds</th>\n",
       "      <th>ret_change_times</th>\n",
       "      <th>quantile_0</th>\n",
       "      <th>quantile_1</th>\n",
       "      <th>quantile_2</th>\n",
       "      <th>...</th>\n",
       "      <th>entropy_60_10</th>\n",
       "      <th>entropy_60_30</th>\n",
       "      <th>entropy_60_60</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>vol_quantile_0</th>\n",
       "      <th>imbalance_quantile_0</th>\n",
       "      <th>vol_quantile_1</th>\n",
       "      <th>imbalance_quantile_1</th>\n",
       "      <th>vol_quantile_2</th>\n",
       "      <th>imbalance_quantile_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153576</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-1.029904</td>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.950497</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.189473</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>-0.211545</td>\n",
       "      <td>0.029545</td>\n",
       "      <td>0.689109</td>\n",
       "      <td>-0.075620</td>\n",
       "      <td>0.379304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070277</td>\n",
       "      <td>0.170257</td>\n",
       "      <td>37.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.823792</td>\n",
       "      <td>0.102571</td>\n",
       "      <td>1.140267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403585</td>\n",
       "      <td>0.755708</td>\n",
       "      <td>2.989781</td>\n",
       "      <td>14.810075</td>\n",
       "      <td>0.261117</td>\n",
       "      <td>0.150261</td>\n",
       "      <td>-0.006286</td>\n",
       "      <td>-0.257019</td>\n",
       "      <td>0.125186</td>\n",
       "      <td>-0.291971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.132703</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.751911</td>\n",
       "      <td>0.447799</td>\n",
       "      <td>1.357787</td>\n",
       "      <td>...</td>\n",
       "      <td>3.346957</td>\n",
       "      <td>8.855843</td>\n",
       "      <td>12.950576</td>\n",
       "      <td>-1.988678</td>\n",
       "      <td>0.410844</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>-0.884480</td>\n",
       "      <td>0.026573</td>\n",
       "      <td>0.242825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165413</td>\n",
       "      <td>0.215126</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-0.775364</td>\n",
       "      <td>0.189733</td>\n",
       "      <td>1.158413</td>\n",
       "      <td>...</td>\n",
       "      <td>3.521326</td>\n",
       "      <td>10.673072</td>\n",
       "      <td>21.194466</td>\n",
       "      <td>-5.424806</td>\n",
       "      <td>0.409813</td>\n",
       "      <td>-0.123007</td>\n",
       "      <td>-0.247409</td>\n",
       "      <td>-0.501979</td>\n",
       "      <td>0.262230</td>\n",
       "      <td>0.278925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.149525</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-0.933860</td>\n",
       "      <td>0.088822</td>\n",
       "      <td>1.207721</td>\n",
       "      <td>...</td>\n",
       "      <td>2.831463</td>\n",
       "      <td>9.135907</td>\n",
       "      <td>19.285445</td>\n",
       "      <td>-8.638203</td>\n",
       "      <td>-0.224793</td>\n",
       "      <td>0.103901</td>\n",
       "      <td>0.154870</td>\n",
       "      <td>-0.173902</td>\n",
       "      <td>0.259310</td>\n",
       "      <td>-0.057253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.128483</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.148900</td>\n",
       "      <td>-0.050557</td>\n",
       "      <td>0.841266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829005</td>\n",
       "      <td>3.566250</td>\n",
       "      <td>11.005239</td>\n",
       "      <td>-14.218954</td>\n",
       "      <td>0.105987</td>\n",
       "      <td>0.125208</td>\n",
       "      <td>-0.285584</td>\n",
       "      <td>-0.485725</td>\n",
       "      <td>-0.215696</td>\n",
       "      <td>-0.144039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:06:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235428</td>\n",
       "      <td>0.280623</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.057598</td>\n",
       "      <td>-0.060052</td>\n",
       "      <td>0.945063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.434104</td>\n",
       "      <td>-18.870400</td>\n",
       "      <td>0.102676</td>\n",
       "      <td>-0.231962</td>\n",
       "      <td>-0.185992</td>\n",
       "      <td>0.235239</td>\n",
       "      <td>-0.056506</td>\n",
       "      <td>-0.013393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.072431</td>\n",
       "      <td>-0.253060</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.066722</td>\n",
       "      <td>0.109472</td>\n",
       "      <td>0.965269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689714</td>\n",
       "      <td>1.683939</td>\n",
       "      <td>2.016381</td>\n",
       "      <td>-16.657134</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>-0.033327</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.373604</td>\n",
       "      <td>-0.155816</td>\n",
       "      <td>-0.897658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.056604</td>\n",
       "      <td>-0.231385</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-1.007138</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.969862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423578</td>\n",
       "      <td>1.297306</td>\n",
       "      <td>3.256097</td>\n",
       "      <td>-15.261343</td>\n",
       "      <td>-0.194640</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.086670</td>\n",
       "      <td>-0.282515</td>\n",
       "      <td>0.350880</td>\n",
       "      <td>0.133144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:09:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>0.216379</td>\n",
       "      <td>29.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-1.113413</td>\n",
       "      <td>-0.042046</td>\n",
       "      <td>1.113367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727067</td>\n",
       "      <td>2.359666</td>\n",
       "      <td>4.585963</td>\n",
       "      <td>-37.607876</td>\n",
       "      <td>0.208946</td>\n",
       "      <td>-0.165622</td>\n",
       "      <td>-0.345881</td>\n",
       "      <td>-0.363368</td>\n",
       "      <td>0.068628</td>\n",
       "      <td>-0.514738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.098263</td>\n",
       "      <td>-0.077050</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.023045</td>\n",
       "      <td>-0.108588</td>\n",
       "      <td>1.027990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068666</td>\n",
       "      <td>0.350719</td>\n",
       "      <td>1.468776</td>\n",
       "      <td>-44.611247</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>-0.065165</td>\n",
       "      <td>-0.053319</td>\n",
       "      <td>-0.356827</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.140586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.091930</td>\n",
       "      <td>-0.082737</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.198306</td>\n",
       "      <td>-0.376106</td>\n",
       "      <td>0.689015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238445</td>\n",
       "      <td>0.761235</td>\n",
       "      <td>1.276669</td>\n",
       "      <td>-53.422491</td>\n",
       "      <td>-0.541296</td>\n",
       "      <td>-0.172060</td>\n",
       "      <td>-0.274417</td>\n",
       "      <td>0.098189</td>\n",
       "      <td>-0.138849</td>\n",
       "      <td>-0.378278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:12:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161285</td>\n",
       "      <td>0.113173</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.921368</td>\n",
       "      <td>0.067695</td>\n",
       "      <td>1.078017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059547</td>\n",
       "      <td>0.062108</td>\n",
       "      <td>0.369181</td>\n",
       "      <td>-66.879465</td>\n",
       "      <td>0.124796</td>\n",
       "      <td>-0.481211</td>\n",
       "      <td>0.085117</td>\n",
       "      <td>-0.152890</td>\n",
       "      <td>-0.021408</td>\n",
       "      <td>-0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:13:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.126593</td>\n",
       "      <td>0.060155</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.203777</td>\n",
       "      <td>0.114519</td>\n",
       "      <td>0.937105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704964</td>\n",
       "      <td>2.218546</td>\n",
       "      <td>3.687903</td>\n",
       "      <td>-80.824625</td>\n",
       "      <td>-0.044405</td>\n",
       "      <td>0.161449</td>\n",
       "      <td>-0.318536</td>\n",
       "      <td>-0.801035</td>\n",
       "      <td>0.157828</td>\n",
       "      <td>-0.222841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031625</td>\n",
       "      <td>-0.147547</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.185362</td>\n",
       "      <td>-0.092406</td>\n",
       "      <td>0.996789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081883</td>\n",
       "      <td>0.141936</td>\n",
       "      <td>0.992224</td>\n",
       "      <td>-82.516711</td>\n",
       "      <td>-0.050557</td>\n",
       "      <td>-0.095838</td>\n",
       "      <td>-0.376879</td>\n",
       "      <td>-0.184198</td>\n",
       "      <td>0.124989</td>\n",
       "      <td>1.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.164147</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-1.071139</td>\n",
       "      <td>-0.111148</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887421</td>\n",
       "      <td>2.581837</td>\n",
       "      <td>3.108687</td>\n",
       "      <td>-68.073476</td>\n",
       "      <td>-0.170508</td>\n",
       "      <td>-0.098457</td>\n",
       "      <td>-0.102227</td>\n",
       "      <td>0.121672</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>-0.121451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:16:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158850</td>\n",
       "      <td>0.229103</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.580852</td>\n",
       "      <td>0.308717</td>\n",
       "      <td>1.240138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655306</td>\n",
       "      <td>1.205921</td>\n",
       "      <td>4.759841</td>\n",
       "      <td>-68.443982</td>\n",
       "      <td>0.950501</td>\n",
       "      <td>-0.641671</td>\n",
       "      <td>0.192922</td>\n",
       "      <td>0.225859</td>\n",
       "      <td>0.385319</td>\n",
       "      <td>-0.580479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    minute  msymbol_ukey  DD.askSize  DD.bidSize  \\\n",
       "0   2020-01-01  04:00:00             1    0.153576    0.159888   \n",
       "1   2020-01-01  04:01:00             1    0.070277    0.170257   \n",
       "2   2020-01-01  04:02:00             1    0.132703    0.141176   \n",
       "3   2020-01-01  04:03:00             1    0.165413    0.215126   \n",
       "4   2020-01-01  04:04:00             1   -0.149525    0.029624   \n",
       "5   2020-01-01  04:05:00             1   -0.128483    0.044118   \n",
       "6   2020-01-01  04:06:00             1    0.235428    0.280623   \n",
       "7   2020-01-01  04:07:00             1   -0.072431   -0.253060   \n",
       "8   2020-01-01  04:08:00             1   -0.056604   -0.231385   \n",
       "9   2020-01-01  04:09:00             1   -0.026685    0.216379   \n",
       "10  2020-01-01  04:10:00             1   -0.098263   -0.077050   \n",
       "11  2020-01-01  04:11:00             1   -0.091930   -0.082737   \n",
       "12  2020-01-01  04:12:00             1    0.161285    0.113173   \n",
       "13  2020-01-01  04:13:00             1   -0.126593    0.060155   \n",
       "14  2020-01-01  04:14:00             1   -0.031625   -0.147547   \n",
       "15  2020-01-01  04:15:00             1   -0.164147    0.055756   \n",
       "16  2020-01-01  04:16:00             1    0.158850    0.229103   \n",
       "\n",
       "    active_seconds  ret_change_times  quantile_0  quantile_1  quantile_2  ...  \\\n",
       "0             32.0              28.0   -1.029904    0.040093    0.950497  ...   \n",
       "1             37.0              25.0   -0.823792    0.102571    1.140267  ...   \n",
       "2             23.0              28.0   -0.751911    0.447799    1.357787  ...   \n",
       "3             27.0              35.0   -0.775364    0.189733    1.158413  ...   \n",
       "4             28.0              34.0   -0.933860    0.088822    1.207721  ...   \n",
       "5             28.0              24.0   -1.148900   -0.050557    0.841266  ...   \n",
       "6             32.0              31.0   -1.057598   -0.060052    0.945063  ...   \n",
       "7             31.0              31.0   -1.066722    0.109472    0.965269  ...   \n",
       "8             26.0              27.0   -1.007138    0.259542    0.969862  ...   \n",
       "9             29.0              37.0   -1.113413   -0.042046    1.113367  ...   \n",
       "10            26.0              29.0   -1.023045   -0.108588    1.027990  ...   \n",
       "11            30.0              32.0   -1.198306   -0.376106    0.689015  ...   \n",
       "12            30.0              27.0   -0.921368    0.067695    1.078017  ...   \n",
       "13            28.0              31.0   -1.203777    0.114519    0.937105  ...   \n",
       "14            28.0              25.0   -1.185362   -0.092406    0.996789  ...   \n",
       "15            30.0              39.0   -1.071139   -0.111148    0.853360  ...   \n",
       "16            24.0              15.0   -0.580852    0.308717    1.240138  ...   \n",
       "\n",
       "    entropy_60_10  entropy_60_30  entropy_60_60  imbalance  vol_quantile_0  \\\n",
       "0             NaN            NaN            NaN   8.189473        0.034226   \n",
       "1        0.403585       0.755708       2.989781  14.810075        0.261117   \n",
       "2        3.346957       8.855843      12.950576  -1.988678        0.410844   \n",
       "3        3.521326      10.673072      21.194466  -5.424806        0.409813   \n",
       "4        2.831463       9.135907      19.285445  -8.638203       -0.224793   \n",
       "5        0.829005       3.566250      11.005239 -14.218954        0.105987   \n",
       "6        0.005229       0.005229       0.434104 -18.870400        0.102676   \n",
       "7        0.689714       1.683939       2.016381 -16.657134        0.049987   \n",
       "8        0.423578       1.297306       3.256097 -15.261343       -0.194640   \n",
       "9        0.727067       2.359666       4.585963 -37.607876        0.208946   \n",
       "10       0.068666       0.350719       1.468776 -44.611247        0.004357   \n",
       "11       0.238445       0.761235       1.276669 -53.422491       -0.541296   \n",
       "12       0.059547       0.062108       0.369181 -66.879465        0.124796   \n",
       "13       0.704964       2.218546       3.687903 -80.824625       -0.044405   \n",
       "14       0.081883       0.141936       0.992224 -82.516711       -0.050557   \n",
       "15       0.887421       2.581837       3.108687 -68.073476       -0.170508   \n",
       "16       0.655306       1.205921       4.759841 -68.443982        0.950501   \n",
       "\n",
       "    imbalance_quantile_0  vol_quantile_1  imbalance_quantile_1  \\\n",
       "0              -0.211545        0.029545              0.689109   \n",
       "1               0.150261       -0.006286             -0.257019   \n",
       "2               0.000086        0.533422             -0.884480   \n",
       "3              -0.123007       -0.247409             -0.501979   \n",
       "4               0.103901        0.154870             -0.173902   \n",
       "5               0.125208       -0.285584             -0.485725   \n",
       "6              -0.231962       -0.185992              0.235239   \n",
       "7              -0.033327        0.022358              0.373604   \n",
       "8               0.016368        0.086670             -0.282515   \n",
       "9              -0.165622       -0.345881             -0.363368   \n",
       "10             -0.065165       -0.053319             -0.356827   \n",
       "11             -0.172060       -0.274417              0.098189   \n",
       "12             -0.481211        0.085117             -0.152890   \n",
       "13              0.161449       -0.318536             -0.801035   \n",
       "14             -0.095838       -0.376879             -0.184198   \n",
       "15             -0.098457       -0.102227              0.121672   \n",
       "16             -0.641671        0.192922              0.225859   \n",
       "\n",
       "    vol_quantile_2  imbalance_quantile_2  \n",
       "0        -0.075620              0.379304  \n",
       "1         0.125186             -0.291971  \n",
       "2         0.026573              0.242825  \n",
       "3         0.262230              0.278925  \n",
       "4         0.259310             -0.057253  \n",
       "5        -0.215696             -0.144039  \n",
       "6        -0.056506             -0.013393  \n",
       "7        -0.155816             -0.897658  \n",
       "8         0.350880              0.133144  \n",
       "9         0.068628             -0.514738  \n",
       "10        0.009381              0.140586  \n",
       "11       -0.138849             -0.378278  \n",
       "12       -0.021408             -0.120600  \n",
       "13        0.157828             -0.222841  \n",
       "14        0.124989              1.061014  \n",
       "15       -0.000490             -0.121451  \n",
       "16        0.385319             -0.580479  \n",
       "\n",
       "[17 rows x 33 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'(1, 2, 5, 7)' into tuple\n",
    "x = 'feat_(1, 2, 5, 7)_erfs'\n",
    "x = x.split('_')\n",
    "#position of 'feat'\n",
    "x = x[x.index('feat') + 1]\n",
    "x = tuple([int(i) for i in x[1:-1].split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = [1, 2, 3, 4, 5]\n",
    "k = np.random.randn(5)\n",
    "np.array(pos)[np.isnan(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-21:\n",
      "Process SpawnPoolWorker-19:\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'job' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[222], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     res \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39mmap(job, \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m))\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(res)\n\u001b[0;32m---> 22\u001b[0m multicore()\n",
      "Cell \u001b[0;32mIn[222], line 19\u001b[0m, in \u001b[0;36mmulticore\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m#num of processes\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(mp\u001b[39m.\u001b[39mcpu_count())\n\u001b[0;32m---> 19\u001b[0m res \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(job, \u001b[39mrange\u001b[39;49m(\u001b[39m10\u001b[39;49m))\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(res)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#multiprocessing\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import numpy as np\n",
    "p = 5\n",
    "def job(x):\n",
    "    #do some job\n",
    "    #time.sleep(1)\n",
    "    return x ** 2\n",
    "\n",
    "def multicore():\n",
    "    #multiprocessing\n",
    "    #input: None\n",
    "    #output: None\n",
    "    #return None\n",
    "    pool = mp.Pool()\n",
    "    #num of processes\n",
    "    print(mp.cpu_count())\n",
    "    res = pool.map(job, range(10))\n",
    "    print(res)\n",
    "\n",
    "multicore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 30 17:30:48 EDT 2023\n"
     ]
    }
   ],
   "source": [
    "#systime time in command line\n",
    "!date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2, 1]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5]\n",
    "x[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
