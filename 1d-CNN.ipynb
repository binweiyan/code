{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 1d cnn model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1d(nn.Module):\n",
    "    #create a 1d cnn regression model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, kernel_size, layer_num, hidden_size,\n",
    "                  dropout=0.5, batch_norm=True):\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        super(CNN1d, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layer_num = layer_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.batch_norm = batch_norm\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(self.input_dim, self.hidden_size, self.kernel_size)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(self.hidden_size)])\n",
    "        for i in range(self.layer_num - 1):\n",
    "            self.convs.append(nn.Conv1d(self.hidden_size, self.hidden_size, self.kernel_size))\n",
    "            self.bns.append(nn.BatchNorm1d(self.hidden_size))\n",
    "        self.fc1 = nn.Linear(self.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        for conv in self.convs:\n",
    "            torch.nn.init.xavier_uniform_(conv.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        #output shape: (batch_size, 1)\n",
    "        x = x.transpose(1, 2)\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if self.batch_norm:\n",
    "                x = F.relu(self.bns[i](conv(x)))\n",
    "            else:\n",
    "                x = F.relu(conv(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc1(x[:, :, -1])\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        #predict the target value\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        #calculate loss\n",
    "        return F.mse_loss(self.forward(x), y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positional encoding\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #add positional encoding to the input\n",
    "    def __init__(self, input_len, input_dim, dropout=0.5):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pe = torch.zeros(self.input_len, self.input_dim)\n",
    "        position = torch.arange(0, self.input_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.input_dim, 2).float() * (-math.log(10000.0) / self.input_dim))\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0)\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        #output shape: (batch_size, input_len, input_dim)\n",
    "        x = x + self.pe\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    #create MULTIHEADATTENTION model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, num_heads, dropout=0.5):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.q_linear = nn.Linear(self.input_dim, self.hidden_size)\n",
    "        self.v_linear = nn.Linear(self.input_dim, self.hidden_size)\n",
    "        self.k_linear = nn.Linear(self.input_dim, self.hidden_size)\n",
    "        self.multihead_attn = nn.MultiheadAttention(self.hidden_size, self.num_heads)\n",
    "        self.out = nn.Linear(self.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #use positional encoding\n",
    "        x = PositionalEncoding(self.input_len, self.input_dim)(x)\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "        q = self.q_linear(x)\n",
    "        k = self.k_linear(x)\n",
    "        v = self.v_linear(x)\n",
    "        attn_output, _ = self.multihead_attn(q, k, v)\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        output = self.out(attn_output[:, -1, :])\n",
    "        return output\n",
    "\n",
    "    def predict(self, x):\n",
    "        #predict the target value\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        #calculate loss\n",
    "        return F.mse_loss(self.forward(x), y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 1000\n",
    "#test the model\n",
    "X = torch.randn(num_samples, 10)\n",
    "Y = torch.randn(num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "day = torch.randint(0, 30, (num_samples, 1))\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y, day, input_len=128):\n",
    "        #the input data is a 1d array, indicate the minute of the day\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.day = day\n",
    "        self.input_len = input_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #output previous self.input_len minutes data and target value\n",
    "        #if the there is no enough data in the same day, pad with 0\n",
    "        d = self.day[index]\n",
    "        start = index - self.input_len\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if self.day[start] != d:\n",
    "            while self.day[start] != d:\n",
    "                start += 1\n",
    "            #pad with 0 before start\n",
    "        if index - start < self.input_len:\n",
    "            x = torch.zeros(self.input_len, 10)\n",
    "            x[self.input_len - index + start: self.input_len] = self.X[start: index].clone()\n",
    "        else:\n",
    "            x = self.X[start: index]\n",
    "            \n",
    "        y = self.y[index].clone()\n",
    "        if x.shape != (self.input_len, 10):\n",
    "            print(x.shape, index, start)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "mydataset = MyDataset(X, Y, day, input_len=128)\n",
    "train_index = range(0, int(num_samples * 0.8))\n",
    "test_index = range(0, int(num_samples * 0.8))\n",
    "#test_index = range(int(num_samples * 0.8), num_samples)\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(mydataset, train_index)\n",
    "test_dataset = torch.utils.data.Subset(mydataset, test_index)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.8228365182876587\n",
      "test loss: 0.8946669101715088\n",
      "tensor([[ 1.0340e-01],\n",
      "        [ 2.7850e-01],\n",
      "        [-1.4524e+00],\n",
      "        [ 4.4976e-01],\n",
      "        [-1.6339e+00],\n",
      "        [-1.3247e+00],\n",
      "        [-1.0558e+00],\n",
      "        [ 4.0196e-01],\n",
      "        [-7.0728e-01],\n",
      "        [ 1.2954e+00],\n",
      "        [-4.4962e-01],\n",
      "        [-6.5616e-01],\n",
      "        [-8.1838e-01],\n",
      "        [-1.1353e+00],\n",
      "        [-2.5619e-01],\n",
      "        [-1.0760e+00],\n",
      "        [ 7.8851e-01],\n",
      "        [ 1.0763e+00],\n",
      "        [ 1.3571e+00],\n",
      "        [ 4.4242e-01],\n",
      "        [-4.4572e-01],\n",
      "        [ 2.8043e-01],\n",
      "        [ 3.5877e-01],\n",
      "        [ 1.8783e+00],\n",
      "        [ 1.5051e+00],\n",
      "        [-3.4021e-01],\n",
      "        [-5.4949e-01],\n",
      "        [ 1.7317e-01],\n",
      "        [ 1.0465e+00],\n",
      "        [-1.4213e+00],\n",
      "        [ 3.6202e-01],\n",
      "        [-1.1025e-01],\n",
      "        [ 7.2494e-01],\n",
      "        [ 3.5854e-01],\n",
      "        [-5.0771e-04],\n",
      "        [ 1.9347e+00],\n",
      "        [ 1.5889e+00],\n",
      "        [-2.3667e+00],\n",
      "        [-3.6950e-02],\n",
      "        [-8.2248e-01],\n",
      "        [ 7.1647e-01],\n",
      "        [ 7.7962e-01],\n",
      "        [ 1.7257e-01],\n",
      "        [ 6.0821e-01],\n",
      "        [-1.0232e+00],\n",
      "        [-1.7773e-01],\n",
      "        [ 1.5498e+00],\n",
      "        [ 7.0793e-02],\n",
      "        [-1.1134e+00],\n",
      "        [ 3.4349e-01],\n",
      "        [-1.4322e-01],\n",
      "        [ 4.0387e-01],\n",
      "        [ 3.0376e-01],\n",
      "        [ 1.2170e+00],\n",
      "        [-1.4570e+00],\n",
      "        [ 1.8085e+00],\n",
      "        [ 6.8632e-01],\n",
      "        [-2.3023e-01],\n",
      "        [-2.2654e-01],\n",
      "        [ 4.1071e-02],\n",
      "        [ 4.9921e-02],\n",
      "        [ 3.2685e-02],\n",
      "        [-2.0444e+00],\n",
      "        [ 1.6374e+00],\n",
      "        [-1.4544e+00],\n",
      "        [ 8.5951e-01],\n",
      "        [ 4.4657e-01],\n",
      "        [-9.2423e-01],\n",
      "        [-1.7205e-01],\n",
      "        [ 1.0191e+00],\n",
      "        [-2.6448e-02],\n",
      "        [-2.8194e-01],\n",
      "        [-1.1346e+00],\n",
      "        [ 7.2936e-01],\n",
      "        [ 5.5543e-01],\n",
      "        [ 1.1515e+00],\n",
      "        [-5.0131e-01],\n",
      "        [ 1.1914e+00],\n",
      "        [ 3.7980e-01],\n",
      "        [ 5.1284e-01],\n",
      "        [ 1.8305e-01],\n",
      "        [-1.9541e+00],\n",
      "        [-1.2494e+00],\n",
      "        [-1.6954e+00],\n",
      "        [-5.5621e-01],\n",
      "        [-8.4841e-01],\n",
      "        [-1.4554e+00],\n",
      "        [ 3.5563e-01],\n",
      "        [ 9.0890e-02],\n",
      "        [-1.0695e+00],\n",
      "        [ 6.7468e-01],\n",
      "        [-1.9957e-01],\n",
      "        [-1.1755e+00],\n",
      "        [ 7.8054e-01],\n",
      "        [-7.1696e-01],\n",
      "        [ 1.2993e+00],\n",
      "        [-3.0258e-01],\n",
      "        [ 9.0702e-02],\n",
      "        [-2.2925e+00],\n",
      "        [-1.4177e+00],\n",
      "        [-3.7047e-01],\n",
      "        [-2.2770e-01],\n",
      "        [-7.8727e-01],\n",
      "        [ 1.8685e-01],\n",
      "        [ 9.1393e-01],\n",
      "        [ 2.6189e-01],\n",
      "        [ 2.4244e-01],\n",
      "        [-9.0962e-01],\n",
      "        [-5.3509e-01],\n",
      "        [ 6.6842e-01],\n",
      "        [ 2.4178e-01],\n",
      "        [-1.9550e+00],\n",
      "        [-1.6321e-01],\n",
      "        [-3.4033e-01],\n",
      "        [-5.5562e-01],\n",
      "        [ 1.3842e+00],\n",
      "        [-1.0013e+00],\n",
      "        [-1.0763e-01],\n",
      "        [ 1.9645e-01],\n",
      "        [-9.1928e-01],\n",
      "        [ 1.5316e+00],\n",
      "        [-8.7260e-01],\n",
      "        [ 6.0190e-01],\n",
      "        [ 3.5085e-01],\n",
      "        [ 2.1091e-01],\n",
      "        [-4.0613e-01],\n",
      "        [-3.4780e-01],\n",
      "        [-6.3834e-01]])\n",
      "tensor([[ 0.5629],\n",
      "        [ 0.8994],\n",
      "        [-0.0697],\n",
      "        [-1.6787],\n",
      "        [ 0.4466],\n",
      "        [ 0.1608],\n",
      "        [-1.6091],\n",
      "        [-0.2770],\n",
      "        [-1.0444],\n",
      "        [ 1.3737],\n",
      "        [ 1.0291],\n",
      "        [-0.2102],\n",
      "        [ 0.9997],\n",
      "        [-0.0872],\n",
      "        [ 0.3519],\n",
      "        [-2.3902],\n",
      "        [-0.0653],\n",
      "        [ 0.4751],\n",
      "        [-1.4681],\n",
      "        [ 0.4077],\n",
      "        [ 1.3318],\n",
      "        [-0.0120],\n",
      "        [-0.7619],\n",
      "        [ 0.0793],\n",
      "        [ 0.1708],\n",
      "        [ 0.0194],\n",
      "        [ 2.2732],\n",
      "        [-1.6139],\n",
      "        [ 0.5526],\n",
      "        [-0.2433],\n",
      "        [-0.1244],\n",
      "        [ 0.3732],\n",
      "        [-0.2317],\n",
      "        [ 0.3774],\n",
      "        [ 1.6077],\n",
      "        [ 0.2474],\n",
      "        [-0.4739],\n",
      "        [ 2.4374],\n",
      "        [ 1.1933],\n",
      "        [ 0.5474],\n",
      "        [ 1.1698],\n",
      "        [-2.0962],\n",
      "        [ 1.3448],\n",
      "        [ 0.0313],\n",
      "        [ 1.0549],\n",
      "        [-0.3753],\n",
      "        [ 0.8422],\n",
      "        [ 1.4154],\n",
      "        [ 0.5443],\n",
      "        [ 1.2091],\n",
      "        [-0.2455],\n",
      "        [-0.6216],\n",
      "        [ 1.0590],\n",
      "        [ 0.6838],\n",
      "        [ 0.5183],\n",
      "        [ 0.0749],\n",
      "        [ 0.7322],\n",
      "        [ 0.4813],\n",
      "        [-0.5633],\n",
      "        [ 0.6141],\n",
      "        [ 1.2730],\n",
      "        [-0.6746],\n",
      "        [ 0.3315],\n",
      "        [ 0.9671],\n",
      "        [-0.9477],\n",
      "        [ 0.0460],\n",
      "        [-0.0921],\n",
      "        [-0.0504],\n",
      "        [-0.6088],\n",
      "        [-0.2328],\n",
      "        [-0.5696],\n",
      "        [-1.3736],\n",
      "        [ 0.0124],\n",
      "        [ 1.1118],\n",
      "        [ 1.6922],\n",
      "        [-0.3692],\n",
      "        [ 1.6868],\n",
      "        [-1.8842],\n",
      "        [ 0.8042],\n",
      "        [ 0.7808],\n",
      "        [-2.1673],\n",
      "        [ 0.0034],\n",
      "        [-0.4615],\n",
      "        [-0.0317],\n",
      "        [ 0.5957],\n",
      "        [ 0.8644],\n",
      "        [-0.1979],\n",
      "        [-1.3669],\n",
      "        [ 0.0923],\n",
      "        [-0.1382],\n",
      "        [ 0.2224],\n",
      "        [-0.2051],\n",
      "        [-1.1927],\n",
      "        [-0.2751],\n",
      "        [-2.7369],\n",
      "        [-0.2496],\n",
      "        [ 1.8099],\n",
      "        [-0.2697],\n",
      "        [ 0.4398],\n",
      "        [-1.3968],\n",
      "        [-0.9830],\n",
      "        [-1.0617],\n",
      "        [-0.6988],\n",
      "        [-0.1251],\n",
      "        [ 0.9059],\n",
      "        [ 0.6907],\n",
      "        [ 1.0002],\n",
      "        [ 0.1416],\n",
      "        [ 1.5862],\n",
      "        [ 0.5800],\n",
      "        [ 0.8935],\n",
      "        [ 0.1259],\n",
      "        [-1.7846],\n",
      "        [ 0.6852],\n",
      "        [-2.7217],\n",
      "        [-1.2881],\n",
      "        [ 0.6736],\n",
      "        [ 0.0496],\n",
      "        [-0.2735],\n",
      "        [-1.9438],\n",
      "        [-0.2568],\n",
      "        [ 0.3680],\n",
      "        [-0.2416],\n",
      "        [-0.4682],\n",
      "        [ 0.2161],\n",
      "        [ 0.8669],\n",
      "        [ 0.5656],\n",
      "        [-0.0433]])\n",
      "tensor([[ 0.3672],\n",
      "        [ 1.3356],\n",
      "        [-1.1602],\n",
      "        [ 0.9212],\n",
      "        [-0.0072],\n",
      "        [-0.1631],\n",
      "        [-0.2757],\n",
      "        [ 0.8767],\n",
      "        [ 0.8649],\n",
      "        [ 1.2786],\n",
      "        [-0.9195],\n",
      "        [-1.2239],\n",
      "        [-1.3815],\n",
      "        [ 0.6115],\n",
      "        [-0.0784],\n",
      "        [ 0.6220],\n",
      "        [ 0.3945],\n",
      "        [-1.2338],\n",
      "        [ 0.2564],\n",
      "        [-1.7458],\n",
      "        [ 0.9902],\n",
      "        [-1.1863],\n",
      "        [ 0.6820],\n",
      "        [-1.0949],\n",
      "        [-1.5378],\n",
      "        [ 0.2281],\n",
      "        [ 0.6558],\n",
      "        [ 0.7541],\n",
      "        [-1.1555],\n",
      "        [ 0.0672],\n",
      "        [ 1.9661],\n",
      "        [-1.1345],\n",
      "        [-0.8513],\n",
      "        [-0.4864],\n",
      "        [-1.2674],\n",
      "        [ 0.2063],\n",
      "        [-1.1774],\n",
      "        [-1.4663],\n",
      "        [ 0.7624],\n",
      "        [ 0.4631],\n",
      "        [ 0.8592],\n",
      "        [-0.4802],\n",
      "        [ 1.0189],\n",
      "        [ 0.4632],\n",
      "        [-0.0998],\n",
      "        [-0.2074],\n",
      "        [ 0.1937],\n",
      "        [ 0.6818],\n",
      "        [ 0.1172],\n",
      "        [ 0.5696],\n",
      "        [ 0.9214],\n",
      "        [ 0.0820],\n",
      "        [ 0.3024],\n",
      "        [ 0.4660],\n",
      "        [-0.0249],\n",
      "        [-0.3679],\n",
      "        [ 1.4279],\n",
      "        [ 1.2683],\n",
      "        [ 1.0240],\n",
      "        [-2.1870],\n",
      "        [-1.2220],\n",
      "        [ 0.8883],\n",
      "        [-1.4910],\n",
      "        [ 0.5567],\n",
      "        [-0.2693],\n",
      "        [ 1.3104],\n",
      "        [-0.9365],\n",
      "        [ 0.2186],\n",
      "        [-0.9516],\n",
      "        [ 0.0185],\n",
      "        [ 0.1762],\n",
      "        [-1.4053],\n",
      "        [ 1.3370],\n",
      "        [-1.2757],\n",
      "        [ 0.3969],\n",
      "        [ 1.2572],\n",
      "        [-1.0496],\n",
      "        [ 0.3043],\n",
      "        [-1.5876],\n",
      "        [ 0.4342],\n",
      "        [ 1.2957],\n",
      "        [ 1.2266],\n",
      "        [-1.8339],\n",
      "        [ 0.0447],\n",
      "        [ 0.6809],\n",
      "        [-0.2213],\n",
      "        [ 2.0980],\n",
      "        [ 0.6103],\n",
      "        [ 1.1298],\n",
      "        [-0.6627],\n",
      "        [ 2.2620],\n",
      "        [ 0.4884],\n",
      "        [-0.7240],\n",
      "        [ 0.3810],\n",
      "        [ 0.5069],\n",
      "        [-2.2130],\n",
      "        [-1.1780],\n",
      "        [-2.6033],\n",
      "        [ 0.2149],\n",
      "        [-1.8002],\n",
      "        [-1.1459],\n",
      "        [ 0.2706],\n",
      "        [-0.4071],\n",
      "        [-0.6850],\n",
      "        [ 0.9804],\n",
      "        [ 0.4759],\n",
      "        [-0.1326],\n",
      "        [ 1.2565],\n",
      "        [ 0.3114],\n",
      "        [ 0.5747],\n",
      "        [ 1.0616],\n",
      "        [ 0.2887],\n",
      "        [-0.6485],\n",
      "        [ 0.3312],\n",
      "        [-0.2501],\n",
      "        [-0.0367],\n",
      "        [-0.2399],\n",
      "        [ 0.8638],\n",
      "        [ 1.7307],\n",
      "        [ 0.7239],\n",
      "        [-1.1971],\n",
      "        [-1.6761],\n",
      "        [ 0.9149],\n",
      "        [ 0.1728],\n",
      "        [-0.7640],\n",
      "        [ 0.8584],\n",
      "        [ 0.2713],\n",
      "        [ 0.8129]])\n",
      "tensor([[-0.7017],\n",
      "        [ 0.8879],\n",
      "        [ 0.1820],\n",
      "        [ 1.1084],\n",
      "        [ 0.7298],\n",
      "        [-3.5094],\n",
      "        [-0.7542],\n",
      "        [ 0.3439],\n",
      "        [-0.2413],\n",
      "        [ 0.5410],\n",
      "        [ 0.2553],\n",
      "        [-1.2118],\n",
      "        [-0.1929],\n",
      "        [-0.2287],\n",
      "        [ 0.5685],\n",
      "        [ 2.3071],\n",
      "        [-1.2228],\n",
      "        [ 1.7918],\n",
      "        [ 0.4055],\n",
      "        [ 0.7615],\n",
      "        [ 1.3729],\n",
      "        [-0.4800],\n",
      "        [-0.8590],\n",
      "        [ 0.0315],\n",
      "        [ 1.0133],\n",
      "        [-0.4374],\n",
      "        [-1.0356],\n",
      "        [ 0.3276],\n",
      "        [ 0.7935],\n",
      "        [-0.1140],\n",
      "        [ 0.1427],\n",
      "        [ 0.7968],\n",
      "        [-0.8902],\n",
      "        [ 0.1007],\n",
      "        [ 0.7429],\n",
      "        [-1.9194],\n",
      "        [-1.4074],\n",
      "        [-0.4045],\n",
      "        [ 0.8320],\n",
      "        [-0.0458],\n",
      "        [-0.5017],\n",
      "        [ 1.1107],\n",
      "        [-0.7806],\n",
      "        [-0.5248],\n",
      "        [-1.3278],\n",
      "        [ 0.7754],\n",
      "        [ 1.8925],\n",
      "        [ 1.6028],\n",
      "        [-0.6839],\n",
      "        [ 0.1255],\n",
      "        [ 0.6889],\n",
      "        [ 1.3510],\n",
      "        [-0.5306],\n",
      "        [-0.6743],\n",
      "        [ 0.8003],\n",
      "        [ 1.0411],\n",
      "        [-0.8765],\n",
      "        [ 0.6544],\n",
      "        [-0.4352],\n",
      "        [ 1.3690],\n",
      "        [-0.8230],\n",
      "        [-0.2658],\n",
      "        [-1.6830],\n",
      "        [-1.0034],\n",
      "        [-0.4307],\n",
      "        [ 0.0689],\n",
      "        [ 1.3386],\n",
      "        [-0.0565],\n",
      "        [-0.6830],\n",
      "        [-1.1905],\n",
      "        [-1.0895],\n",
      "        [ 0.6841],\n",
      "        [-0.5032],\n",
      "        [-1.6981],\n",
      "        [ 1.2332],\n",
      "        [-0.1113],\n",
      "        [ 0.7388],\n",
      "        [-0.7298],\n",
      "        [ 1.2321],\n",
      "        [-2.4803],\n",
      "        [-1.3291],\n",
      "        [-0.0112],\n",
      "        [-0.5087],\n",
      "        [-1.1490],\n",
      "        [ 0.0268],\n",
      "        [-0.6548],\n",
      "        [ 0.9325],\n",
      "        [ 0.6323],\n",
      "        [ 0.8160],\n",
      "        [-0.6603],\n",
      "        [ 0.6693],\n",
      "        [-1.2199],\n",
      "        [-0.0406],\n",
      "        [ 0.6958],\n",
      "        [-1.5979],\n",
      "        [-1.2242],\n",
      "        [-3.3883],\n",
      "        [-0.1753],\n",
      "        [ 0.6383],\n",
      "        [ 0.2093],\n",
      "        [-1.3478],\n",
      "        [ 0.2742],\n",
      "        [ 0.4841],\n",
      "        [ 0.3168],\n",
      "        [ 1.4745],\n",
      "        [-1.5166],\n",
      "        [ 2.0431],\n",
      "        [ 0.2897],\n",
      "        [ 1.1008],\n",
      "        [ 0.1116],\n",
      "        [ 0.8097],\n",
      "        [ 0.3142],\n",
      "        [-0.3651],\n",
      "        [ 0.1355],\n",
      "        [ 1.0724],\n",
      "        [ 0.3034],\n",
      "        [-0.2845],\n",
      "        [ 0.3893],\n",
      "        [-0.6240],\n",
      "        [-1.0468],\n",
      "        [-1.9054],\n",
      "        [ 1.7016],\n",
      "        [ 1.6799],\n",
      "        [ 0.1779],\n",
      "        [-0.2128],\n",
      "        [ 0.9267],\n",
      "        [ 0.0956],\n",
      "        [ 0.4737]])\n",
      "tensor([[-0.2435],\n",
      "        [-0.7206],\n",
      "        [-0.0340],\n",
      "        [ 1.0850],\n",
      "        [ 0.3596],\n",
      "        [-0.3526],\n",
      "        [-0.9506],\n",
      "        [-0.5285],\n",
      "        [ 1.9024],\n",
      "        [-3.0953],\n",
      "        [ 0.0254],\n",
      "        [ 2.2815],\n",
      "        [ 0.8139],\n",
      "        [ 0.9565],\n",
      "        [-0.7575],\n",
      "        [-0.8886],\n",
      "        [-2.6662],\n",
      "        [ 0.3126],\n",
      "        [-0.2665],\n",
      "        [ 1.0109],\n",
      "        [ 0.2374],\n",
      "        [-2.2524],\n",
      "        [-1.6506],\n",
      "        [ 1.7304],\n",
      "        [-1.6621],\n",
      "        [-0.7677],\n",
      "        [ 1.3477],\n",
      "        [-0.1037],\n",
      "        [ 0.4661],\n",
      "        [-0.3188],\n",
      "        [-0.0386],\n",
      "        [ 1.4488],\n",
      "        [-0.5102],\n",
      "        [-1.7707],\n",
      "        [-0.7425],\n",
      "        [-0.6747],\n",
      "        [ 1.2679],\n",
      "        [ 1.7278],\n",
      "        [-0.0167],\n",
      "        [ 0.2646],\n",
      "        [ 2.3036],\n",
      "        [-0.9117],\n",
      "        [ 0.0967],\n",
      "        [-1.2778],\n",
      "        [ 0.7310],\n",
      "        [ 0.6193],\n",
      "        [ 1.4527],\n",
      "        [ 0.3671],\n",
      "        [ 0.6105],\n",
      "        [-1.3605],\n",
      "        [-0.0955],\n",
      "        [-0.1346],\n",
      "        [ 2.0368],\n",
      "        [-1.0118],\n",
      "        [-0.3156],\n",
      "        [-1.9066],\n",
      "        [ 0.2694],\n",
      "        [-2.1576],\n",
      "        [-0.5007],\n",
      "        [ 0.6073],\n",
      "        [ 0.8497],\n",
      "        [ 1.4071],\n",
      "        [-1.3431],\n",
      "        [-0.3556],\n",
      "        [ 1.2892],\n",
      "        [ 0.1982],\n",
      "        [ 0.2079],\n",
      "        [-0.9908],\n",
      "        [-1.8788],\n",
      "        [-1.1249],\n",
      "        [-0.5467],\n",
      "        [-1.8866],\n",
      "        [ 1.6751],\n",
      "        [ 0.3660],\n",
      "        [ 0.1217],\n",
      "        [ 0.6108],\n",
      "        [ 0.0602],\n",
      "        [ 0.6894],\n",
      "        [-0.8698],\n",
      "        [ 0.2563],\n",
      "        [ 0.6772],\n",
      "        [ 0.3071],\n",
      "        [-0.5729],\n",
      "        [ 0.2568],\n",
      "        [-1.1023],\n",
      "        [ 0.3687],\n",
      "        [-0.9342],\n",
      "        [-0.8984],\n",
      "        [-1.0948],\n",
      "        [-0.0055],\n",
      "        [-0.5138],\n",
      "        [-1.8293],\n",
      "        [-1.1427],\n",
      "        [-0.7670],\n",
      "        [ 1.2847],\n",
      "        [ 0.8393],\n",
      "        [ 0.0881],\n",
      "        [ 0.2550],\n",
      "        [ 0.0901],\n",
      "        [-1.6456],\n",
      "        [ 0.3728],\n",
      "        [-1.3637],\n",
      "        [-0.2893],\n",
      "        [ 0.0949],\n",
      "        [ 0.2511],\n",
      "        [ 1.7260],\n",
      "        [-0.9275],\n",
      "        [-0.1342],\n",
      "        [ 0.4417],\n",
      "        [-1.2319],\n",
      "        [ 1.9510],\n",
      "        [-1.2148],\n",
      "        [ 1.9298],\n",
      "        [-0.9859],\n",
      "        [-0.3630],\n",
      "        [ 0.1784],\n",
      "        [-0.2020],\n",
      "        [-1.6256],\n",
      "        [ 0.0746],\n",
      "        [ 0.7813],\n",
      "        [-0.1350],\n",
      "        [ 0.2068],\n",
      "        [ 0.5064],\n",
      "        [ 1.1068],\n",
      "        [-0.8219],\n",
      "        [ 0.2439],\n",
      "        [-0.3705],\n",
      "        [-0.4728]])\n",
      "tensor([[-0.7072],\n",
      "        [-0.3159],\n",
      "        [-0.4516],\n",
      "        [ 0.4544],\n",
      "        [-0.1116],\n",
      "        [ 0.4519],\n",
      "        [-1.0282],\n",
      "        [-0.9932],\n",
      "        [ 0.0803],\n",
      "        [ 1.3832],\n",
      "        [-0.3693],\n",
      "        [ 0.4110],\n",
      "        [-0.3261],\n",
      "        [ 0.2202],\n",
      "        [ 0.5542],\n",
      "        [-0.3880],\n",
      "        [-0.5008],\n",
      "        [-0.3726],\n",
      "        [-0.2118],\n",
      "        [-0.6049],\n",
      "        [-0.8174],\n",
      "        [ 1.0188],\n",
      "        [ 0.1852],\n",
      "        [-0.3092],\n",
      "        [-0.6294],\n",
      "        [ 0.1440],\n",
      "        [-0.6757],\n",
      "        [-1.1432],\n",
      "        [-0.5919],\n",
      "        [ 1.3100],\n",
      "        [ 0.9541],\n",
      "        [ 0.8995],\n",
      "        [-0.1491],\n",
      "        [ 1.0101],\n",
      "        [ 0.4540],\n",
      "        [ 0.2839],\n",
      "        [ 0.6566],\n",
      "        [ 0.6739],\n",
      "        [ 1.7621],\n",
      "        [ 0.4776],\n",
      "        [ 1.3134],\n",
      "        [ 0.3463],\n",
      "        [ 0.5551],\n",
      "        [-0.1386],\n",
      "        [-0.2577],\n",
      "        [ 0.9121],\n",
      "        [-0.2587],\n",
      "        [-0.1129],\n",
      "        [ 0.4492],\n",
      "        [ 0.9913],\n",
      "        [-0.6750],\n",
      "        [-2.0059],\n",
      "        [ 0.1283],\n",
      "        [ 1.0250],\n",
      "        [ 1.2566],\n",
      "        [-0.5331],\n",
      "        [ 0.8717],\n",
      "        [ 0.0388],\n",
      "        [ 2.2893],\n",
      "        [-0.2700],\n",
      "        [-0.0856],\n",
      "        [-0.3800],\n",
      "        [-0.3688],\n",
      "        [-0.6859],\n",
      "        [ 0.0459],\n",
      "        [-0.7918],\n",
      "        [ 0.6230],\n",
      "        [-0.7661],\n",
      "        [-0.1971],\n",
      "        [ 0.2727],\n",
      "        [-0.6001],\n",
      "        [ 1.2925],\n",
      "        [ 0.5957],\n",
      "        [ 0.3410],\n",
      "        [-1.1995],\n",
      "        [ 0.0788],\n",
      "        [-0.7364],\n",
      "        [ 0.1350],\n",
      "        [ 0.5369],\n",
      "        [ 0.1885],\n",
      "        [ 0.7997],\n",
      "        [ 1.1563],\n",
      "        [ 0.5430],\n",
      "        [-0.1596],\n",
      "        [-1.9034],\n",
      "        [ 0.1120],\n",
      "        [ 0.7470],\n",
      "        [-0.2275],\n",
      "        [ 0.8279],\n",
      "        [ 0.5933],\n",
      "        [ 0.0624],\n",
      "        [ 1.0839],\n",
      "        [ 0.8458],\n",
      "        [ 1.7419],\n",
      "        [-0.3089],\n",
      "        [-1.3499],\n",
      "        [ 1.1438],\n",
      "        [-1.8613],\n",
      "        [ 0.5991],\n",
      "        [-0.1962],\n",
      "        [ 0.3138],\n",
      "        [ 0.7808],\n",
      "        [ 0.3379],\n",
      "        [ 0.8604],\n",
      "        [-0.4029],\n",
      "        [ 2.0176],\n",
      "        [ 0.1728],\n",
      "        [-0.0742],\n",
      "        [ 0.6758],\n",
      "        [ 0.7184],\n",
      "        [ 1.4272],\n",
      "        [ 0.4487],\n",
      "        [ 0.7642],\n",
      "        [-1.4719],\n",
      "        [ 1.6250],\n",
      "        [ 0.7147],\n",
      "        [ 1.1340],\n",
      "        [ 1.2946],\n",
      "        [-0.4707],\n",
      "        [ 1.6981],\n",
      "        [ 0.2994],\n",
      "        [-0.8277],\n",
      "        [ 0.8286],\n",
      "        [-1.5146],\n",
      "        [ 1.8301],\n",
      "        [ 0.5302],\n",
      "        [ 0.0371],\n",
      "        [-0.0319]])\n",
      "tensor([[ 0.5205],\n",
      "        [ 0.2266],\n",
      "        [-0.8256],\n",
      "        [-0.1090],\n",
      "        [-0.7377],\n",
      "        [-0.4314],\n",
      "        [-1.8574],\n",
      "        [ 1.6924],\n",
      "        [ 0.8930],\n",
      "        [-1.1992],\n",
      "        [-0.6656],\n",
      "        [-0.3182],\n",
      "        [ 2.5235],\n",
      "        [ 0.2497],\n",
      "        [-0.3657],\n",
      "        [ 0.7290],\n",
      "        [ 0.0333],\n",
      "        [ 0.1404],\n",
      "        [ 0.9937],\n",
      "        [-0.4480],\n",
      "        [-0.4931],\n",
      "        [ 1.3574],\n",
      "        [-1.7921],\n",
      "        [-2.4691],\n",
      "        [-2.8585],\n",
      "        [ 0.4597],\n",
      "        [ 0.6425],\n",
      "        [ 0.8055],\n",
      "        [ 1.8695],\n",
      "        [-0.2373],\n",
      "        [-1.4508],\n",
      "        [-0.7470]])\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Attention(input_dim=10, input_len=128, hidden_size=64, num_heads=8).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x, y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(\"epoch: {}, loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = model.loss(x, y)\n",
    "            print(\"test loss: {}\".format(loss.item()))\n",
    "            break\n",
    "    model.train()\n",
    "\n",
    "pred = torch.zeros(len(test_dataset), 1)\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred[i * 128: i * 128 + len(x)] = model.predict(x)\n",
    "        print(y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7947)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred - Y[test_index]).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 800 is out of bounds for dimension 0 with size 72",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[39m-\u001b[39m y[test_index]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 800 is out of bounds for dimension 0 with size 72"
     ]
    }
   ],
   "source": [
    "pred - y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scores(pred, target, days):\n",
    "#     pred_group, ground_group, corr = groupbyday(pred, target, days)\n",
    "#     sharpes = sharpeyear(corr, list(pred_group.keys()))\n",
    "#     return corr.mean(), sharpes\n",
    "    \n",
    "# def fitmodel(model, training_data, test_data, training_target, test_target, training_days, test_days):\n",
    "#     for train, test, train_target, test_target, train_day, test_day in zip(training_data, test_data, training_target, test_target, training_days, test_days):\n",
    "#         model.fit(train, train_target)\n",
    "#         pred_train = model.predict(train)\n",
    "#         pred_test = model.predict(test)\n",
    "#         pnl_train, sharpe_train = scores(pred_train, train_target,train_day)\n",
    "#         pnl_test, sharpe_test = scores(pred_test, test_target, test_day)\n",
    "#         return pnl_train, sharpe_train, pnl_test, sharpe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model = Attention(input_dim=10, input_len=128, hidden_size=64, num_heads=8)\n",
    "def trainmodel(model, data, target, days, train_index, test_index, epochs=100):\n",
    "    #get dataset\n",
    "    mydataset = MyDataset(data, target, days)\n",
    "    train_index = range(0, int(num_samples * 0.8))\n",
    "    test_index = range(int(num_samples * 0.8), num_samples)\n",
    "\n",
    "    train_dataset = torch.utils.data.Subset(mydataset, train_index)\n",
    "    test_dataset = torch.utils.data.Subset(mydataset, test_index)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "    #train the model\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(x, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(\"epoch: {}, loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "        #evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                x, y = data\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                loss = model.loss(x, y)\n",
    "                print(\"test loss: {}\".format(loss.item()))\n",
    "    \n",
    "    pred = np.zeros(len(test_dataset), 1)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred[i * 128: i * 128 + len(x)] = model.predict(x)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.7170489430427551\n",
      "test loss: 1.0776116847991943\n",
      "epoch: 1, loss: 1.1976138353347778\n",
      "test loss: 1.0752530097961426\n",
      "epoch: 2, loss: 1.0374078750610352\n",
      "test loss: 1.1087355613708496\n",
      "epoch: 3, loss: 1.279557466506958\n",
      "test loss: 1.078538179397583\n",
      "epoch: 4, loss: 0.9948725700378418\n",
      "test loss: 1.057780385017395\n",
      "epoch: 5, loss: 0.9333169460296631\n",
      "test loss: 1.0650285482406616\n",
      "epoch: 6, loss: 0.7389782667160034\n",
      "test loss: 1.0728360414505005\n",
      "epoch: 7, loss: 1.4094113111495972\n",
      "test loss: 1.0735621452331543\n",
      "epoch: 8, loss: 0.7442904114723206\n",
      "test loss: 1.056931734085083\n",
      "epoch: 9, loss: 0.6093248128890991\n",
      "test loss: 1.112714409828186\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainmodel(model, X, y, day, train_index, test_index, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[63], line 46\u001b[0m, in \u001b[0;36mtrainmodel\u001b[0;34m(model, data, target, days, train_index, test_index, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     45\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 46\u001b[0m         pred[i] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x)\n\u001b[1;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m pred\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "trainmodel(model, X, y, day, train_index, test_index, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
