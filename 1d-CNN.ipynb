{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 1d cnn model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1d(nn.Module):\n",
    "    #create a 1d cnn regression model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, kernel_size, layer_num, hidden_size,\n",
    "                  dropout=0.5, batch_norm=True):\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        super(CNN1d, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layer_num = layer_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.batch_norm = batch_norm\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(self.input_dim, self.hidden_size, self.kernel_size, padding=self.kernel_size // 2)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(self.hidden_size)])\n",
    "        for i in range(self.layer_num - 1):\n",
    "            self.convs.append(nn.Conv1d(self.hidden_size, self.hidden_size, self.kernel_size, padding=self.kernel_size // 2))\n",
    "            self.bns.append(nn.BatchNorm1d(self.hidden_size))\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_len * self.hidden_size, 74)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        for conv in self.convs:\n",
    "            torch.nn.init.xavier_uniform_(conv.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        #output shape: (batch_size, 1)\n",
    "        x = x.transpose(1, 2)\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if self.batch_norm:\n",
    "                x = F.relu(self.bns[i](conv(x)))\n",
    "            else:\n",
    "                x = F.relu(conv(x))\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = x.view(-1, (self.input_len * self.hidden_size))\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        #predict the target value\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        #calculate loss\n",
    "        return F.mse_loss(self.forward(x), y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positional encoding\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #add positional encoding to the input\n",
    "    def __init__(self, input_len, input_dim, dropout=0.5):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pe = torch.zeros(self.input_len, self.input_dim)\n",
    "        position = torch.arange(0, self.input_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.input_dim, 2).float() * (-math.log(10000.0) / self.input_dim))\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0)\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        #input shape: (batch_size, input_len, input_dim)\n",
    "        #output shape: (batch_size, input_len, input_dim)\n",
    "        x = x + self.pe\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    #create MULTIHEADATTENTION model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, num_heads, layer_num, dropout=0.5):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        #embedding\n",
    "\n",
    "        self.embedding = nn.Linear(self.input_dim, self.hidden_size)\n",
    "        self.q_linears = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for i in range(self.layer_num)])\n",
    "        self.k_linears = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for i in range(self.layer_num)])\n",
    "        self.v_linears = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for i in range(self.layer_num)])\n",
    "        self.multihead_attns = nn.ModuleList([nn.MultiheadAttention(self.hidden_size, self.num_heads) for i in range(self.layer_num)])\n",
    "        self.norms = nn.ModuleList([nn.BatchNorm1d(self.input_len) for i in range(self.layer_num)])\n",
    "        self.out = nn.Linear(self.hidden_size * self.input_len, 74)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pe = torch.zeros(self.input_len, self.hidden_size)\n",
    "        position = torch.arange(0, self.input_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_size, 2).float() * (-math.log(10000.0) / self.hidden_size))\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0)\n",
    "        self.pe.requires_grad = False\n",
    "        self.init_weights()\n",
    "        self.mean = nn.Parameter(torch.zeros(74))\n",
    "        self.std = nn.Parameter(torch.ones(74))\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.out.weight)\n",
    "        \n",
    "    def positional_encoding(self, x):\n",
    "        #use positional encoding\n",
    "        x = x + self.pe.to(x.device)\n",
    "        return self.dropout(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        #use positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "        for i in range(self.layer_num):\n",
    "            q = self.q_linears[i](x)\n",
    "            k = self.k_linears[i](x)\n",
    "            v = self.v_linears[i](x)\n",
    "            x, _ = self.multihead_attns[i](q, k, v)\n",
    "            x = self.norms[i](x)\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(bs, -1)\n",
    "        x = self.out(x)\n",
    "        x = (x - self.mean) / self.std\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        #calculate loss\n",
    "        return F.mse_loss(self.forward(x), y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 1000\n",
    "#test the model\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "Y = torch.randn(num_samples, 74)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "day = torch.randint(0, 30, (num_samples, 1))\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y, day, input_len=128):\n",
    "        #the input data is a 1d array, indicate the minute of the day\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.day = day\n",
    "        self.input_len = input_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #output previous self.input_len minutes data and target value\n",
    "        #if the there is no enough data in the same day, pad with 0\n",
    "        d = self.day[index]\n",
    "        start = index - self.input_len\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if self.day[start] != d:\n",
    "            while self.day[start] != d:\n",
    "                start += 1\n",
    "            #pad with 0 before start\n",
    "        if index - start < self.input_len:\n",
    "            x = torch.zeros(self.input_len, self.X.shape[1])\n",
    "            x[self.input_len - index + start: self.input_len] = self.X[start: index].clone()\n",
    "        else:\n",
    "            x = self.X[start: index]\n",
    "            \n",
    "        y = self.y[index].clone()\n",
    "        if x.shape != (self.input_len, self.X.shape[1]):\n",
    "            print(x.shape, index, start)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "mydataset = MyDataset(X, Y, day, input_len=120)\n",
    "train_index = range(0, int(num_samples * 0.8))\n",
    "test_index = range(0, int(num_samples * 0.8))\n",
    "#test_index = range(int(num_samples * 0.8), num_samples)\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(mydataset, train_index)\n",
    "test_dataset = torch.utils.data.Subset(mydataset, test_index)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 74, 3], expected input[128, 296, 120] to have 74 channels, but got 296 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m     p \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     20\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(p, y) \u001b[39m+\u001b[39m \u001b[39m0.01\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msum(model\u001b[39m.\u001b[39mfc1\u001b[39m.\u001b[39mweight \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m     21\u001b[0m     prediction\u001b[39m.\u001b[39mappend(p)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m, in \u001b[0;36mCNN1d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m i, conv \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_norm:\n\u001b[0;32m---> 44\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbns[i](conv(x)))\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(conv(x))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    304\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 74, 3], expected input[128, 296, 120] to have 74 channels, but got 296 channels instead"
     ]
    }
   ],
   "source": [
    "#train the model with 4 GPUs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "model = CNN1d(input_len=120, input_dim=74, kernel_size=3, layer_num=3, hidden_size=128, dropout=0.5, batch_norm=True)\n",
    "def correlation_t(x, y):\n",
    "    return torch.sum(x * y) / (torch.sqrt(torch.sum(x * x)) * torch.sqrt(torch.sum(y * y)))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    prediction = []\n",
    "    ground_truth = []\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        p = model(x)\n",
    "        loss = F.mse_loss(p, y) + 0.01 * torch.sum(model.fc1.weight ** 2)\n",
    "        prediction.append(p)\n",
    "        ground_truth.append(y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, loss.item())\n",
    "    prediction = torch.cat(prediction, dim=0)\n",
    "    ground_truth = torch.cat(ground_truth, dim=0)\n",
    "    print(prediction.shape, ground_truth.shape)\n",
    "    print(epoch, correlation_t(prediction, ground_truth).item())\n",
    "\n",
    "#the number of gpu \n",
    "print(torch.cuda.device_count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    #create MLP model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, layer_num, dropout=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        #embedding\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_dim, self.hidden_size)])\n",
    "        self.norms = nn.ModuleList([nn.BatchNorm1d(self.input_len)])\n",
    "\n",
    "        for i in range(self.layer_num - 1):\n",
    "            self.linears.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            self.norms.append(nn.BatchNorm1d(self.input_len))\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size * self.input_len, 74)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "        self.mean = nn.Parameter(torch.zeros(74))\n",
    "        self.std = nn.Parameter(torch.ones(74))\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "\n",
    "        for i in range(self.layer_num):\n",
    "            x = self.linears[i](x)\n",
    "            x = self.norms[i](x)\n",
    "            x = self.dropout(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = x.view(bs, -1)\n",
    "        x = self.out(x)\n",
    "        x = (x - self.mean) / self.std\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    #create RNN model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, layer_num, dropout=0.5, bidirectional=True):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        #embedding\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn = nn.GRU(self.input_dim, self.hidden_size, self.layer_num, batch_first=True, dropout=self.dropout, bidirectional = self.bidirectional)\n",
    "        self.out = nn.Linear(self.hidden_size * (1 + int(self.bidirectional)), 74)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "        x, hn = self.rnn(x)\n",
    "        h = hn[-(1 + int(self.bidirectional)):]\n",
    "        x = torch.cat(h.split(1), dim=-1).squeeze(0)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.0544946193695068\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m prediction\u001b[39m.\u001b[39mappend(p)\n\u001b[1;32m     15\u001b[0m ground_truth\u001b[39m.\u001b[39mappend(y)\n\u001b[0;32m---> 16\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RNN(input_len=120, input_dim=296, hidden_size=128, layer_num=3, dropout=0.5)\n",
    "def correlation_t(x, y):\n",
    "    return torch.sum(x * y) / (torch.sqrt(torch.sum(x * x)) * torch.sqrt(torch.sum(y * y)))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    prediction = []\n",
    "    ground_truth = []\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        p = model(x)\n",
    "        loss = F.mse_loss(p, y)\n",
    "        prediction.append(p)\n",
    "        ground_truth.append(y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, loss.item())\n",
    "    prediction = torch.cat(prediction, dim=0)\n",
    "    ground_truth = torch.cat(ground_truth, dim=0)\n",
    "    print(prediction.shape, ground_truth.shape)\n",
    "    print(epoch, correlation_t(prediction, ground_truth).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    #create LSTM model\n",
    "    #the ouput is a target value of 60 minutes later, is a scalar\n",
    "    def __init__(self, input_len, input_dim, hidden_size, layer_num, dropout=0.5, bidirectional=True):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        #embedding\n",
    "        self.bidirectional = bidirectional\n",
    "        #activation function\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_size, self.layer_num, batch_first=True, dropout=self.dropout, bidirectional = self.bidirectional,\n",
    "                            activation='relu')\n",
    "        self.out = nn.Linear(self.hidden_size * (1 + int(self.bidirectional)), 74)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        #initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #forward pass\n",
    "        bs = x.size(0)\n",
    "        _, (hn, _)= self.lstm(x)\n",
    "        h = hn[-(1 + int(self.bidirectional)):]\n",
    "        x = torch.cat(h.split(1), dim=-1).squeeze(0)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.031086802482605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m     p \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     13\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(p, y)\n\u001b[1;32m     14\u001b[0m     prediction\u001b[39m.\u001b[39mappend(p)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[22], line 26\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     24\u001b[0m     \u001b[39m#forward pass\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     bs \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     x, (hn, cn)\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[1;32m     27\u001b[0m     h \u001b[39m=\u001b[39m hn[\u001b[39m-\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)):]\n\u001b[1;32m     28\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(h\u001b[39m.\u001b[39msplit(\u001b[39m1\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:769\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    770\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    771\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    773\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LSTM(input_len=120, input_dim=296, hidden_size=128, layer_num=3, dropout=0.5)\n",
    "def correlation_t(x, y):\n",
    "    return torch.sum(x * y) / (torch.sqrt(torch.sum(x * x)) * torch.sqrt(torch.sum(y * y)))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    prediction = []\n",
    "    ground_truth = []\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        p = model(x)\n",
    "        loss = F.mse_loss(p, y)\n",
    "        prediction.append(p)\n",
    "        ground_truth.append(y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(epoch, i, loss.item())\n",
    "    prediction = torch.cat(prediction, dim=0)\n",
    "    ground_truth = torch.cat(ground_truth, dim=0)\n",
    "    print(prediction.shape, ground_truth.shape)\n",
    "    print(epoch, correlation_t(prediction, ground_truth).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/rdd16gz922j8hc9s9c737lpw0000gr/T/ipykernel_67180/38055778.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree models random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "Y = torch.randn(num_samples, 1)\n",
    "X = X.numpy()\n",
    "Y = Y.numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "#multiprocessing\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=0, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear classifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "# 4 classes\n",
    "Y = torch.randint(0, 4, (num_samples, 1))\n",
    "X = X.numpy()\n",
    "Y = Y.numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:59:59\n"
     ]
    }
   ],
   "source": [
    "#'04:00:00' to int\n",
    "def time_to_int(time):\n",
    "    #convert time to int\n",
    "    #input time format: '04:00:00'\n",
    "    #output int\n",
    "    h, m, s = time.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "#int to '04:00:00'\n",
    "def int_to_time(i):\n",
    "    #convert int to time\n",
    "    #input int\n",
    "    #output time format: '04:00:00'\n",
    "    h = i // 3600\n",
    "    m = (i - h * 3600) // 60\n",
    "    s = i - h * 3600 - m * 60\n",
    "    return '%02d:%02d:%02d' % (h, m, s)\n",
    "\n",
    "#convert time to int\n",
    "a = time_to_int('04:00:00')\n",
    "a -= 1\n",
    "print(int_to_time(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the std of the previous 60 minutes\n",
    "#nan to 0 in np array\n",
    "#inf to 0 in np array\n",
    "#-inf to 0 in np array\n",
    "x = np.array([1, 2, 3, np.nan])\n",
    "x[np.isnan(x)] = 0\n",
    "x[np.isinf(x)] = 0\n",
    "x[np.isneginf(x)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([1, 1, np.inf, np.nan, -np.inf])\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each row, normalize the mean and std of the previous 100 rows\n",
    "df = pd.DataFrame(np.random.randn(1000, 3))\n",
    "std = df.rolling(100).std().fillna(df.std())\n",
    "mean = df.rolling(100).mean().fillna(df.mean())\n",
    "df = (df - mean) / std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.zeros((1, 2)), np.ones((1, 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(np.random.randn(1000, 3))\n",
    "#assign [1, 5, 6] to each row\n",
    "df.values[:] = [1, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(max_depth=10, max_iter=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(max_depth=10, max_iter=1000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(max_depth=10, max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost Regressor\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "Y = torch.randn(num_samples, 1)\n",
    "X = X.numpy()\n",
    "Y = Y.numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "clf = HistGradientBoostingRegressor(max_iter=1000, learning_rate=0.1, max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "num_samples = 1000\n",
    "X = torch.randn(num_samples, 4 * 74)\n",
    "Y = torch.randn(num_samples, 1)\n",
    "X = X.numpy()\n",
    "Y = Y.numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "param = {'num_leaves': 31, 'objective': 'regression', 'metric': 'l2'}\n",
    "num_round = 1000\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(5, 3))\n",
    "df.index = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].index = [1, 2, 3, 1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = df[1]\n",
    "u.index = [1, 2, 3, 1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval =  ['04:00:00', '05:00:00', '06:00:00', '07:00:00']\n",
    "X = np.random.randn(4, 74)\n",
    "Y = np.random.randn(4, 1)\n",
    "#insert every minute into interval and fill corresponding position of X and Y with 0\n",
    "def insert_interval(X, Y, interval):\n",
    "    #insert every minute into interval and fill corresponding position of X and Y with 0\n",
    "    #output X and Y\n",
    "    X = pd.DataFrame(X)\n",
    "    Y = pd.DataFrame(Y)\n",
    "\n",
    "    #invert interval to int\n",
    "    interval_t = [time_to_int(i) for i in interval]\n",
    "    X.index = interval_t\n",
    "    Y.index = interval_t\n",
    "\n",
    "    #insert every minute into interval and fill corresponding position of X and Y with 0\n",
    "    X = X.reindex(range(interval_t[0], interval_t[-1] + 1, 60)).fillna(0)\n",
    "    Y = Y.reindex(range(interval_t[0], interval_t[-1] + 1, 60)).fillna(0)\n",
    "    #position of interval_t in X.index\n",
    "    pos = [X.index.get_loc(i) for i in interval_t]\n",
    "\n",
    "    return list(X.index), X.values, Y.values, pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.0.0.tar.gz (1.7 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from lightgbm) (1.10.0)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightgbm: filename=lightgbm-4.0.0-py3-none-macosx_13_0_arm64.whl size=1311735 sha256=0e08c39900e3169ae5ed39eda71385638edcb98c6da26e25b32358c348d3483d\n",
      "  Stored in directory: /Users/binweiyan/Library/Caches/pip/wheels/87/b8/97/383847beeac44a4247d7c7f350f34f0dca66bbd9bc13e02403\n",
      "Successfully built lightgbm\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval, X, Y, pos = insert_interval(X, Y, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interval_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(interval_t)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'interval_t' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(interval_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m5\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "#add 5 to all the elements in l\n",
    "l = [1, 2, 3]\n",
    "l = [i + 5 for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(4, 74)\n",
    "index = [1, 2]\n",
    "X[index][:,range(8)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/rdd16gz922j8hc9s9c737lpw0000gr/T/ipykernel_94237/3180936425.py:5: RuntimeWarning: invalid value encountered in power\n",
      "  X = np.random.normal(0, 1, 100000) ** 1.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#normal distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.random.normal(0, 1, 100000) ** 1.5\n",
    "plt.hist(X, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas fill -inf with min value\n",
    "import pandas as pd\n",
    "X = pd.DataFrame(np.random.randn(100, 3))\n",
    "X.iloc[0:10, 0] = -np.inf\n",
    "X = X.replace(-np.inf, np.nan)\n",
    "X = X.fillna(min(X.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>0.785854</td>\n",
       "      <td>0.139290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>0.348877</td>\n",
       "      <td>1.290593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>0.940154</td>\n",
       "      <td>-0.762405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>-1.022373</td>\n",
       "      <td>0.075832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.038437</td>\n",
       "      <td>-0.230745</td>\n",
       "      <td>0.880037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.850661</td>\n",
       "      <td>0.511920</td>\n",
       "      <td>-0.356195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.506087</td>\n",
       "      <td>-0.490782</td>\n",
       "      <td>0.750037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.268783</td>\n",
       "      <td>-1.446341</td>\n",
       "      <td>-0.239300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.918332</td>\n",
       "      <td>-0.730611</td>\n",
       "      <td>-0.046762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.660034</td>\n",
       "      <td>0.349468</td>\n",
       "      <td>-1.451226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0  -3.038437  0.785854  0.139290\n",
       "1  -3.038437  0.348877  1.290593\n",
       "2  -3.038437  0.940154 -0.762405\n",
       "3  -3.038437 -1.022373  0.075832\n",
       "4  -3.038437 -0.230745  0.880037\n",
       "..       ...       ...       ...\n",
       "95  1.850661  0.511920 -0.356195\n",
       "96 -1.506087 -0.490782  0.750037\n",
       "97  2.268783 -1.446341 -0.239300\n",
       "98  0.918332 -0.730611 -0.046762\n",
       "99 -1.660034  0.349468 -1.451226\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, np.nan])\n",
    "#count the number of nan\n",
    "np.sum(np.isnan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select column not nan\n",
    "X = pd.DataFrame(np.random.randn(100, 3))\n",
    "X.iloc[0:10, 0] = np.nan\n",
    "X = X[np.isnan(X.iloc[:, 0]) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate average minute quote data\n",
    "import pandas as pd\n",
    "\n",
    "#df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize']\n",
    "num_samples = 1000\n",
    "df = pd.DataFrame(columns = ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize'], \n",
    "                  index = range(num_samples))\n",
    "df['date'] = '2020-01-01'\n",
    "#generate random interval for each second\n",
    "df['interval'] = pd.date_range('2020-01-01 04:00:00', periods=num_samples, freq='S')\n",
    "df['interval'] = df['interval'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "df['msymbol_ukey'] = 1\n",
    "df['DD.askSize'] = np.random.randn(num_samples)\n",
    "df['DD.ask'] = np.random.randn(num_samples)\n",
    "df['DD.bid'] = np.random.randn(num_samples)\n",
    "df['DD.bidSize'] = np.random.randn(num_samples)\n",
    "df['DD.isActive'] = np.random.randint(0, 2, num_samples)\n",
    "df['DD.volBuy'] = np.random.randn(num_samples)\n",
    "df['DD.volSell'] = np.random.randn(num_samples)\n",
    "df['DD.ret'] = np.random.randn(num_samples)\n",
    "df['DD.vol'] = np.random.randn(num_samples)\n",
    "#get the average minute quote data\n",
    "\n",
    "def get_average_minute_quote(df):\n",
    "    #get the average minute quota data\n",
    "    #input df\n",
    "    #output df\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5])\n",
    "    ask = df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.askSize'].transform(lambda x: np.mean(x))\n",
    "    bid = df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.bidSize'].transform(lambda x: np.mean(x))\n",
    "    return pd.concat([ask, bid], axis=1)\n",
    "#how many seconds is active in each minute\n",
    "def get_active_seconds(df):\n",
    "    #how many seconds is active in each minute\n",
    "    #input df\n",
    "    #output df\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize', 'DD.isActive']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    #count the number of DD.active == 1 in each minute\n",
    "    df['active_seconds'] = df.groupby( ['date', 'minute', 'msymbol_ukey'])['DD.isActive'].transform('sum')\n",
    "    return df['active_seconds']\n",
    "\n",
    "#how any times the ret goes from positive to negative in each minute\n",
    "def get_ret_change_times(df):\n",
    "    #how any times the ret goes from positive to negative in each minute\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    #how many times the ret goes from positive to negative in each minute\n",
    "    #ignore 0\n",
    "\n",
    "    df['non_zero_ret'] = df.groupby( ['date', 'minute', 'msymbol_ukey'] )['DD.ret'].transform(lambda x: x[x != 0])\n",
    "    df['ret_change_times'] = df.groupby(['date', 'minute', 'msymbol_ukey'])['non_zero_ret'].transform( lambda x: np.sum(np.diff(np.sign(x)) != 0))\n",
    "\n",
    "    return df['ret_change_times']\n",
    "\n",
    "#quantile for each minute\n",
    "def get_quantile(df, quantile = 3):\n",
    "    #quantile for each minute\n",
    "    #input df\n",
    "    #output df\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    #return the mean of each quantile\n",
    "    for i in range(quantile):\n",
    "        df['quantile_' + str(i)] = df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.ret'].transform( lambda x: np.mean(x[(x > np.quantile(x, i / quantile)) * ((x < np.quantile(x, (i + 1) / quantile)))]))\n",
    "    return df[[col for col in df.columns if 'quantile' in col]]\n",
    "\n",
    "#Entropy of a time horizon\n",
    "def get_entropy(df, m, t):\n",
    "    #Entropy of a time horizon\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    #t is the time horizon\n",
    "    #apply smoothing to each horizon m\n",
    "    df['smooth'] = df.groupby(['date', 'msymbol_ukey'])['DD.ret'].transform(lambda x: x.rolling(m).apply(lambda x: np.mean(x)))\n",
    "    #get the entropy of each time horizon t\n",
    "    df['entropy'] = df.groupby(['date', 'msymbol_ukey'])['smooth'].transform(lambda x: x.rolling(t).apply(lambda x: -np.sum(x * np.log(x))))\n",
    "    return df['entropy']\n",
    "\n",
    "#the acculmulated Buy - Sell imbalance\n",
    "def get_imbalance(df):\n",
    "    #the acculmulated Buy - Sell imbalance\n",
    "    #df has columns: ['date', 'interval', 'msymbol_ukey', 'DD.askSize', 'DD.ask', 'DD.bid', 'DD.bidSize', 'DD.isActive', 'DD.volBuy', 'DD.volSell']\n",
    "    #interval is in format of string '04:00:00'\n",
    "    df['imbalance'] = df.groupby(['date', 'msymbol_ukey'])['DD.volBuy'].transform(lambda x: np.cumsum(x)) - df.groupby(['date', 'msymbol_ukey'])['DD.volSell'].transform(lambda x: np.cumsum(x))\n",
    "    return df['imbalance']\n",
    "\n",
    "#get the quantile of ret based on DD.vol quantile\n",
    "def get_vol_quantile(df, quantile = 2):\n",
    "    #get the quantile of ret based on DD.vol quantile\n",
    "    #return vol quantile\n",
    "    df['vol_quantile'] = pd.qcut(df['DD.vol'], quantile, labels=False)\n",
    "    df['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    #return the mean of each quantile\n",
    "    for i in range(quantile):\n",
    "        df['vol_quantile_' + str(i)] = df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.ret'].transform(lambda x: np.mean(x[df['vol_quantile'] == i]))\n",
    "        df['imbalance_quantile_' + str(i)] = df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.volBuy'].transform(lambda x: np.mean(x[df['vol_quantile'] == i])) - df.groupby(['date', 'minute', 'msymbol_ukey'])['DD.volSell'].transform(lambda x: np.mean(x[df['vol_quantile'] == i]))\n",
    "    return df[[col for col in df.columns if '_quantile_' in col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile = 3\n",
    "i = 0\n",
    "f =  lambda x: np.mean(x[(x > np.quantile(x, i / quantile)) * ((x < np.quantile(x, (i + 1) / quantile)))])\n",
    "f(np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrate all the features\n",
    "def get_features(df):\n",
    "    #integrate all the features\n",
    "    new = pd.DataFrame()\n",
    "    new = pd.concat([new, get_average_minute_quote(df)], axis=1)\n",
    "    new['active_seconds'] = get_active_seconds(df)\n",
    "    new['ret_change_times'] = get_ret_change_times(df)\n",
    "    new = pd.concat([new, get_quantile(df, quantile = 3)], axis=1)\n",
    "    for m in [10, 30, 60]:\n",
    "        for t in [10, 30, 60]:\n",
    "            new['entropy_' + str(m) + '_' + str(t)] = get_entropy(df, m, t)\n",
    "    new['imbalance'] = get_imbalance(df)\n",
    "    new = pd.concat([new, get_vol_quantile(df, quantile = 3)], axis=1)\n",
    "    new['date'] = df['date']\n",
    "    new['minute'] = df['interval'].apply(lambda x: x[0:5]) + ':00'\n",
    "    new['msymbol_ukey'] = df['msymbol_ukey']\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1,   1,   1,   1,   1, -17,  19])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(np.array([1, 2, 3, 4, 5, 6, 7, 8, -9, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = get_features(df)\n",
    "#squeeze the dataframe by squeezing the minute\n",
    "new = new.groupby(['date', 'minute', 'msymbol_ukey']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>minute</th>\n",
       "      <th>msymbol_ukey</th>\n",
       "      <th>DD.askSize</th>\n",
       "      <th>DD.bidSize</th>\n",
       "      <th>active_seconds</th>\n",
       "      <th>ret_change_times</th>\n",
       "      <th>quantile_0</th>\n",
       "      <th>quantile_1</th>\n",
       "      <th>quantile_2</th>\n",
       "      <th>...</th>\n",
       "      <th>entropy_60_10</th>\n",
       "      <th>entropy_60_30</th>\n",
       "      <th>entropy_60_60</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>vol_quantile_0</th>\n",
       "      <th>imbalance_quantile_0</th>\n",
       "      <th>vol_quantile_1</th>\n",
       "      <th>imbalance_quantile_1</th>\n",
       "      <th>vol_quantile_2</th>\n",
       "      <th>imbalance_quantile_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153576</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-1.029904</td>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.950497</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.189473</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>-0.211545</td>\n",
       "      <td>0.029545</td>\n",
       "      <td>0.689109</td>\n",
       "      <td>-0.075620</td>\n",
       "      <td>0.379304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070277</td>\n",
       "      <td>0.170257</td>\n",
       "      <td>37.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.823792</td>\n",
       "      <td>0.102571</td>\n",
       "      <td>1.140267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403585</td>\n",
       "      <td>0.755708</td>\n",
       "      <td>2.989781</td>\n",
       "      <td>14.810075</td>\n",
       "      <td>0.261117</td>\n",
       "      <td>0.150261</td>\n",
       "      <td>-0.006286</td>\n",
       "      <td>-0.257019</td>\n",
       "      <td>0.125186</td>\n",
       "      <td>-0.291971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.132703</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.751911</td>\n",
       "      <td>0.447799</td>\n",
       "      <td>1.357787</td>\n",
       "      <td>...</td>\n",
       "      <td>3.346957</td>\n",
       "      <td>8.855843</td>\n",
       "      <td>12.950576</td>\n",
       "      <td>-1.988678</td>\n",
       "      <td>0.410844</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>-0.884480</td>\n",
       "      <td>0.026573</td>\n",
       "      <td>0.242825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165413</td>\n",
       "      <td>0.215126</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-0.775364</td>\n",
       "      <td>0.189733</td>\n",
       "      <td>1.158413</td>\n",
       "      <td>...</td>\n",
       "      <td>3.521326</td>\n",
       "      <td>10.673072</td>\n",
       "      <td>21.194466</td>\n",
       "      <td>-5.424806</td>\n",
       "      <td>0.409813</td>\n",
       "      <td>-0.123007</td>\n",
       "      <td>-0.247409</td>\n",
       "      <td>-0.501979</td>\n",
       "      <td>0.262230</td>\n",
       "      <td>0.278925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.149525</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-0.933860</td>\n",
       "      <td>0.088822</td>\n",
       "      <td>1.207721</td>\n",
       "      <td>...</td>\n",
       "      <td>2.831463</td>\n",
       "      <td>9.135907</td>\n",
       "      <td>19.285445</td>\n",
       "      <td>-8.638203</td>\n",
       "      <td>-0.224793</td>\n",
       "      <td>0.103901</td>\n",
       "      <td>0.154870</td>\n",
       "      <td>-0.173902</td>\n",
       "      <td>0.259310</td>\n",
       "      <td>-0.057253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.128483</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.148900</td>\n",
       "      <td>-0.050557</td>\n",
       "      <td>0.841266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829005</td>\n",
       "      <td>3.566250</td>\n",
       "      <td>11.005239</td>\n",
       "      <td>-14.218954</td>\n",
       "      <td>0.105987</td>\n",
       "      <td>0.125208</td>\n",
       "      <td>-0.285584</td>\n",
       "      <td>-0.485725</td>\n",
       "      <td>-0.215696</td>\n",
       "      <td>-0.144039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:06:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235428</td>\n",
       "      <td>0.280623</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.057598</td>\n",
       "      <td>-0.060052</td>\n",
       "      <td>0.945063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.434104</td>\n",
       "      <td>-18.870400</td>\n",
       "      <td>0.102676</td>\n",
       "      <td>-0.231962</td>\n",
       "      <td>-0.185992</td>\n",
       "      <td>0.235239</td>\n",
       "      <td>-0.056506</td>\n",
       "      <td>-0.013393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.072431</td>\n",
       "      <td>-0.253060</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.066722</td>\n",
       "      <td>0.109472</td>\n",
       "      <td>0.965269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689714</td>\n",
       "      <td>1.683939</td>\n",
       "      <td>2.016381</td>\n",
       "      <td>-16.657134</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>-0.033327</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.373604</td>\n",
       "      <td>-0.155816</td>\n",
       "      <td>-0.897658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.056604</td>\n",
       "      <td>-0.231385</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-1.007138</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.969862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423578</td>\n",
       "      <td>1.297306</td>\n",
       "      <td>3.256097</td>\n",
       "      <td>-15.261343</td>\n",
       "      <td>-0.194640</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.086670</td>\n",
       "      <td>-0.282515</td>\n",
       "      <td>0.350880</td>\n",
       "      <td>0.133144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:09:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>0.216379</td>\n",
       "      <td>29.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-1.113413</td>\n",
       "      <td>-0.042046</td>\n",
       "      <td>1.113367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727067</td>\n",
       "      <td>2.359666</td>\n",
       "      <td>4.585963</td>\n",
       "      <td>-37.607876</td>\n",
       "      <td>0.208946</td>\n",
       "      <td>-0.165622</td>\n",
       "      <td>-0.345881</td>\n",
       "      <td>-0.363368</td>\n",
       "      <td>0.068628</td>\n",
       "      <td>-0.514738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.098263</td>\n",
       "      <td>-0.077050</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.023045</td>\n",
       "      <td>-0.108588</td>\n",
       "      <td>1.027990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068666</td>\n",
       "      <td>0.350719</td>\n",
       "      <td>1.468776</td>\n",
       "      <td>-44.611247</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>-0.065165</td>\n",
       "      <td>-0.053319</td>\n",
       "      <td>-0.356827</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.140586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.091930</td>\n",
       "      <td>-0.082737</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.198306</td>\n",
       "      <td>-0.376106</td>\n",
       "      <td>0.689015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238445</td>\n",
       "      <td>0.761235</td>\n",
       "      <td>1.276669</td>\n",
       "      <td>-53.422491</td>\n",
       "      <td>-0.541296</td>\n",
       "      <td>-0.172060</td>\n",
       "      <td>-0.274417</td>\n",
       "      <td>0.098189</td>\n",
       "      <td>-0.138849</td>\n",
       "      <td>-0.378278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:12:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161285</td>\n",
       "      <td>0.113173</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.921368</td>\n",
       "      <td>0.067695</td>\n",
       "      <td>1.078017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059547</td>\n",
       "      <td>0.062108</td>\n",
       "      <td>0.369181</td>\n",
       "      <td>-66.879465</td>\n",
       "      <td>0.124796</td>\n",
       "      <td>-0.481211</td>\n",
       "      <td>0.085117</td>\n",
       "      <td>-0.152890</td>\n",
       "      <td>-0.021408</td>\n",
       "      <td>-0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:13:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.126593</td>\n",
       "      <td>0.060155</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.203777</td>\n",
       "      <td>0.114519</td>\n",
       "      <td>0.937105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704964</td>\n",
       "      <td>2.218546</td>\n",
       "      <td>3.687903</td>\n",
       "      <td>-80.824625</td>\n",
       "      <td>-0.044405</td>\n",
       "      <td>0.161449</td>\n",
       "      <td>-0.318536</td>\n",
       "      <td>-0.801035</td>\n",
       "      <td>0.157828</td>\n",
       "      <td>-0.222841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031625</td>\n",
       "      <td>-0.147547</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.185362</td>\n",
       "      <td>-0.092406</td>\n",
       "      <td>0.996789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081883</td>\n",
       "      <td>0.141936</td>\n",
       "      <td>0.992224</td>\n",
       "      <td>-82.516711</td>\n",
       "      <td>-0.050557</td>\n",
       "      <td>-0.095838</td>\n",
       "      <td>-0.376879</td>\n",
       "      <td>-0.184198</td>\n",
       "      <td>0.124989</td>\n",
       "      <td>1.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.164147</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-1.071139</td>\n",
       "      <td>-0.111148</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887421</td>\n",
       "      <td>2.581837</td>\n",
       "      <td>3.108687</td>\n",
       "      <td>-68.073476</td>\n",
       "      <td>-0.170508</td>\n",
       "      <td>-0.098457</td>\n",
       "      <td>-0.102227</td>\n",
       "      <td>0.121672</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>-0.121451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:16:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158850</td>\n",
       "      <td>0.229103</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.580852</td>\n",
       "      <td>0.308717</td>\n",
       "      <td>1.240138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655306</td>\n",
       "      <td>1.205921</td>\n",
       "      <td>4.759841</td>\n",
       "      <td>-68.443982</td>\n",
       "      <td>0.950501</td>\n",
       "      <td>-0.641671</td>\n",
       "      <td>0.192922</td>\n",
       "      <td>0.225859</td>\n",
       "      <td>0.385319</td>\n",
       "      <td>-0.580479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    minute  msymbol_ukey  DD.askSize  DD.bidSize  \\\n",
       "0   2020-01-01  04:00:00             1    0.153576    0.159888   \n",
       "1   2020-01-01  04:01:00             1    0.070277    0.170257   \n",
       "2   2020-01-01  04:02:00             1    0.132703    0.141176   \n",
       "3   2020-01-01  04:03:00             1    0.165413    0.215126   \n",
       "4   2020-01-01  04:04:00             1   -0.149525    0.029624   \n",
       "5   2020-01-01  04:05:00             1   -0.128483    0.044118   \n",
       "6   2020-01-01  04:06:00             1    0.235428    0.280623   \n",
       "7   2020-01-01  04:07:00             1   -0.072431   -0.253060   \n",
       "8   2020-01-01  04:08:00             1   -0.056604   -0.231385   \n",
       "9   2020-01-01  04:09:00             1   -0.026685    0.216379   \n",
       "10  2020-01-01  04:10:00             1   -0.098263   -0.077050   \n",
       "11  2020-01-01  04:11:00             1   -0.091930   -0.082737   \n",
       "12  2020-01-01  04:12:00             1    0.161285    0.113173   \n",
       "13  2020-01-01  04:13:00             1   -0.126593    0.060155   \n",
       "14  2020-01-01  04:14:00             1   -0.031625   -0.147547   \n",
       "15  2020-01-01  04:15:00             1   -0.164147    0.055756   \n",
       "16  2020-01-01  04:16:00             1    0.158850    0.229103   \n",
       "\n",
       "    active_seconds  ret_change_times  quantile_0  quantile_1  quantile_2  ...  \\\n",
       "0             32.0              28.0   -1.029904    0.040093    0.950497  ...   \n",
       "1             37.0              25.0   -0.823792    0.102571    1.140267  ...   \n",
       "2             23.0              28.0   -0.751911    0.447799    1.357787  ...   \n",
       "3             27.0              35.0   -0.775364    0.189733    1.158413  ...   \n",
       "4             28.0              34.0   -0.933860    0.088822    1.207721  ...   \n",
       "5             28.0              24.0   -1.148900   -0.050557    0.841266  ...   \n",
       "6             32.0              31.0   -1.057598   -0.060052    0.945063  ...   \n",
       "7             31.0              31.0   -1.066722    0.109472    0.965269  ...   \n",
       "8             26.0              27.0   -1.007138    0.259542    0.969862  ...   \n",
       "9             29.0              37.0   -1.113413   -0.042046    1.113367  ...   \n",
       "10            26.0              29.0   -1.023045   -0.108588    1.027990  ...   \n",
       "11            30.0              32.0   -1.198306   -0.376106    0.689015  ...   \n",
       "12            30.0              27.0   -0.921368    0.067695    1.078017  ...   \n",
       "13            28.0              31.0   -1.203777    0.114519    0.937105  ...   \n",
       "14            28.0              25.0   -1.185362   -0.092406    0.996789  ...   \n",
       "15            30.0              39.0   -1.071139   -0.111148    0.853360  ...   \n",
       "16            24.0              15.0   -0.580852    0.308717    1.240138  ...   \n",
       "\n",
       "    entropy_60_10  entropy_60_30  entropy_60_60  imbalance  vol_quantile_0  \\\n",
       "0             NaN            NaN            NaN   8.189473        0.034226   \n",
       "1        0.403585       0.755708       2.989781  14.810075        0.261117   \n",
       "2        3.346957       8.855843      12.950576  -1.988678        0.410844   \n",
       "3        3.521326      10.673072      21.194466  -5.424806        0.409813   \n",
       "4        2.831463       9.135907      19.285445  -8.638203       -0.224793   \n",
       "5        0.829005       3.566250      11.005239 -14.218954        0.105987   \n",
       "6        0.005229       0.005229       0.434104 -18.870400        0.102676   \n",
       "7        0.689714       1.683939       2.016381 -16.657134        0.049987   \n",
       "8        0.423578       1.297306       3.256097 -15.261343       -0.194640   \n",
       "9        0.727067       2.359666       4.585963 -37.607876        0.208946   \n",
       "10       0.068666       0.350719       1.468776 -44.611247        0.004357   \n",
       "11       0.238445       0.761235       1.276669 -53.422491       -0.541296   \n",
       "12       0.059547       0.062108       0.369181 -66.879465        0.124796   \n",
       "13       0.704964       2.218546       3.687903 -80.824625       -0.044405   \n",
       "14       0.081883       0.141936       0.992224 -82.516711       -0.050557   \n",
       "15       0.887421       2.581837       3.108687 -68.073476       -0.170508   \n",
       "16       0.655306       1.205921       4.759841 -68.443982        0.950501   \n",
       "\n",
       "    imbalance_quantile_0  vol_quantile_1  imbalance_quantile_1  \\\n",
       "0              -0.211545        0.029545              0.689109   \n",
       "1               0.150261       -0.006286             -0.257019   \n",
       "2               0.000086        0.533422             -0.884480   \n",
       "3              -0.123007       -0.247409             -0.501979   \n",
       "4               0.103901        0.154870             -0.173902   \n",
       "5               0.125208       -0.285584             -0.485725   \n",
       "6              -0.231962       -0.185992              0.235239   \n",
       "7              -0.033327        0.022358              0.373604   \n",
       "8               0.016368        0.086670             -0.282515   \n",
       "9              -0.165622       -0.345881             -0.363368   \n",
       "10             -0.065165       -0.053319             -0.356827   \n",
       "11             -0.172060       -0.274417              0.098189   \n",
       "12             -0.481211        0.085117             -0.152890   \n",
       "13              0.161449       -0.318536             -0.801035   \n",
       "14             -0.095838       -0.376879             -0.184198   \n",
       "15             -0.098457       -0.102227              0.121672   \n",
       "16             -0.641671        0.192922              0.225859   \n",
       "\n",
       "    vol_quantile_2  imbalance_quantile_2  \n",
       "0        -0.075620              0.379304  \n",
       "1         0.125186             -0.291971  \n",
       "2         0.026573              0.242825  \n",
       "3         0.262230              0.278925  \n",
       "4         0.259310             -0.057253  \n",
       "5        -0.215696             -0.144039  \n",
       "6        -0.056506             -0.013393  \n",
       "7        -0.155816             -0.897658  \n",
       "8         0.350880              0.133144  \n",
       "9         0.068628             -0.514738  \n",
       "10        0.009381              0.140586  \n",
       "11       -0.138849             -0.378278  \n",
       "12       -0.021408             -0.120600  \n",
       "13        0.157828             -0.222841  \n",
       "14        0.124989              1.061014  \n",
       "15       -0.000490             -0.121451  \n",
       "16        0.385319             -0.580479  \n",
       "\n",
       "[17 rows x 33 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'(1, 2, 5, 7)' into tuple\n",
    "x = 'feat_(1, 2, 5, 7)_erfs'\n",
    "x = x.split('_')\n",
    "#position of 'feat'\n",
    "x = x[x.index('feat') + 1]\n",
    "x = tuple([int(i) for i in x[1:-1].split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = [1, 2, 3, 4, 5]\n",
    "k = np.random.randn(5)\n",
    "np.array(pos)[np.isnan(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
